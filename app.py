import streamlit as st
# Force rebuild 2026-01-29 v5 (Sync & UI Polish)
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import io
import sqlite3
import datetime
import re
import smtplib
import json
import platform
import os
import matplotlib.font_manager as fm
from matplotlib import rc
from email.mime.text import MIMEText
from scipy.stats import gmean, ttest_rel, f_oneway
from PIL import Image
import itertools
from math import pi
from dateutil.relativedelta import relativedelta

# [í•„ìˆ˜] plotly ë¼ì´ë¸ŒëŸ¬ë¦¬ (requirements.txtì— plotly ì¶”ê°€ í•„ìš”)
import plotly.express as px
import plotly.graph_objects as go
from scipy import stats
import gspread
from google.oauth2.service_account import Credentials
from signup_agreement import show_agreement_ui, save_agreement_to_sheets, validate_all_agreements

# 1. ì¶”ê°€í•´ì•¼ í•  ë¼ì´ë¸ŒëŸ¬ë¦¬ (ê¸°ì¡´ Credentials ë°”ë¡œ ì•„ë˜ ì¶”ê°€)
from streamlit_javascript import st_javascript
import base64

# IP ìœ„ì¹˜ ì¶”ì  ë° ê³µì¸ IP ì¶”ì¶œì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
import requests

# [ìµœì í™” ì¶”ê°€] ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ ìŠ¤ë ˆë”© ë¼ì´ë¸ŒëŸ¬ë¦¬
import threading

# ANOVA ë° ì‚¬í›„ê²€ì •ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì—†ì„ ê²½ìš° ì˜ˆì™¸ì²˜ë¦¬)
try:
    from statsmodels.stats.multicomp import pairwise_tukeyhsd
    STATSMODELS_AVAILABLE = True
except ImportError:
    STATSMODELS_AVAILABLE = False

# =============================================================================
# 0. ì‹œìŠ¤í…œ ì„¤ì • ë° ìœ í‹¸ë¦¬í‹°
# =============================================================================

# [ìˆ˜ì •] Base64 ë¬¸ìì—´ì˜ íŒ¨ë”© ë° ì •ì œë¥¼ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ê°•í™”
def fix_base64_padding(data):
    """
    Base64 ë¬¸ìì—´ì˜ íŒ¨ë”©(Incorrect padding) ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ëŠ” í•¨ìˆ˜
    """
    if isinstance(data, str):
        # 1. ëª¨ë“  ê³µë°± ë° ì¤„ë°”ê¿ˆ ë¬¸ì ì œê±° (ê°€ì¥ ì¤‘ìš”í•œ ìˆ˜ì •)
        data = re.sub(r'\s+', '', data)
        
        # 2. íŒ¨ë”©(=) ê³„ì‚° ë° ì¶”ê°€
        missing_padding = len(data) % 4
        if missing_padding:
            data += '=' * (4 - missing_padding)
    return data

# [ìˆ˜ì • ë°˜ì˜] 1) SEO íƒœê·¸ ì‚½ì…, 2) ì„œë¹„ìŠ¤ ëª… ë³€ê²½(AHP ë§ˆìŠ¤í„°), 4) íŒŒë¹„ì½˜ ì„¤ì •
try:
    logo_path = "ahp_master_logo.png"
    if os.path.exists(logo_path):
        logo_img = Image.open(logo_path)
    else:
        logo_img = "ğŸ“Š"
    
    st.set_page_config(
        page_title="AHP ë§ˆìŠ¤í„°", 
        layout="wide", 
        page_icon=logo_img,
        menu_items={
            'Get Help': None,
            'Report a bug': None,
            'About': "AHP ë§ˆìŠ¤í„° - ìŠ¤ë§ˆíŠ¸ ì˜ì‚¬ê²°ì • ë¶„ì„ ì‹œìŠ¤í…œ"
        }
    )
except Exception:
    st.set_page_config(page_title="AHP ë§ˆìŠ¤í„°", layout="wide", page_icon="ğŸ“Š")

# [ìˆ˜ì • ë°˜ì˜] ë©”íƒ€ ì½”ë“œê°€ í™”ë©´ì— ë…¸ì¶œë˜ì§€ ì•Šë„ë¡ display:none ìŠ¤íƒ€ì¼ì„ ì¶”ê°€í•œ SEO íƒœê·¸
seo_tags = """
    <div style="display:none;">
        <head>
            <meta name="description" content="AHP ë§ˆìŠ¤í„° - í•™ìœ„ ë…¼ë¬¸ ë° ì •ì±… ì—°êµ¬ë¥¼ ìœ„í•œ ìµœì ì˜ AHP ë¶„ì„ ìë™í™” ì†”ë£¨ì…˜. ì¼ê´€ì„± ë¹„ìœ¨(CR) ìë™ ë³´ì • ë° í†µê³„ ê²€ì • ì œê³µ.">
            <meta name="keywords" content="AHP, ë¬´ë£Œ, í”„ë¡œê·¸ë¨, AHPë¶„ì„, ê³„ì¸µë¶„ì„ê³¼ì •, ì¼ê´€ì„±ë³´ì •, CRë³´ì •, í•™ìœ„ë…¼ë¬¸í†µê³„, AHPê³„ì‚°ê¸°, AHP ë§ˆìŠ¤í„°">
            <meta name="author" content="AHP Master">
            <meta property="og:title" content="AHP ë§ˆìŠ¤í„°: ë¶„ì„ ìë™í™” ì‹œìŠ¤í…œ">
            <meta property="og:description" content="ìˆ˜í•™ì  ì¼ê´€ì„± ë³´ì •ê³¼ ê³ ë„í™”ëœ í†µê³„ ë¶„ì„ì„ ì§€ì›í•˜ëŠ” ìµœì‹  AHP ì „ë¬¸ ë„êµ¬">
        </head>
    </div>
"""
st.markdown(seo_tags, unsafe_allow_html=True)

# [í°íŠ¸ ì„¤ì •]
def set_font_config():
    system_name = platform.system()
    try:
        if system_name == 'Windows':
            font_path = "c:/Windows/Fonts/malgun.ttf"
            if os.path.exists(font_path):
                font_name = fm.FontProperties(fname=font_path).get_name()
                rc('font', family=font_name)
        elif system_name == 'Darwin': # Mac
            rc('font', family='AppleGothic')
        else: # Linux
            font_path = "NanumGothic.ttf"
            if not os.path.exists(font_path):
                import urllib.request
                url = "https://github.com/google/fonts/raw/main/ofl/nanumgothic/NanumGothic-Regular.ttf"
                urllib.request.urlretrieve(url, font_path)
            fm.fontManager.addfont(font_path)
            font_prop = fm.FontProperties(fname=font_path)
            rc('font', family=font_prop.get_name())
    except Exception:
        pass
    plt.rcParams['axes.unicode_minus'] = False 

set_font_config()

# [ì¤‘ìš” ìˆ˜ì •] êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° í—¬í¼ í•¨ìˆ˜ - ì¸ì¦ ì •ë³´ ë¡œë“œ ë¡œì§ ì „ë©´ ì¬ê²€í†  ë° ìˆ˜ì •
# TOML(Dict), JSON String, Base64 Encoded String ë“± ë‹¤ì–‘í•œ í¬ë§·ì— ëŒ€ì‘í•˜ë„ë¡ ê°•í™”
def get_gspread_client():
    scope = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
    
    # st.secretsì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸° (ì—†ì„ ê²½ìš° ì—ëŸ¬ ì²˜ë¦¬)
    if "gcp_service_account" not in st.secrets:
        st.error("Secretsì— 'gcp_service_account' ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    raw_auth = st.secrets["gcp_service_account"]
    auth_info = {}

    # Case 1: ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš° (TOML í¬ë§·) - ê°€ì¥ ì¼ë°˜ì ì¸ ê²½ìš°
    if isinstance(raw_auth, dict) or hasattr(raw_auth, "keys"): 
        auth_info = dict(raw_auth) # AttrDict ë“±ì„ dictë¡œ ë³€í™˜
    
    # Case 2: ë¬¸ìì—´ í˜•íƒœì¸ ê²½ìš° (JSON ë¬¸ìì—´ í˜¹ì€ Base64 ì¸ì½”ë”© ë¬¸ìì—´)
    elif isinstance(raw_auth, str):
        # ì•ë’¤ ê³µë°± ë° ë”°ì˜´í‘œ ì œê±°
        auth_str = raw_auth.strip().strip('"').strip("'")
        
        try:
            # 2-1. ìˆœìˆ˜ JSON ë¬¸ìì—´ë¡œ íŒŒì‹± ì‹œë„
            auth_info = json.loads(auth_str)
        except json.JSONDecodeError:
            # 2-2. JSON íŒŒì‹± ì‹¤íŒ¨ -> Base64 ì¸ì½”ë”©ëœ ê°’ìœ¼ë¡œ ê°€ì •í•˜ê³  ë””ì½”ë”© ì‹œë„
            try:
                # 1ë‹¨ê³„: ë¬¸ìì—´ ì •ì œ (ëª¨ë“  ê³µë°± ì œê±°)
                clean_b64 = re.sub(r'\s+', '', auth_str)
                
                # 2ë‹¨ê³„: íŒ¨ë”©(=) ë³´ì •
                missing_padding = len(clean_b64) % 4
                if missing_padding:
                    clean_b64 += '=' * (4 - missing_padding)
                
                # 3ë‹¨ê³„: Base64 ë””ì½”ë”© (Standard ë° URL-Safe ë°©ì‹ ëª¨ë‘ ì‹œë„)
                try:
                    decoded_bytes = base64.b64decode(clean_b64)
                except Exception:
                    # Standard ì‹¤íŒ¨ ì‹œ URL-Safe ë°©ì‹ ì‹œë„ (-ì™€ _ ë¬¸ì ì²˜ë¦¬)
                    decoded_bytes = base64.urlsafe_b64decode(clean_b64)
                    
                decoded_info = decoded_bytes.decode('utf-8')
                auth_info = json.loads(decoded_info)
            except Exception as e:
                st.error(f"ì„œë¹„ìŠ¤ ê³„ì • í‚¤ ë””ì½”ë”© ì‹¤íŒ¨ (Base64/JSON ì˜¤ë¥˜): {e}")
                return None
    else:
        st.error("gcp_service_account í˜•ì‹ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # [ì¤‘ìš”] Private Key ë‚´ì˜ ì¤„ë°”ê¿ˆ ë¬¸ì(\n) ì²˜ë¦¬
    # TOML ë“±ì—ì„œ ë¬¸ìì—´ë¡œ ì½ì–´ì˜¬ ë•Œ \\nìœ¼ë¡œ ì´ìŠ¤ì¼€ì´í”„ëœ ê²½ìš° ì‹¤ì œ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë³€ê²½ í•„ìš”
    if auth_info and "private_key" in auth_info:
        auth_info["private_key"] = auth_info["private_key"].replace("\\n", "\n")

    # í•„ìˆ˜ í•„ë“œ í™•ì¸ (Missing fields ì—ëŸ¬ ë°©ì§€)
    required_fields = ["private_key", "client_email", "token_uri"]
    missing = [f for f in required_fields if f not in auth_info]
    if missing:
        st.error(f"ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´ì— í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing)}")
        return None

    creds = Credentials.from_service_account_info(auth_info, scopes=scope)
    return gspread.authorize(creds)

# DB ì´ˆê¸°í™” ë° êµ¬ê¸€ ì‹œíŠ¸ë¡œë¶€í„° ë°ì´í„°(íšŒì›+ë°©ë¬¸ë¡œê·¸) ë³µêµ¬ ë¡œì§
def init_db():
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS users
                  (id TEXT PRIMARY KEY, pw TEXT, role TEXT, signup_date TEXT, expiry_date TEXT)''')
    c.execute('''CREATE TABLE IF NOT EXISTS saved_analyses
                  (id INTEGER PRIMARY KEY AUTOINCREMENT, user_id TEXT, filename TEXT, save_date TEXT, file_data BLOB)''')
    c.execute('''CREATE TABLE IF NOT EXISTS user_models
                  (user_id TEXT PRIMARY KEY, model_data TEXT)''')
    c.execute('''CREATE TABLE IF NOT EXISTS visit_logs
                  (ip_address TEXT, visit_date TEXT, PRIMARY KEY (ip_address, visit_date))''')
    
    # [ì»¤ë®¤ë‹ˆí‹° ê¸°ëŠ¥ í…Œì´ë¸” ìˆ˜ì •/ì¶”ê°€]
    # views: ì¡°íšŒìˆ˜ ì¹´ìš´íŠ¸ ì»¬ëŸ¼ ì¶”ê°€
    c.execute('''CREATE TABLE IF NOT EXISTS community_posts
                  (id INTEGER PRIMARY KEY AUTOINCREMENT, user_id TEXT, title TEXT, content TEXT, reg_date TEXT, is_secret INTEGER, is_notice INTEGER, likes INTEGER DEFAULT 0, non_user_pw TEXT, views INTEGER DEFAULT 0)''')
    
    try:
        c.execute("ALTER TABLE community_posts ADD COLUMN non_user_pw TEXT")
    except sqlite3.OperationalError:
        pass
    
    # [ìš”ì²­ì‚¬í•­ 3] ì¡°íšŒìˆ˜ ì»¬ëŸ¼ ì¶”ê°€ ë¡œì§
    try:
        c.execute("ALTER TABLE community_posts ADD COLUMN views INTEGER DEFAULT 0")
    except sqlite3.OperationalError:
        pass

    c.execute('''CREATE TABLE IF NOT EXISTS community_comments
                (id INTEGER PRIMARY KEY AUTOINCREMENT, post_id INTEGER, user_id TEXT, 
                content TEXT, reg_date TEXT, is_secret INTEGER)''')
    
    # [ìµœì í™” ì¶”ê°€] DB ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì¸ë±ìŠ¤ ìƒì„±
    c.execute("CREATE INDEX IF NOT EXISTS idx_post_id ON community_comments(post_id)")
    
    # ê´€ë¦¬ì ê³„ì • ìƒì„±
    try:
        kst_now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))
        signup_date_str = kst_now.strftime("%Y-%m-%d")
        c.execute("INSERT OR IGNORE INTO users VALUES (?, ?, ?, ?, ?)", 
                  ('shjeon', '@jsh2143033', 'admin', signup_date_str, '9999-12-31'))
        conn.commit()
    except sqlite3.IntegrityError:
        pass 

    # [ë³µêµ¬ ë¡œì§ 1] íšŒì› ì •ë³´ ë³µêµ¬
    c.execute("SELECT COUNT(*) FROM users")
    if c.fetchone()[0] <= 1:
        try:
            client = get_gspread_client()
            if client:
                spreadsheet = client.open_by_key(st.secrets["SPREADSHEET_ID"])
                sheet = spreadsheet.sheet1 
                all_values = sheet.get_all_values()
                if len(all_values) > 1:
                    for row in all_values[1:]:
                        if row[0] == 'shjeon': continue
                        c.execute("INSERT OR IGNORE INTO users (id, role, signup_date, pw, expiry_date) VALUES (?, ?, ?, ?, ?)", 
                                  (row[0], row[1], row[2], row[3], '9999-12-31'))
                    conn.commit()
        except Exception:
            pass

    # [ë³µêµ¬ ë¡œì§ 2] ë°©ë¬¸ ë¡œê·¸ ë³µêµ¬
    c.execute("SELECT COUNT(*) FROM visit_logs")
    if c.fetchone()[0] == 0:
        try:
            client = get_gspread_client()
            if client:
                spreadsheet = client.open_by_key(st.secrets["SPREADSHEET_ID"])
                try:
                    visit_sheet = spreadsheet.worksheet("Visit_Logs")
                    records = visit_sheet.get_all_records()
                    for row in records:
                        c.execute("INSERT OR IGNORE INTO visit_logs (ip_address, visit_date) VALUES (?, ?)", 
                                  (row['IP'], row['Date']))
                    conn.commit()
                except gspread.exceptions.WorksheetNotFound:
                    pass
        except Exception:
            pass

    conn.close()
    
    # [ìš”ì²­ì‚¬í•­ 4] ì–´í”Œ ì¬ë¶€íŒ… ì‹œ êµ¬ê¸€ ì‹œíŠ¸ ë‚´ìš©(íšŒì›, ê²Œì‹œê¸€, ëŒ“ê¸€) ë¶ˆëŸ¬ì˜¤ê¸°
    sync_db_from_sheets()

# [ì‹ ê·œ ê¸°ëŠ¥ 1 & ìš”ì²­ì‚¬í•­ 4] êµ¬ê¸€ ì‹œíŠ¸ì˜ ë‚´ìš©ì„ ê°•ì œë¡œ DBì— ë™ê¸°í™”í•˜ëŠ” í•¨ìˆ˜
def sync_db_from_sheets():
    """êµ¬ê¸€ ì‹œíŠ¸ì˜ ë°ì´í„°ë¥¼ ì½ì–´ì™€ DBì— ì—†ëŠ” ë°ì´í„°ë¥¼ ê°•ì œë¡œ ì¶”ê°€í•©ë‹ˆë‹¤. (íšŒì›, ê²Œì‹œê¸€, ëŒ“ê¸€)"""
    try:
        client = get_gspread_client()
        if not client: return -1
        
        spreadsheet = client.open_by_key(st.secrets["SPREADSHEET_ID"])
        conn = sqlite3.connect('users.db')
        c = conn.cursor()
        
        # 1. íšŒì› ì •ë³´ ë™ê¸°í™”
        try:
            sheet = spreadsheet.sheet1
            all_values = sheet.get_all_values()
            if len(all_values) > 1:
                for row in all_values[1:]:
                    if len(row) >= 4:
                        user_id = row[0]
                        role = row[1]
                        signup_date = row[2]
                        pw = row[3]
                        expiry_date = '9999-12-31' 
                        c.execute("INSERT OR IGNORE INTO users (id, pw, role, signup_date, expiry_date) VALUES (?, ?, ?, ?, ?)", 
                                  (user_id, pw, role, signup_date, expiry_date))
        except: pass

        # 2. ê²Œì‹œê¸€ ë™ê¸°í™” (Community_Posts)
        try:
            post_sheet = spreadsheet.worksheet("Community_Posts")
            posts = post_sheet.get_all_values()
            # Header: ID, UserID, Title, Content, RegDate, IsSecret, IsNotice, Likes, NonUserPW, Views
            if len(posts) > 1:
                for row in posts[1:]:
                    if len(row) >= 8: # ìµœì†Œ í•„ë“œ í™•ë³´
                        p_id = row[0]
                        u_id = row[1]
                        ttl = row[2]
                        cnt = row[3]
                        reg = row[4]
                        sec = int(row[5]) if row[5] else 0
                        notc = int(row[6]) if row[6] else 0
                        lks = int(row[7]) if row[7] else 0
                        npw = row[8] if len(row) > 8 else None
                        vws = int(row[9]) if len(row) > 9 and row[9] else 0
                        
                        c.execute("INSERT OR IGNORE INTO community_posts (id, user_id, title, content, reg_date, is_secret, is_notice, likes, non_user_pw, views) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                                  (p_id, u_id, ttl, cnt, reg, sec, notc, lks, npw, vws))
        except gspread.exceptions.WorksheetNotFound:
            pass
            
        # 3. ëŒ“ê¸€ ë™ê¸°í™” (Community_Comments)
        try:
            com_sheet = spreadsheet.worksheet("Community_Comments")
            comments = com_sheet.get_all_values()
            # Header: ID, PostID, UserID, Content, RegDate, IsSecret
            if len(comments) > 1:
                for row in comments[1:]:
                    if len(row) >= 6:
                        c_id = row[0]
                        p_id = row[1]
                        u_id = row[2]
                        cnt = row[3]
                        reg = row[4]
                        sec = int(row[5]) if row[5] else 0
                        c.execute("INSERT OR IGNORE INTO community_comments (id, post_id, user_id, content, reg_date, is_secret) VALUES (?, ?, ?, ?, ?, ?)",
                                  (c_id, p_id, u_id, cnt, reg, sec))
        except gspread.exceptions.WorksheetNotFound:
            pass

        conn.commit()
        conn.close()
        # [ìµœì í™” ì¶”ê°€] ê²Œì‹œíŒ ë°ì´í„° ë³€ê²½ ì‹œ ìºì‹œ ì´ˆê¸°í™”
        st.cache_data.clear()
        return 1
    except Exception:
        return -1

# ë°©ë¬¸ì ì¶”ì  ë° êµ¬ê¸€ ì‹œíŠ¸ ì‹¤ì‹œê°„ ì €ì¥
def track_visitor():
    js_ip_script = 'await fetch("https://api.ipify.org?format=json").then(r => r.json()).then(d => d.ip)'
    client_ip = st_javascript(js_ip_script)
    if not client_ip:
        return 

    ip = str(client_ip).strip()
    
    if st.session_state.get('visited'):
        return

    try:
        now_ts = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).strftime("%Y-%m-%d %H:%M:%S")
        
        country, region, city, lat, lon = "", "", "", "", ""
        if ip not in ["localhost", "unknown_ip", "127.0.0.1"] and not ip.startswith("192.168."):
            try:
                response = requests.get(f"http://ip-api.com/json/{ip}", timeout=5)
                if response.status_code == 200:
                    data = response.json()
                    if data.get("status") == "success":
                        country = data.get("country", "")
                        region = data.get("regionName", "")
                        city = data.get("city", "")
                        lat = data.get("lat", "")
                        lon = data.get("lon", "")
            except:
                pass

        conn = sqlite3.connect('users.db')
        c = conn.cursor()
        c.execute("INSERT OR IGNORE INTO visit_logs (ip_address, visit_date) VALUES (?, ?)", (ip, now_ts))
        conn.commit()
        conn.close()

        try:
            client = get_gspread_client()
            if client:
                spreadsheet = client.open_by_key(st.secrets["SPREADSHEET_ID"])
                try:
                    visit_sheet = spreadsheet.worksheet("Visit_Logs")
                except gspread.exceptions.WorksheetNotFound:
                    visit_sheet = spreadsheet.add_worksheet(title="Visit_Logs", rows="1000", cols="10")
                    visit_sheet.append_row(["IP", "Date", "Country", "Region", "City", "Latitude", "Longitude"])
                
                existing_logs = visit_sheet.get_all_values()
                if [ip, now_ts] not in [row[:2] for row in existing_logs]:
                    # [ìµœì í™” ì¶”ê°€] ë°©ë¬¸ ë¡œê·¸ëŠ” ìŠ¤ë ˆë“œ ì²˜ë¦¬í•˜ì—¬ ì‘ë‹µì„± í–¥ìƒ
                    threading.Thread(target=visit_sheet.append_row, args=([ip, now_ts, country, region, city, lat, lon],)).start()
                
                st.session_state.visited = True
            
        except Exception:
            pass
    except Exception:
        pass

# ë°©ë¬¸ì ì¶”ì  ì‹¤í–‰ë¶€
if 'visited' not in st.session_state:
    st.session_state.visited = False
track_visitor()

def validate_email(email):
    return re.match(r"[^@]+@[^@]+\.[^@]+", email)

def validate_password(password):
    if len(password) < 4: return False
    has_char = re.search(r'[a-zA-Z]', password)
    has_special = re.search(r'[!@#$%^&*(),.?":{}|<>]', password)
    return has_char and has_special

def send_application_email(user_email):
    sender_email = "jeon080423@gmail.com"
    password = "csuh xxru wqdy mttt"
    recipient_email = "jeon080423@gmail.com"
    subject = f"[AHP ë§ˆìŠ¤í„°] ì •ì‹ ì‚¬ìš©ì ìŠ¹ì¸ ìš”ì²­: {user_email}"
    kst_today = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).date()
    body = f"ì‚¬ìš©ìê°€ ì •ì‹ ê¶Œí•œ ì‹ ì²­.\nID: {user_email}\nì‹ ì²­ì¼: {kst_today}"
    msg = MIMEText(body)
    msg['Subject'] = subject
    msg['From'] = sender_email
    msg['To'] = recipient_email
    try:
        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:
            server.login(sender_email, password)
            server.sendmail(sender_email, recipient_email, msg.as_string())
    except: pass

def send_conversion_request_email(user_email):
    sender_email = "jeon080423@gmail.com"
    password = "csuh xxru wqdy mttt"
    recipient_email = "jeon080423@gmail.com"
    subject = f"[AHP ë§ˆìŠ¤í„°] ì •ì‹ì‚¬ìš©ì ì „í™˜ ìš”ì²­: {user_email}"
    body = f"ì„ì‹œ ì‚¬ìš©ìê°€ ì •ì‹ì‚¬ìš©ìë¡œ ì „í™˜ ìš”ì²­ í–ˆìŠµë‹ˆë‹¤\nID: {user_email}"
    msg = MIMEText(body)
    msg['Subject'] = subject
    msg['From'] = sender_email
    msg['To'] = recipient_email
    try:
        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:
            server.login(sender_email, password)
            server.sendmail(sender_email, recipient_email, msg.as_string())
        return True
    except: return False

def send_approval_email(user_email):
    sender_email = "jeon080423@gmail.com"
    password = "csuh xxru wqdy mttt"
    recipient_email = user_email
    subject = "[AHP ë§ˆìŠ¤í„°] ì •ì‹ ì‚¬ìš©ì ìŠ¹ì¸ ì™„ë£Œ"
    body = f"{user_email}ë‹˜, ì •ì‹ ì‚¬ìš©ìë¡œ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ë¶€í„° 2ê°œì›”ê°„ ëª¨ë“  ê¸°ëŠ¥ì„ ë¬´ì œí•œìœ¼ë¡œ ì‚¬ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    msg = MIMEText(body)
    msg['Subject'] = subject
    msg['From'] = sender_email
    msg['To'] = recipient_email
    try:
        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:
            server.login(sender_email, password)
            server.sendmail(sender_email, recipient_email, msg.as_string())
        return True
    except: return False

def send_password_recovery_email(user_email, user_pw):
    sender_email = "jeon080423@gmail.com"
    password = "csuh xxru wqdy mttt"
    recipient_email = user_email
    subject = "[AHP ë§ˆìŠ¤í„°] ë¹„ë°€ë²ˆí˜¸ ì•ˆë‚´"
    body = f"""ì•ˆë…•í•˜ì„¸ìš”. ìš”ì²­í•˜ì‹  ê³„ì • ì •ë³´ë¥¼ ì•ˆë‚´í•´ ë“œë¦½ë‹ˆë‹¤.

ID: {user_email}
PW: {user_pw}

ë¡œê·¸ì¸ í›„ ë¹„ë°€ë²ˆí˜¸ë¥¼ ë³€ê²½í•˜ì‹œê¸°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.
ê°ì‚¬í•©ë‹ˆë‹¤.
"""
    msg = MIMEText(body)
    msg['Subject'] = subject
    msg['From'] = sender_email
    msg['To'] = recipient_email
    try:
        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:
            server.login(sender_email, password)
            server.sendmail(sender_email, recipient_email, msg.as_string())
        return True
    except Exception:
        return False

# --- DB CRUD ---

def log_to_sheets(user_id, role, signup_date, pw, agree_info="ë¯¸ë™ì˜"):
    try:
        client = get_gspread_client()
        if client:
            spreadsheet = client.open_by_key(st.secrets["SPREADSHEET_ID"])
            sheet = spreadsheet.sheet1
            
            headers = sheet.row_values(1)
            if "agree_info" not in headers:
                sheet.update_cell(1, 5, "agree_info")
            if "expiry_date" not in headers:
                sheet.update_cell(1, 6, "expiry_date")

            sheet.append_row([user_id, role, str(signup_date), pw, agree_info, "9999-12-31"])
    except Exception as e:
        st.error(f"Google Sheets ë¡œê¹… ì˜¤ë¥˜: {e}")

def add_user(user_id, pw, role, agree_info="ë¯¸ë™ì˜"):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    signup_date = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).strftime("%Y-%m-%d")
    expiry_date = "9999-12-31"
    try:
        c.execute("INSERT INTO users VALUES (?, ?, ?, ?, ?)", 
                  (user_id, pw, role, signup_date, expiry_date))
        conn.commit()
        log_to_sheets(user_id, role, signup_date, pw, agree_info)
        success = True
    except sqlite3.IntegrityError:
        success = False
    finally:
        conn.close()
    return success

def check_login(user_id, pw):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("SELECT role, expiry_date FROM users WHERE id=? AND pw=?", (user_id, pw))
    result = c.fetchone()
    conn.close()
    return result

def get_user_password(user_id):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("SELECT pw FROM users WHERE id=?", (user_id,))
    result = c.fetchone()
    conn.close()
    return result[0] if result else None

def change_user_password(user_id, new_pw):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("UPDATE users SET pw=? WHERE id=?", (new_pw, user_id))
    conn.commit()
    conn.close()

    try:
        client = get_gspread_client()
        if client:
            spreadsheet = client.open_by_key(st.secrets["SPREADSHEET_ID"])
            sheet = spreadsheet.sheet1
            cell = sheet.find(user_id)
            if cell:
                sheet.update_cell(cell.row, 4, new_pw)
    except Exception:
        pass
    return True

def get_all_users():
    conn = sqlite3.connect('users.db')
    df = pd.read_sql_query("SELECT * FROM users", conn)
    conn.close()
    return df

def update_user_full_info(user_id, new_pw, new_role, new_expiry):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    if new_pw is not None and new_pw != "":
        c.execute("UPDATE users SET pw=?, role=?, expiry_date=? WHERE id=?", (new_pw, new_role, new_expiry, user_id))
    else:
        c.execute("UPDATE users SET role=?, expiry_date=? WHERE id=?", (new_role, new_expiry, user_id))
    conn.commit()
    conn.close()
    
    try:
        client = get_gspread_client()
        if client:
            spreadsheet = client.open_by_key(st.secrets["SPREADSHEET_ID"])
            sheet = spreadsheet.sheet1
            
            headers = sheet.row_values(1)
            if "expiry_date" not in headers:
                sheet.update_cell(1, 6, "expiry_date")

            cell = sheet.find(user_id)
            if cell:
                row_num = cell.row
                sheet.update_cell(row_num, 2, new_role)
                sheet.update_cell(row_num, 6, new_expiry)
                if new_pw is not None and new_pw != "":
                    sheet.update_cell(row_num, 4, new_pw)
    except Exception:
        pass 

def delete_user(user_id):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("DELETE FROM users WHERE id=?", (user_id,))
    c.execute("DELETE FROM saved_analyses WHERE user_id=?", (user_id,))
    c.execute("DELETE FROM user_models WHERE user_id=?", (user_id,))
    conn.commit()
    conn.close()

    try:
        client = get_gspread_client()
        if client:
            spreadsheet = client.open_by_key(st.secrets["SPREADSHEET_ID"])
            sheet = spreadsheet.sheet1
            
            try:
                del_sheet = spreadsheet.worksheet("Deleted_Users")
            except gspread.exceptions.WorksheetNotFound:
                del_sheet = spreadsheet.add_worksheet(title="Deleted_Users", rows="1000", cols="10")
                del_sheet.append_row(["ID", "Role", "SignupDate", "PW", "DeletedDate"])

            all_values = sheet.get_all_values()
            target_row_index = -1
            row_data = []
            for i, row in enumerate(all_values):
                if row[0] == user_id:
                    target_row_index = i + 1
                    row_data = row
                    break
            
            if target_row_index != -1:
                kst_now_ts = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).strftime("%Y-%m-%d %H:%M:%S")
                row_data.append(str(kst_now_ts))
                del_sheet.append_row(row_data)
                sheet.delete_rows(target_row_index)
    except Exception:
        pass

def restore_from_deleted_sheet(user_id):
    try:
        client = get_gspread_client()
        if client:
            spreadsheet = client.open_by_key(st.secrets["SPREADSHEET_ID"])
            try:
                del_sheet = spreadsheet.worksheet("Deleted_Users")
                cell = del_sheet.find(user_id)
                if cell:
                    del_sheet.delete_rows(cell.row)
            except (gspread.exceptions.WorksheetNotFound, gspread.exceptions.CellNotFound):
                pass
    except Exception:
        pass

def save_analysis_to_db(user_id, filename, file_data):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    save_date = str(datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).strftime("%Y-%m-%d %H:%M:%S"))
    c.execute("INSERT INTO saved_analyses (user_id, filename, save_date, file_data) VALUES (?, ?, ?, ?)",
              (user_id, filename, save_date, file_data))
    conn.commit()
    conn.close()

def get_user_analyses(user_id):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("SELECT id, filename, save_date FROM saved_analyses WHERE user_id=? ORDER BY save_date DESC", (user_id,))
    rows = c.fetchall()
    conn.close()
    return rows

def get_analysis_file(analysis_id):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("SELECT filename, file_data FROM saved_analyses WHERE id=?", (analysis_id,))
    result = c.fetchone()
    conn.close()
    return result

def delete_analysis(analysis_id):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("DELETE FROM saved_analyses WHERE id=?", (analysis_id,))
    conn.commit()
    conn.close()

def save_user_model(user_id, model_dict):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    model_json = json.dumps(model_dict, ensure_ascii=False)
    c.execute("INSERT OR REPLACE INTO user_models (user_id, model_data) VALUES (?, ?)", (user_id, model_json))
    conn.commit()
    conn.close()

def load_user_model(user_id):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("SELECT model_data FROM user_models WHERE user_id=?", (user_id,))
    result = c.fetchone()
    conn.close()
    if result:
        return json.loads(result[0])
    return None

# -----------------------------------------------------------------------------
# Saaty(1980) AHP Functions
# -----------------------------------------------------------------------------
def get_ri(n):
    ri_dict = {1: 0.00, 2: 0.00, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45, 10: 1.49}
    return ri_dict.get(n, 1.49)

def calculate_weights(matrix, method='geometric'):
    if method == 'arithmetic':
        col_sum = matrix.sum(axis=0)
        col_sum[col_sum == 0] = 1
        normalized_matrix = matrix / col_sum
        weights = normalized_matrix.mean(axis=1)
    else:
        geom_means = gmean(matrix, axis=1)
        weights = geom_means / geom_means.sum()
    return weights

def calculate_consistency(matrix, method='geometric'):
    n = matrix.shape[0]
    if n <= 2: return 0.0, 0.0, n
    weights = calculate_weights(matrix, method)
    weighted_sum = matrix.dot(weights)
    weights_safe = weights.copy()
    weights_safe[weights_safe == 0] = 1e-10
    lambda_values = weighted_sum / weights_safe
    lambda_max = lambda_values.mean()
    ci = (lambda_max - n) / (n - 1)
    ri = get_ri(n)
    cr = ci / ri if ri > 0 else 0.0
    return cr, ci, lambda_max

def improve_consistency(matrix, threshold, min_val, max_val, max_iter=500, learning_rate=0.4, method='geometric', allow_even=False):
    current_matrix = matrix.copy()
    n = current_matrix.shape[0]
    cr, ci, _ = calculate_consistency(current_matrix, method)
    iterations = 0
    if cr <= threshold: return current_matrix, cr, iterations, False
    
    triu_indices = np.triu_indices(n, k=1)
    
    for it in range(max_iter):
        if cr <= threshold: break
        
        w = calculate_weights(current_matrix, method)
        consistent_matrix = np.outer(w, 1/w)
        
        new_matrix = (current_matrix * (1 - learning_rate)) + (consistent_matrix * learning_rate)
        np.fill_diagonal(new_matrix, 1.0)
        
        vals = new_matrix[triu_indices]
        
        temp_raw = np.where(vals == 1.0, 1.0, 
                   np.where(vals > 1.0, -np.round(vals), 
                   np.round(1.0/vals)))
        
        temp_raw = np.clip(temp_raw, min_val, max_val)
        
        abs_raw = np.abs(temp_raw)
        signs = np.sign(temp_raw)
        
        if not allow_even:
            abs_raw = np.where((abs_raw % 2 == 0) & (abs_raw != 0), np.maximum(1, abs_raw - 1), abs_raw)
            
        temp_raw = np.where(temp_raw == 0, 1, (signs * abs_raw)).astype(int)
        
        final_vals = np.where(temp_raw == 0, 1.0,
                     np.where(temp_raw < 0, np.abs(temp_raw).astype(float),
                     np.where(temp_raw == 1, 1.0, 1.0 / temp_raw)))
        
        new_matrix[triu_indices] = final_vals
        new_matrix.T[triu_indices] = 1.0 / final_vals
        
        current_matrix = new_matrix
        cr, ci, _ = calculate_consistency(current_matrix, method)
        iterations += 1
        
    was_corrected = iterations > 0
    return current_matrix, cr, iterations, was_corrected

def parse_input_value(val):
    if val == 0: return 1.0
    elif val < 0: return abs(val)
    elif val == 1: return 1.0
    else: return 1.0 / val

def infer_factors_from_columns(cols):
    m = len(cols)
    delta = 1 + 8 * m
    n = int((1 + np.sqrt(delta)) / 2)
    extracted_factors = []
    seen = set()
    for c in cols:
        parts = str(c).split('_')
        for p in parts:
            p_str = p.strip()
            if p_str not in seen:
                seen.add(p_str)
                extracted_factors.append(p_str)
    if len(extracted_factors) == n:
        factors = extracted_factors 
    else:
        factors = [f"F{i+1}" for i in range(n)]
    return factors, n

def calculate_pairwise_ttest(df, factors):
    n = len(factors)
    p_values = pd.DataFrame(index=factors, columns=factors)
    weight_cols = [f"Weight_{f}" for f in factors]
    for i in range(n):
        for j in range(n):
            if i == j:
                p_values.iloc[i, j] = 1.0
            else:
                col1 = weight_cols[i]
                col2 = weight_cols[j]
                if col1 in df.columns and col2 in df.columns and len(df) > 1:
                    try:
                        _, p = ttest_rel(df[col1], df[col2], nan_policy='omit')
                        p_values.iloc[i, j] = p
                    except:
                        p_values.iloc[i, j] = np.nan
                else:
                    p_values.iloc[i, j] = np.nan
    return p_values

def process_single_sheet(df, cr_threshold, max_iter, method='geometric'):
    meta_cols = df.columns[:2]
    comp_cols = df.columns[2:]
    factors, n = infer_factors_from_columns(comp_cols)
    
    all_comp_values = df[comp_cols].values.flatten()
    sheet_min = int(np.min(all_comp_values))
    sheet_max = int(np.max(all_comp_values))
    
    has_even = np.any((np.abs(all_comp_values) % 2 == 0) & (np.abs(all_comp_values) > 1))
    
    results_list = []
    excluded_list = []
    excluded_count = 0
    for idx, row in df.iterrows():
        respondent_id = row.iloc[0]
        respondent_type = row.iloc[1]
        matrix = np.eye(n)
        
        raw_values = []
        col_idx = 0
        for i in range(n):
            for j in range(i + 1, n):
                if col_idx < len(comp_cols):
                    raw_val = row[comp_cols[col_idx]]
                    raw_values.append(raw_val)
                    ahp_val = parse_input_value(raw_val)
                    matrix[i, j] = ahp_val
                    matrix[j, i] = 1.0 / ahp_val
                    col_idx += 1
        
        orig_cr, orig_ci, _ = calculate_consistency(matrix, method)
        final_matrix = matrix.copy()
        final_cr = orig_cr
        iterations = 0
        corrected_flag = False
        if orig_cr > cr_threshold:
            final_matrix, final_cr, iterations, corrected_flag = improve_consistency(
                matrix, cr_threshold, sheet_min, sheet_max, max_iter=max_iter, method=method, allow_even=has_even
            )
        
        if final_cr > cr_threshold:
            excluded_count += 1
            ex_res = {"ID": respondent_id, "Type": respondent_type}
            for k, col_name in enumerate(comp_cols):
                ex_res[col_name] = raw_values[k]
            ex_res["CR"] = final_cr
            excluded_list.append(ex_res)
            continue

        final_raw_values = []
        for i in range(n):
            for j in range(i + 1, n):
                val = final_matrix[i, j]
                if val == 1.0: final_raw_val = 1
                elif val > 1.0: final_raw_val = -int(round(val)) 
                else: final_raw_val = int(round(1.0/val)) 
                final_raw_values.append(final_raw_val)

        _, final_ci, _ = calculate_consistency(final_matrix, method)
        final_weights = calculate_weights(final_matrix, method)
        
        res = {
            "ID": respondent_id,
            "Type": respondent_type
        }
        
        for k, col_name in enumerate(comp_cols):
            res[f"Raw_Orig_{col_name}"] = raw_values[k]
        
        res["Original_CI"] = orig_ci
        res["Original_CR"] = orig_cr
        
        for k, col_name in enumerate(comp_cols):
            res[f"Raw_Final_{col_name}"] = final_raw_values[k]
            
        res["Final_CI"] = final_ci
        res["Final_CR"] = final_cr
        
        res["Iterations"] = iterations
        res["Corrected"] = corrected_flag
        res["Matrix_Object"] = final_matrix 
        
        for f_idx, f_name in enumerate(factors):
            res[f"Weight_{f_name}"] = final_weights[f_idx]
            
        results_list.append(res)
        
    results_df = pd.DataFrame(results_list)
    excluded_df = pd.DataFrame(excluded_list)
    return results_df, factors, excluded_count, excluded_df

def create_sample_excel():
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        main_cols = ["ID", "Type", "ê±°ë²„ë„ŒìŠ¤_ê³„íšíƒ€ë‹¹ì„±", "ê±°ë²„ë„ŒìŠ¤_ì‹¤í˜„ê°€ëŠ¥ì„±", "ê±°ë²„ë„ŒìŠ¤_ì‚¬ì—…íš¨ê³¼", 
                      "ê³„íšíƒ€ë‹¹ì„±_ì‹¤í˜„ê°€ëŠ¥ì„±", "ê³„íšíƒ€ë‹¹ì„±_ì‚¬ì—…íš¨ê³¼", "ì‹¤í˜„ê°€ëŠ¥ì„±_ì‚¬ì—…íš¨ê³¼"]
        main_data = [
            [1, "ì „ë¬¸ê°€", 5, -5, 5, 5, -5, 5],               
            [2, "ì „ë¬¸ê°€", 7, 7, -7, -7, 2, -2],       
            [3, "ì¼ë°˜", -5, 5, 5, -5, 5, 5],
            [4, "ì¼ë°˜", 3, -3, 3, -3, 3, -3],
            [5, "ê³µë¬´ì›", 9, -9, 9, -9, 9, -9]
        ]
        df_main = pd.DataFrame(main_data, columns=main_cols)
        df_main.to_excel(writer, sheet_name="Main_Criteria", index=False)
        
        inconsistent_pattern = [
            [1, "ì „ë¬¸ê°€", 5, -5, 5],
            [2, "ì „ë¬¸ê°€", 7, -7, 7],
            [3, "ì¼ë°˜", 3, -3, 3],
            [4, "ì¼ë°˜", 9, -9, 9],
            [5, "ê³µë¬´ì›", 4, -4, 4]
        ]
        sub1_cols = ["ID", "Type", "í–‰ì •ì§€ì›_ì§€ì—­ê³µë™ì²´", "í–‰ì •ì§€ì›_ì´ê´„ì‚¬ì—…ê´€ë¦¬ì", "ì§€ì—­ê³µë™ì²´_ì´ê´„ì‚¬ì—…ê´€ë¦¬ì"]
        pd.DataFrame(inconsistent_pattern, columns=sub1_cols).to_excel(writer, sheet_name="ê±°ë²„ë„ŒìŠ¤", index=False)
        sub2_cols = ["ID", "Type", "í˜„ì•ˆì ì •ì„±_ëŒ€ì•ˆì ì •ì„±", "í˜„ì•ˆì ì •ì„±_ëª©í‘œêµ¬ì²´ì„±", "ëŒ€ì•ˆì ì •ì„±_ëª©í‘œêµ¬ì²´ì„±"]
        pd.DataFrame(inconsistent_pattern, columns=sub2_cols).to_excel(writer, sheet_name="ê³„íšíƒ€ë‹¹ì„±", index=False)
        sub3_cols = ["ID", "Type", "ë¶€ì§€í™•ë³´_ì‚¬ì—…êµ¬ì²´í™”", "ë¶€ì§€í™•ë³´_ì‚¬ì—…ë¹„ì ì •ì„±", "ì‚¬ì—…êµ¬ì²´í™”_ì‚¬ì—…ë¹„ì ì •ì„±"]
        pd.DataFrame(inconsistent_pattern, columns=sub3_cols).to_excel(writer, sheet_name="ì‹¤í˜„ê°€ëŠ¥ì„±", index=False)
        sub4_cols = ["ID", "Type", "ê²½ì œì íš¨ê³¼_ì‚¬íšŒì íš¨ê³¼", "ê²½ì œì íš¨ê³¼_ì„±ê³¼ê´€ë¦¬", "ì‚¬íšŒì íš¨ê³¼_ì„±ê³¼ê´€ë¦¬"]
        pd.DataFrame(inconsistent_pattern, columns=sub4_cols).to_excel(writer, sheet_name="ì‚¬ì—…íš¨ê³¼", index=False)
    output.seek(0)
    return output

def calculate_anova_and_posthoc(full_data):
    results = []
    unique_factors = full_data['Factor'].unique()
    
    for factor in unique_factors:
        subset = full_data[full_data['Factor'] == factor]
        groups = [group['Global_Weight'].values for name, group in subset.groupby('Type')]
        
        if len(groups) < 2:
            continue
            
        f_stat, p_val = f_oneway(*groups)
        
        row = {
            "ìš”ì¸": factor,
            "F-ê°’": f_stat,
            "P-Value": p_val,
            "ìœ ì˜ì„±": "ìœ ì˜í•¨" if p_val < 0.05 else "ìœ ì˜í•˜ì§€ ì•ŠìŒ",
            "ì‚¬í›„ê²€ì •(Tukey HSD)": ""
        }
        
        if p_val < 0.05 and STATSMODELS_AVAILABLE:
            try:
                tukey = pairwise_tukeyhsd(endog=subset['Global_Weight'], groups=subset['Type'], alpha=0.05)
                tukey_df = pd.DataFrame(data=tukey.summary().data[1:], columns=tukey.summary().data[0])
                sig_pairs = tukey_df[tukey_df['reject'] == True]
                if not sig_pairs.empty:
                    pairs_str = []
                    for _, r in sig_pairs.iterrows():
                        pairs_str.append(f"{r['group1']} vs {r['group2']}")
                    row["ì‚¬í›„ê²€ì •(Tukey HSD)"] = ", ".join(pairs_str) + " ì°¨ì´ ìˆìŒ"
                else:
                    row["ì‚¬í›„ê²€ì •(Tukey HSD)"] = "ì§‘ë‹¨ ê°„ êµ¬ì²´ì  ì°¨ì´ ë°œê²¬ ëª»í•¨"
            except Exception:
                row["ì‚¬í›„ê²€ì •(Tukey HSD)"] = "ê³„ì‚° ì˜¤ë¥˜"
        
        results.append(row)
        
    return pd.DataFrame(results)

# -----------------------------------------------------------------------------
# [ì‹ ê·œ] ì»¤ë®¤ë‹ˆí‹° ë°ì´í„°ë² ì´ìŠ¤ ë° UI ë¡œì§ (êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ í¬í•¨)
# -----------------------------------------------------------------------------

def log_community_to_sheets(sheet_name, data):
    try:
        client = get_gspread_client()
        if client:
            spreadsheet = client.open_by_key(st.secrets["SPREADSHEET_ID"])
            try:
                work_sheet = spreadsheet.worksheet(sheet_name)
            except gspread.exceptions.WorksheetNotFound:
                if sheet_name == "Community_Posts":
                    work_sheet = spreadsheet.add_worksheet(title="Community_Posts", rows="1000", cols="10")
                    work_sheet.append_row(["ID", "UserID", "Title", "Content", "RegDate", "IsSecret", "IsNotice", "Likes", "NonUserPW", "Views"])
                else:
                    work_sheet = spreadsheet.add_worksheet(title="Community_Comments", rows="1000", cols="10")
                    work_sheet.append_row(["ID", "PostID", "UserID", "Content", "RegDate", "IsSecret"])
            
            # [ìš”ì²­ì‚¬í•­ 1] í—¤ë” ìœ ë¬´ í™•ì¸ ë° ê°•ì œ ê¸°ë¡ (ë°ì´í„° ê¼¬ì„ ë°©ì§€)
            if sheet_name == "Community_Posts":
                if not work_sheet.row_values(1):
                    work_sheet.append_row(["ID", "UserID", "Title", "Content", "RegDate", "IsSecret", "IsNotice", "Likes", "NonUserPW", "Views"])
            
            if isinstance(data, list): 
                # [ìµœì í™” ì¶”ê°€] ì‹œíŠ¸ ì €ì¥ì„ ë¹„ë™ê¸° ì²˜ë¦¬í•˜ì—¬ ê²Œì‹œíŒ ì‘ë‹µ ì†ë„ í–¥ìƒ
                threading.Thread(target=work_sheet.append_row, args=(data,)).start()
    except Exception:
        pass

# [ìµœì í™” ì¶”ê°€] ê²Œì‹œíŒ ëª©ë¡ ì½ê¸° ë¡œì§ ìºì‹± ì ìš©
@st.cache_data(show_spinner=False)
def get_posts():
    conn = sqlite3.connect('users.db')
    df = pd.read_sql_query("SELECT * FROM community_posts ORDER BY is_notice DESC, id DESC", conn)
    conn.close()
    return df

# [ìš”ì²­ì‚¬í•­ 3] ì¡°íšŒìˆ˜ ì¦ê°€ ë° êµ¬ê¸€ ì‹œíŠ¸ ê¸°ë¡ í•¨ìˆ˜
def increment_views(pid):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("UPDATE community_posts SET views = views + 1 WHERE id=?", (pid,))
    conn.commit()
    
    # ê°±ì‹ ëœ ì¡°íšŒìˆ˜ ê°€ì ¸ì˜¤ê¸°
    c.execute("SELECT views FROM community_posts WHERE id=?", (pid,))
    new_views = c.fetchone()[0]
    conn.close()
    
    # [ìš”ì²­ì‚¬í•­ 1 & 3] êµ¬ê¸€ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ë°ì´í„°ì— ë§ì“°ì§€ ì•Šê³  í–‰ ì—…ë°ì´íŠ¸)
    try:
        client = get_gspread_client()
        if client:
            spreadsheet = client.open_by_key(st.secrets["SPREADSHEET_ID"])
            sheet = spreadsheet.worksheet("Community_Posts")
            cell = sheet.find(str(pid))
            if cell:
                # ViewsëŠ” Jì—´(10ë²ˆì§¸ ì—´)ì— ìœ„ì¹˜í•œë‹¤ê³  ê°€ì • (í—¤ë” ìˆœì„œ ê¸°ë°˜)
                # [ìµœì í™” ì¶”ê°€] ë¹„ë™ê¸° ì—…ë°ì´íŠ¸
                threading.Thread(target=sheet.update_cell, args=(cell.row, 10, new_views)).start()
    except: pass
    
    # [ìµœì í™” ì¶”ê°€] ì¡°íšŒìˆ˜ ë³€ê²½ ì‹œ ìºì‹œ ë¬´íš¨í™”
    st.cache_data.clear()

def add_post(uid, title, content, is_secret, is_notice, non_user_pw=None):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).strftime("%Y-%m-%d %H:%M:%S")
    c.execute("INSERT INTO community_posts (user_id, title, content, reg_date, is_secret, is_notice, non_user_pw, views) VALUES (?, ?, ?, ?, ?, ?, ?, ?)",
              (uid, title, content, now, 1 if is_secret else 0, 1 if is_notice else 0, non_user_pw, 0))
    post_id = c.lastrowid
    conn.commit()
    conn.close()
    
    # [ìš”ì²­ì‚¬í•­ 1] êµ¬ê¸€ ì‹œíŠ¸ì— ìƒˆ í–‰ìœ¼ë¡œ ì¶”ê°€ (append_row ì‚¬ìš©ìœ¼ë¡œ ê¸°ì¡´ ë°ì´í„° ë³´ì¡´, ì •í™•í•œ ì»¬ëŸ¼ ë§¤í•‘)
    log_community_to_sheets("Community_Posts", [post_id, uid, title, content, now, 1 if is_secret else 0, 1 if is_notice else 0, 0, non_user_pw, 0])
    
    # [ìµœì í™” ì¶”ê°€] ë°ì´í„° ì¶”ê°€ ì‹œ ìºì‹œ ë¬´íš¨í™”
    st.cache_data.clear()

def update_post(pid, title, content, is_secret, is_notice):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("UPDATE community_posts SET title=?, content=?, is_secret=?, is_notice=? WHERE id=?", 
              (title, content, 1 if is_secret else 0, 1 if is_notice else 0, pid))
    conn.commit()
    conn.close()
    
    try:
        client = get_gspread_client()
        if client:
            spreadsheet = client.open_by_key(st.secrets["SPREADSHEET_ID"])
            sheet = spreadsheet.worksheet("Community_Posts")
            cell = sheet.find(str(pid))
            if cell:
                # ë§ì“°ì§€ ì•Šê³  íŠ¹ì • ì—´ ë²”ìœ„ë§Œ ì—…ë°ì´íŠ¸ (C:Title ~ G:IsNotice)
                # [ìµœì í™” ì¶”ê°€] ë¹„ë™ê¸° ì²˜ë¦¬
                threading.Thread(target=sheet.update, kwargs={"range_name": f'C{cell.row}:G{cell.row}', "values": [[title, content, "", 1 if is_secret else 0, 1 if is_notice else 0]]}).start()
    except: pass
    
    # [ìµœì í™” ì¶”ê°€] ìºì‹œ ë¬´íš¨í™”
    st.cache_data.clear()

def delete_post(pid):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("DELETE FROM community_posts WHERE id=?", (pid,))
    c.execute("DELETE FROM community_comments WHERE post_id=?", (pid,))
    conn.commit()
    conn.close()
    
    try:
        client = get_gspread_client()
        if client:
            spreadsheet = client.open_by_key(st.secrets["SPREADSHEET_ID"])
            sheet = spreadsheet.worksheet("Community_Posts")
            cell = sheet.find(str(pid))
            if cell: 
                # [ìµœì í™” ì¶”ê°€] ë¹„ë™ê¸° ì‚­ì œ
                threading.Thread(target=sheet.delete_rows, args=(cell.row,)).start()
    except: pass
    
    # [ìµœì í™” ì¶”ê°€] ìºì‹œ ë¬´íš¨í™”
    st.cache_data.clear()

# [ìµœì í™” ì¶”ê°€] ëŒ“ê¸€ ì½ê¸° ìºì‹± ì ìš©
@st.cache_data(show_spinner=False)
def get_comments(pid):
    conn = sqlite3.connect('users.db')
    df = pd.read_sql_query(f"SELECT * FROM community_comments WHERE post_id={pid} ORDER BY id ASC", conn)
    conn.close()
    return df

def add_comment(pid, uid, content, is_secret):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).strftime("%Y-%m-%d %H:%M:%S")
    c.execute("INSERT INTO community_comments (post_id, user_id, content, reg_date, is_secret) VALUES (?, ?, ?, ?, ?)",
              (pid, uid, content, now, 1 if is_secret else 0))
    com_id = c.lastrowid
    conn.commit()
    conn.close()
    log_community_to_sheets("Community_Comments", [com_id, pid, uid, content, now, 1 if is_secret else 0])
    
    # [ìµœì í™” ì¶”ê°€] ìºì‹œ ë¬´íš¨í™”
    st.cache_data.clear()

def like_post(pid):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("UPDATE community_posts SET likes = likes + 1 WHERE id=?", (pid,))
    conn.commit()
    conn.close()
    
    try:
        client = get_gspread_client()
        if client:
            spreadsheet = client.open_by_key(st.secrets["SPREADSHEET_ID"])
            sheet = spreadsheet.worksheet("Community_Posts")
            cell = sheet.find(str(pid))
            if cell:
                curr_likes = sheet.cell(cell.row, 8).value
                # [ìµœì í™” ì¶”ê°€] ë¹„ë™ê¸° ì²˜ë¦¬
                threading.Thread(target=sheet.update_cell, args=(cell.row, 8, int(curr_likes or 0) + 1)).start()
    except: pass
    
    # [ìµœì í™” ì¶”ê°€] ìºì‹œ ë¬´íš¨í™”
    st.cache_data.clear()

# [ìš”ì²­ì‚¬í•­ 2] ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œíŒ UI ìˆ˜ì • (ì´ë¯¸ì§€ í˜•íƒœì˜ ëª©ë¡í˜• -> í´ë¦­ ì‹œ ë‚´ìš© í‘œì‹œ)
def show_community_board():
    st.header("ğŸ’¬ ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œíŒ")
    if st.button("â¬…ï¸ ë¶„ì„ ì‹œìŠ¤í…œìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        st.session_state.page = "main"
        st.rerun()

    posts = get_posts()
    tab_list, tab_write = st.tabs(["ê¸€ ëª©ë¡", "ğŸ–‹ï¸ ê¸€ ì“°ê¸°"])

    with tab_list:
        if posts.empty:
            st.info("ë“±ë¡ëœ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # [ìš”ì²­ì‚¬í•­ 2] í‘œ í˜•ì‹ í—¤ë” (ë²ˆí˜¸, ì œëª©, ì´ë¦„, ë‚ ì§œ, ì¡°íšŒ, ì¶”ì²œ, ëŒ“ê¸€) - ëŒ“ê¸€ ì¶”ê°€
            # ë ˆì´ì•„ì›ƒ ë¹„ìœ¨ ì„¤ì •
            h_col1, h_col2, h_col3, h_col4, h_col5, h_col6, h_col7 = st.columns([0.8, 5, 1.5, 1.5, 0.8, 0.8, 0.8])
            h_col1.markdown("**ë²ˆí˜¸**")
            h_col2.markdown("**ì œëª©**")
            h_col3.markdown("**ì´ë¦„**")
            h_col4.markdown("**ë‚ ì§œ**")
            h_col5.markdown("**ì¡°íšŒ**")
            h_col6.markdown("**ì¶”ì²œ**")
            h_col7.markdown("**ëŒ“ê¸€**")
            st.divider()

            # [ìš”ì²­ì‚¬í•­ 2] ê²Œì‹œê¸€ ëª©ë¡ ì¶œë ¥
            for _, row in posts.iterrows():
                c1, c2, c3, c4, c5, c6, c7 = st.columns([0.8, 5, 1.5, 1.5, 0.8, 0.8, 0.8])
                
                # 1. ë²ˆí˜¸ (ê³µì§€ì‚¬í•­ì€ 'ê³µì§€'ë¡œ í‘œì‹œ, ì¼ë°˜ê¸€ì€ ID í‘œì‹œ)
                # [ìš”ì²­ì‚¬í•­ 2] ê³µì§€ì‚¬í•­ í•‘í¬ìƒ‰ ë°•ìŠ¤ ë° ì¤‘ì•™ ì •ë ¬
                if row['is_notice']:
                    c1.markdown('<div style="background-color:#FFEBEE; color:#D32F2F; padding:2px 5px; border-radius:5px; font-weight:bold; text-align:center; font-size:0.8rem;">ê³µì§€</div>', unsafe_allow_html=True)
                else:
                    c1.markdown(f'<div style="text-align:center; font-size:0.9rem;">{row["id"]}</div>', unsafe_allow_html=True)
                
                # 2. ì œëª© (í´ë¦­ ê°€ëŠ¥í•œ ë²„íŠ¼ìœ¼ë¡œ êµ¬í˜„í•˜ì—¬ ë‚´ìš© í† ê¸€)
                # [ìš”ì²­ì‚¬í•­ 3] íšŒìƒ‰ ë°•ìŠ¤(ë²„íŠ¼) ë„ˆë¹„ ì¼ì •í•˜ê²Œ ê³ ì • -> use_container_width=True
                title_text = f"{'ğŸ”’ ' if row['is_secret'] else ''}{row['title']}"
                # í´ë¦­ ì‹œ í•´ë‹¹ ê¸€ì˜ IDë¥¼ active_post_id ì„¸ì…˜ì— ì €ì¥
                if c2.button(title_text, key=f"btn_title_{row['id']}", use_container_width=True):
                    if st.session_state.get('active_post_id') == row['id']:
                        st.session_state.active_post_id = None # ì´ë¯¸ ì—´ë ¤ìˆìœ¼ë©´ ë‹«ê¸°
                    else:
                        st.session_state.active_post_id = row['id']
                        increment_views(row['id']) # ì¡°íšŒìˆ˜ ì¦ê°€
                    st.rerun()
                
                # 3. ì´ë¦„ (ë§ˆìŠ¤í‚¹ ì²˜ë¦¬)
                author_id = row['user_id']
                display_author = author_id[:3] + "*" * (len(author_id.split('@')[0]) - 3) if '@' in author_id and len(author_id.split('@')[0]) > 3 else author_id[:3] + "***"
                c3.markdown(f'<div style="text-align:center; font-size:0.9rem;">{display_author}</div>', unsafe_allow_html=True)
                
                # 4. ë‚ ì§œ (YYYY-MM-DD í˜•ì‹ë§Œ í‘œì‹œ)
                c4.markdown(f'<div style="text-align:center; font-size:0.9rem;">{row["reg_date"][:10]}</div>', unsafe_allow_html=True)
                
                # 5. ì¡°íšŒìˆ˜
                c5.markdown(f'<div style="text-align:center; font-size:0.9rem;">{row.get("views", 0)}</div>', unsafe_allow_html=True)
                
                # 6. ì¶”ì²œìˆ˜
                c6.markdown(f'<div style="text-align:center; font-size:0.9rem;">{row["likes"]}</div>', unsafe_allow_html=True)
                
                # 7. [ìš”ì²­ì‚¬í•­ 1] ëŒ“ê¸€ ìˆ˜ í‘œì‹œ
                comment_count = len(get_comments(row['id']))
                c7.markdown(f'<div style="text-align:center; font-size:0.9rem;">{comment_count}</div>', unsafe_allow_html=True)

                # [ë‚´ìš© í‘œì‹œ ì˜ì—­] ì„ íƒëœ ê¸€ì¸ ê²½ìš° í•˜ë‹¨ì— ë‚´ìš© í‘œì‹œ
                if st.session_state.get('active_post_id') == row['id']:
                    with st.container(border=True):
                        # ê¶Œí•œ ì²´í¬
                        can_view = True
                        if row['is_secret']:
                            if not st.session_state.user_id:
                                can_view = False
                            elif st.session_state.user_role != 'admin' and st.session_state.user_id != row['user_id']:
                                can_view = False
                        
                        if not can_view:
                            st.warning("ğŸ”’ ë¹„ë°€ê¸€ì…ë‹ˆë‹¤. ì‘ì„±ìì™€ ê´€ë¦¬ìë§Œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        else:
                            # [ìš”ì²­ì‚¬í•­ 3] ì¤„ë°”ê¿ˆ ë° ë„ì–´ì“°ê¸° ë³´ì¡´ ì²˜ë¦¬
                            content_display = row['content'].replace("\n", "  \n")
                            st.markdown(content_display)
                            st.divider()
                            
                            # ê¸°ëŠ¥ ë²„íŠ¼ (ì¢‹ì•„ìš”, ìˆ˜ì •, ì‚­ì œ)
                            ac1, ac2, ac3 = st.columns([1,1,1])
                            with ac1:
                                if st.button(f"ğŸ‘ ì¢‹ì•„ìš” ({row['likes']})", key=f"like_inner_{row['id']}"):
                                    if st.session_state.user_id:
                                        like_post(row['id'])
                                        st.rerun()
                                    else: st.warning("íšŒì› ê°€ì… í›„ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                            
                            is_author = st.session_state.user_id and (st.session_state.user_id == row['user_id'])
                            is_admin = st.session_state.user_role == 'admin'
                            
                            if is_author or is_admin:
                                with ac2:
                                    if st.button("ğŸ“ ìˆ˜ì •", key=f"edit_btn_{row['id']}"):
                                        st.session_state.edit_pid = row['id']
                                        st.session_state.edit_mode = True
                                        st.rerun()
                                with ac3:
                                    if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"del_btn_{row['id']}"):
                                        delete_post(row['id'])
                                        st.session_state.active_post_id = None
                                        st.rerun()
                            elif row['non_user_pw'] and not st.session_state.user_id:
                                with st.popover("ë¹„íšŒì› ê¸€ ê´€ë¦¬"):
                                    check_pw = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key=f"check_pw_{row['id']}")
                                    if st.button("í™•ì¸ ë° ì‚­ì œ", key=f"del_non_{row['id']}"):
                                        if check_pw == row['non_user_pw']:
                                            delete_post(row['id'])
                                            st.session_state.active_post_id = None
                                            st.success("ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                                            st.rerun()
                                        else:
                                            st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                            
                            # ëŒ“ê¸€ ì˜ì—­
                            st.write("---")
                            st.markdown("**ğŸ’¬ ëŒ“ê¸€**")
                            comments = get_comments(row['id'])
                            for _, com in comments.iterrows():
                                com_view = True
                                if com['is_secret']:
                                    if not st.session_state.user_id: com_view = False
                                    elif st.session_state.user_role != 'admin' and st.session_state.user_id != com['user_id'] and st.session_state.user_id != row['user_id']:
                                        com_view = False
                                
                                if com_view:
                                    com_author = com['user_id']
                                    display_com_author = com_author[:3] + "***"
                                    st.markdown(f"- **{display_com_author}**: {com['content']} {'ğŸ”’' if com['is_secret'] else ''}")
                                else:
                                    st.markdown(f"- ğŸ”’ ë¹„ë°€ ëŒ“ê¸€ì…ë‹ˆë‹¤.")
                            
                            if st.session_state.user_id:
                                with st.form(f"com_f_{row['id']}", clear_on_submit=True):
                                    ct = st.text_input("ëŒ“ê¸€ ì…ë ¥")
                                    cs = st.checkbox("ë¹„ë°€ëŒ“ê¸€")
                                    if st.form_submit_button("ì‘ì„±"):
                                        if ct: add_comment(row['id'], st.session_state.user_id, ct, cs); st.rerun()
                            else:
                                st.info("ë¡œê·¸ì¸ í›„ ëŒ“ê¸€ ì‘ì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

        if st.session_state.get('edit_mode'):
            st.divider()
            edit_post_data = posts[posts['id'] == st.session_state.edit_pid]
            if not edit_post_data.empty:
                curr = edit_post_data.iloc[0]
                with st.form("edit_post_f"):
                    st.write("### ê¸€ ìˆ˜ì •")
                    et = st.text_input("ì œëª©", value=curr['title'])
                    # [ìš”ì²­ì‚¬í•­ 3] ìˆ˜ì • ì—ë””í„° ë†’ì´ 2ë°° ì¦ê°€ (height=500)
                    ec = st.text_area("ë‚´ìš©", value=curr['content'], height=500)
                    es = st.checkbox("ë¹„ë°€ê¸€", value=bool(curr['is_secret']))
                    en = st.checkbox("ê³µì§€ì‚¬í•­", value=bool(curr['is_notice']), disabled=(st.session_state.user_role != 'admin'))
                    if st.form_submit_button("ìˆ˜ì • ì™„ë£Œ"):
                        update_post(st.session_state.edit_pid, et, ec, es, en)
                        st.session_state.edit_mode = False
                        st.rerun()
                    if st.form_submit_button("ì·¨ì†Œ"):
                        st.session_state.edit_mode = False
                        st.rerun()

    with tab_write:
        if st.session_state.user_id:
            with st.form("new_post_f", clear_on_submit=True):
                wt = st.text_input("ì œëª©")
                # [ìš”ì²­ì‚¬í•­ 3] ê¸€ì“°ê¸° ì—ë””í„° ë†’ì´ ì¡°ì • (ê¸°ë³¸ 200 -> 500)
                wc = st.text_area("ë‚´ìš©", height=500)
                ws = st.checkbox("ë¹„ë°€ ê¸€ì“°ê¸° (ê´€ë¦¬ìë§Œ ì½ì„ ìˆ˜ ìˆìŒ)")
                wn = st.checkbox("ê³µì§€ì‚¬í•­ ë“±ë¡ (ê´€ë¦¬ì ì „ìš©)", disabled=(st.session_state.user_role != 'admin'))
                if st.form_submit_button("ë“±ë¡"):
                    if wt and wc:
                        add_post(st.session_state.user_id, wt, wc, ws, wn)
                        st.success("ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
                    else: st.error("ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            st.info("ğŸ’¡ ë¹„íšŒì›ìœ¼ë¡œ ê¸€ì„ ì‘ì„±í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‘ì„± í›„ íšŒì›ê°€ì…ì„ ê³ ë ¤í•´ ì£¼ì„¸ìš”.")
            with st.form("non_user_post_f", clear_on_submit=True):
                non_name = st.text_input("ì‘ì„±ìëª…")
                non_pw = st.text_input("ë¹„ë°€ë²ˆí˜¸ (ìˆ˜ì •/ì‚­ì œìš©)", type="password")
                wt = st.text_input("ì œëª©")
                wc = st.text_area("ë‚´ìš©", height=500)
                if st.form_submit_button("ë“±ë¡"):
                    if non_name and non_pw and wt and wc:
                        add_post(non_name, wt, wc, False, False, non_user_pw=non_pw)
                        st.success("ê²Œì‹œê¸€ì´ ì„±ê³µì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.info("ğŸ™ ì•ˆë…•í•˜ì„¸ìš”! ê²Œì‹œê¸€ì„ ì‘ì„±í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. íšŒì›ìœ¼ë¡œ ê°€ì…í•˜ì‹œë©´ ì‘ì„±í•˜ì‹  ê¸€ì„ ë” ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê³ , ë¶„ì„ ë³´ê´€í•¨ ë“± AHP ë§ˆìŠ¤í„°ì˜ ëª¨ë“  ì „ë¬¸ ê¸°ëŠ¥ì„ ììœ ë¡­ê²Œ ì´ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§€ê¸ˆ ë°”ë¡œ ê°€ì…í•´ ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?")
                    else:
                        st.error("ëª¨ë“  í•­ëª©(ì‘ì„±ìëª…, ë¹„ë°€ë²ˆí˜¸, ì œëª©, ë‚´ìš©)ì„ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")

# -----------------------------------------------------------------------------
# 2. Setup & Layout
# -----------------------------------------------------------------------------

init_db()

st.markdown("""
<style>
    .stDataFrame {font-size: 0.9rem;} 
    div[data-testid="stMetricValue"] {font-size: 1.2rem;}
    .stDownloadButton > button {
        background-color: #d32f2f;
        color: white;
        border-radius: 5px;
        border: none;
        padding: 0.6rem 1.2rem;
        font-weight: bold;
        transition: background-color 0.3s ease;
    }
    .stDownloadButton > button:hover {
        background-color: #b71c1c;
    }
    div.stButton > button:first-child[kind="primary"] {
        background-color: #90EE90 !important; 
        color: black !important;
        border: none !important;
    }
</style>
""", unsafe_allow_html=True)

if 'user_id' not in st.session_state: st.session_state.user_id = None
if 'user_role' not in st.session_state: st.session_state.user_role = None
if 'expiry_date' not in st.session_state: st.session_state.expiry_date = None
if 'admin_mode' not in st.session_state: st.session_state.admin_mode = False
if 'model_structure' not in st.session_state: st.session_state.model_structure = {}
if 'page' not in st.session_state: st.session_state.page = "main"

# =============================================================================
# 3. Sidebar (Auth & Settings)
# =============================================================================

fee_info_text = """
---
### ğŸ’° ì„œë¹„ìŠ¤ ì´ìš©ë£Œ
- **ë¬´ë£Œì‚¬ìš©ì**: ë¬´ë£Œ (5í‘œë³¸ ì œí•œ ì™¸ ê¸°ëŠ¥ì œí•œ ì—†ìŒ)
- **í•™ìœ„ë…¼ë¬¸**: 40ë§Œì›
- **ì¼ë°˜ì—°êµ¬**: 50ë§Œì›

**ê²°ì œ ì •ë³´**
- **ê³„ì¢Œë²ˆí˜¸**: ì¹´ì¹´ì˜¤ë±…í¬ 3333-23-8667708
- **ì˜ˆê¸ˆì£¼**: ì „ìƒí˜„
- **ì£¼ì˜**: ì†¡ê¸ˆìëª…ì— **ê°€ì…í•œ ì´ë©”ì¼ ì£¼ì†Œ**ë¥¼ ê¸°ì…í•´ì£¼ì„¸ìš”.
"""

with st.sidebar:
    try:
        st.image("ahp_master_logo.png", use_container_width=True)
    except:
        st.subheader("ğŸ“Š AHP ë§ˆìŠ¤í„°")
    
    with st.expander("â„¹ï¸ ì¼ê´€ì„± ë³´ì • ê¸°ì¤€", expanded=False):
        st.markdown("""
        **ë³´ì • ë°©ë²•: ë°˜ë³µ ìˆ˜ë ´ ì¡°ì •ë²•(Iterative Adjustment)**
        ê°€ì¤‘ì¹˜ ì‚°ì¶œ ì•Œê³ ë¦¬ì¦˜(Saaty)ì— ì˜í•´ íŒë‹¨ í–‰ë ¬ì´ ë¹„ì¼ê´€ì (CR > ì„ê³„ê°’)ì¸ ê²½ìš°, ìˆ˜í•™ì ìœ¼ë¡œ ì¼ê´€ëœ í–‰ë ¬ê³¼ ì›ë³¸ í–‰ë ¬ì„ ì¼ì • ë¹„ìœ¨ë¡œ í˜¼í•©í•˜ì—¬ ë°˜ë³µì ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ë¯¸ì„¸ ì¡°ì •í•œ ê²°ê³¼ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
        
        **í˜„ì¬ ë°©ë²•ì˜ íŠ¹ì§•:**
        1. **ìµœì†Œ íŒë‹¨ ì™œê³¡**: ì›ë³¸ ì„¤ë¬¸ ì‘ë‹µì˜ ê²½í–¥ì„±ì„ 90%ë³´ì¡´í•˜ë©´ì„œ ìˆ˜í•™ì  ì¼ê´€ì„±ë§Œì„ í™•ë³´í•©ë‹ˆë‹¤.
        2. **ìë™ ìˆ˜ë ´**: ì„¤ì •ëœ ë°˜ë³µ íšŸìˆ˜ ë‚´ì—ì„œ CR ê°’ì„ ì„ê³„ê°’ ì´í•˜ë¡œ ìë™ ê°œì„ í•©ë‹ˆë‹¤. ($New = Old^{0.9} \\times Ideal^{0.1}$)
        
        """)        
    
    if st.button("ğŸŒ ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œíŒ", use_container_width=True, type="primary"):
        st.session_state.page = "community"
        st.rerun()
    
    if st.session_state.user_id is None:
        tab_login, tab_signup, tab_find_pw = st.tabs(["ë¡œê·¸ì¸", "íšŒì›ê°€ì…", "ë¹„ë°€ë²ˆí˜¸ ì°¾ê¸°"])
        
        with tab_login:
            st.header("ğŸ” ë¡œê·¸ì¸")
            l_id = st.text_input("ì•„ì´ë”” (ì´ë©”ì¼ ì£¼ì†Œ)", key="l_id")
            l_pw = st.text_input("ë¹„ë°€ë²ˆí˜¸ (PW)", type="password", key="l_pw")
            if st.button("ë¡œê·¸ì¸ ì‹¤í–‰"):
                result = check_login(l_id.strip(), l_pw)
                if result:
                    today = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).date()
                    expiry_date = datetime.datetime.strptime(result[1], "%Y-%m-%d").date()
                    if today > expiry_date:
                        st.error(f"âŒ ì´ìš© ê¸°ê°„ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (ë§Œë£Œì¼: {result[1]})")
                    else:
                        st.session_state.user_id = l_id.strip()
                        st.session_state.user_role = result[0]
                        st.session_state.expiry_date = result[1]
                        st.success(f"í™˜ì˜í•©ë‹ˆë‹¤, {l_id}ë‹˜!")
                        st.rerun()
                else:
                    st.error("ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
            st.markdown(fee_info_text)

        with tab_signup:
            st.header("ğŸ“ íšŒì›ê°€ì…")
            agreements = show_agreement_ui()
            s_id = st.text_input("ì•„ì´ë”” (ì´ë©”ì¼ ì£¼ì†Œ)", key="s_id")
            s_pw = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="s_pw")
            s_role_selection = st.radio("ì´ìš© ê¶Œí•œ ì„ íƒ", ("ë¬´ë£Œì‚¬ìš©ì", "ì •ì‹ ì‚¬ìš©ì (2ê°œì›”, ê¸°ëŠ¥ ë¬´ì œí•œ)"), index=0)
            
            if "ì •ì‹" in s_role_selection:
                st.warning("âš ï¸ ì •ì‹ ì‚¬ìš©ì ê°€ì… ì•ˆë‚´")
                st.info("ì •ì‹ ì‚¬ìš©ìëŠ” ì…ê¸‰ ì „ê¹Œì§€ **ë¬´ë£Œì‚¬ìš©ì** ê¶Œí•œì´ ë¶€ì—¬ë©ë‹ˆë‹¤.")
                st.info("ê´€ë¦¬ìê°€ ì…ê¸ˆ í™•ì¸ í›„ **ì •ì‹ ì‚¬ìš©ì**ë¡œ ê¶Œí•œì´ ë³€ê²½ë©ë‹ˆë‹¤, ìŠ¹ì¸ ì™„ë£Œ ì‹œ ì´ë©”ì¼ë¡œ ì•ˆë‚´í•´ ë“œë¦½ë‹ˆë‹¤. (ì‚¬ìš© ê¸°ê°„ì€ 2ê°œì›” ì…ë‹ˆë‹¤)")
            
            if st.button("ê°€ì…ì‹ ì²­"):
                if not agreements.get("agree_personal_info"):
                    st.error("ê°œì¸ì •ë³´ ìˆ˜ì§‘Â·ì´ìš©ì— ë™ì˜í•´ì•¼ ê°€ì…ì‹ ì²­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                elif not validate_email(s_id):
                    st.error("ì˜¬ë°”ë¥¸ ì´ë©”ì¼ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                elif not validate_password(s_pw):
                    st.error("ë¹„ë°€ë²ˆí˜¸ëŠ” ë¬¸ì+íŠ¹ìˆ˜ë¬¸ìì—¬ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    restore_from_deleted_sheet(s_id.strip())
                    initial_role = 'temp'
                    actual_requested_role = 'official' if "ì •ì‹" in s_role_selection else 'temp'
                    agree_text = "ë™ì˜" if agreements.get("agree_personal_info") else "ë¯¸ë™ì˜"
                    if add_user(s_id.strip(), s_pw, initial_role, agree_info=agree_text):
                        if actual_requested_role == 'official':
                            send_application_email(s_id)
                        st.success("ë¬´ë£Œì‚¬ìš©ìë¡œ ê°€ì… ì™„ë£Œ ë˜ì—ˆìŠµë‹ˆë‹¤")
                    else:
                        st.error("ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì•„ì´ë””ì…ë‹ˆë‹¤.")
            
            st.markdown(fee_info_text)

        with tab_find_pw:
            st.header("ğŸ”‘ ë¹„ë°€ë²ˆí˜¸ ì°¾ê¸°")
            st.write("ê°€ì… ì‹œ ì‚¬ìš©í•œ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            f_id = st.text_input("ê°€ì…í•œ ì•„ì´ë”” (ì´ë©”ì¼)", key="f_id")
            if st.button("ë¹„ë°€ë²ˆí˜¸ ì´ë©”ì¼ ì „ì†¡"):
                if not f_id:
                    st.warning("ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    found_pw = get_user_password(f_id.strip())
                    if found_pw:
                        if send_password_recovery_email(f_id.strip(), found_pw):
                            st.success(f"'{f_id}'ë¡œ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì „ì†¡í–ˆìŠµë‹ˆë‹¤.\nì´ë©”ì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                        else:
                            st.error("ì´ë©”ì¼ ì „ì†¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.error("ë“±ë¡ë˜ì§€ ì•Šì€ ì•„ì´ë””ì…ë‹ˆë‹¤.")

    else:
        st.success(f"**{st.session_state.user_id}** ë‹˜")
        role_disp = "ê´€ë¦¬ì" if st.session_state.user_role == 'admin' else ("ì •ì‹ ì‚¬ìš©ì" if st.session_state.user_role == 'official' else "ë¬´ë£Œì‚¬ìš©ì")
        st.info(f"ê¶Œí•œ: {role_disp}")
        
        if st.session_state.user_role == 'temp':
            if st.button("ì •ì‹ ì‚¬ìš©ì ì „í™˜ ìš”ì²­"):
                if send_conversion_request_email(st.session_state.user_id):
                    st.success("ì •ì‹ ì‚¬ìš©ì ì „í™˜ìš”ì²­ì´ ì™„ë£Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì…ê¸ˆ í™•ì¸ í›„ ì •ì‹ì‚¬ìš©ìë¡œ ì „í™˜í•´ ë“œë¦½ë‹ˆë‹¤")
                else:
                    st.error("ìš”ì²­ ì „ì†¡ ì‹¤íŒ¨. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜ë°”ëë‹ˆë‹¤.")

        if st.session_state.expiry_date:
            st.warning(f"ğŸ“… ì‚¬ìš© ë§Œë£Œì¼: {st.session_state.expiry_date}")
        
        if st.session_state.user_role == 'admin':
            if st.button("ğŸ”§ ê´€ë¦¬ì í™”ë©´ ì ‘ì†"):
                st.session_state.admin_mode = not st.session_state.admin_mode
                st.rerun()

        with st.expander("ğŸ” ë¹„ë°€ë²ˆí˜¸ ë³€ê²½"):
            cur_pw = st.text_input("í˜„ì¬ ë¹„ë°€ë²ˆí˜¸", type="password", key="chg_cur")
            new_pw = st.text_input("ìƒˆ ë¹„ë°€ë²ˆí˜¸", type="password", key="chg_new")
            confirm_pw = st.text_input("ìƒˆ ë¹„ë°€ë²ˆí˜¸ í™•ì¸", type="password", key="chg_conf")
            
            if st.button("ë¹„ë°€ë²ˆí˜¸ ë³€ê²½"):
                if new_pw != confirm_pw:
                    st.error("ìƒˆ ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                elif not validate_password(new_pw):
                    st.error("ë¹„ë°€ë²ˆí˜¸ëŠ” 4ì ì´ìƒ, ì˜ë¬¸+íŠ¹ìˆ˜ë¬¸ìë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    chk_res = check_login(st.session_state.user_id, cur_pw)
                    if chk_res:
                        change_user_password(st.session_state.user_id, new_pw)
                        st.success("ë¹„ë°€ë²ˆí˜¸ê°€ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.error("í˜„ì¬ ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        if st.button("ë¡œê·¸ì•„ì›ƒ"):
            st.session_state.user_id = None
            st.session_state.user_role = None
            st.session_state.expiry_date = None
            st.session_state.admin_mode = False
            st.rerun()

    st.markdown("---")
    st.header("ë¶„ì„ ì„¤ì •")
    mean_method_label = st.radio("í‰ê·  ì‚°ì¶œ ë°©ì‹", ('ê¸°í•˜í‰ê·  (Geometric)', 'ì‚°ìˆ í‰ê·  (Arithmetic)'), index=0)
    mean_method = 'geometric' if 'ê¸°í•˜' in mean_method_label else 'arithmetic'
    cr_threshold = st.selectbox("ì¼ê´€ì„± ë¹„ìœ¨(CR) ì„ê³„ê°’", [0.1, 0.2], index=0)
    max_iter = st.number_input("ìµœëŒ€ ë³´ì • ë°˜ë³µ íšŸìˆ˜", min_value=10, max_value=500, value=500, step=50)

    st.markdown("---")
    with st.expander("ğŸ’¡ ì‚¬ìš©ì ê¶Œí•œ ì•ˆë‚´", expanded=False):
        st.info("**ë¹„ë¡œê·¸ì¸(Guest)**: ìƒ˜í”Œ íŒŒì¼ ë¶„ì„ë§Œ ê°€ëŠ¥")
        st.info("**ë¬´ë£Œì‚¬ìš©ì**: ë‚˜ë§Œì˜ ëª¨ë¸ ìƒì„±, ë¶„ì„ ê°€ëŠ¥ (ë¬´ë£Œ 5í‘œë³¸ ì œí•œ)")
        st.info("**ì •ì‹ ì‚¬ìš©ì**: ëª¨ë“  ê¸°ëŠ¥ ë¬´ì œí•œ (2ê°œì›”/í•„ìš”ì‹œ 1ê°œì›” ì—°ì¥)")
    
    st.markdown("### ğŸ“ ë¬¸ì˜ì²˜")
    st.markdown("- **ì´ë©”ì¼**: jeon080423@gmail.com")
    st.markdown("- **ì¹´í†¡ID**: AHPkr")
    st.markdown("- **ì „í™”**: 010-2142-2610")
    st.markdown("- **[ì‚¬ìš©ì„¤ëª…ì„œ](https://morison.tistory.com/97)**")

# =============================================================================
# 4. Main Content Logic
# =============================================================================

if st.session_state.page == "community":
    show_community_board()
else:
    st.title("AHP ë§ˆìŠ¤í„°: ë¶„ì„ ìë™í™” ì‹œìŠ¤í…œ")

    st.markdown("Saaty(1980)ì˜ Analytic Hierarchy Process (AHP) ë¶„ì„ ë° ì¼ê´€ì„± ìë™ ë³´ì • ë„êµ¬ì…ë‹ˆë‹¤. ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ê°œì¸ë³„ ê°€ì¤‘ì¹˜ ì‚°ì¶œ, ì¼ê´€ì„± ë³´ì •(CR), ê·¸ë£¹ë³„ ì§‘ê³„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n\n**â–  ì½”ë”© í”„ë¡œê·¸ë¨**: Python\n\n**â–  ì œì‘/ê´€ë¦¬**: ì œì˜¨ https://blog.naver.com/morison00")
            

    if st.session_state.get('admin_mode', False) and st.session_state.user_role == 'admin':
        st.subheader("ğŸ‘¥ ê°€ì…ì í˜„í™© ë° ê´€ë¦¬")
        
        col_sync1, col_sync2 = st.columns([2, 8])
        with col_sync1:
            if st.button("ğŸ”„ êµ¬ê¸€ ì‹œíŠ¸ì™€ ë™ê¸°í™”"):
                with st.spinner("êµ¬ê¸€ ì‹œíŠ¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                    added_count = sync_db_from_sheets()
                if added_count >= 0:
                    st.success(f"ë™ê¸°í™” ì™„ë£Œ! (ë³µêµ¬ëœ íšŒì› ìˆ˜: {added_count}ëª…)")
                    st.rerun()
                else:
                    st.error("ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        
        try:
            client = get_gspread_client()
            if client:
                spreadsheet = client.open_by_key(st.secrets["SPREADSHEET_ID"])
                try:
                    visit_sheet = spreadsheet.worksheet("Visit_Logs")
                    visit_data_gs = visit_sheet.get_all_records()
                    daily_df_logs = pd.DataFrame(visit_data_gs)
                    if not daily_df_logs.empty:
                        daily_df_logs['Date_Only'] = daily_df_logs['Date'].astype(str).str[:10]
                        daily_df_counts = daily_df_logs.groupby('Date_Only').size().reset_index(name='count')
                        total_visits = len(daily_df_logs)

                        st.write("#### ğŸ—ºï¸ ì ‘ì†ì ì‹¤ì‹œê°„ ìœ„ì¹˜ ë¶„í¬")
                        if 'Latitude' in daily_df_logs.columns and 'Longitude' in daily_df_logs.columns:
                            map_data = daily_df_logs[daily_df_logs['Latitude'].astype(str).str.strip() != ""].copy()
                            if not map_data.empty:
                                map_data['lat'] = pd.to_numeric(map_data['Latitude'], errors='coerce')
                                map_data['lon'] = pd.to_numeric(map_data['Longitude'], errors='coerce')
                                map_data = map_data.dropna(subset=['lat', 'lon'])
                                if not map_data.empty:
                                    map_display = map_data.groupby(['lat', 'lon']).size().reset_index(name='visit_count')
                                    map_display['size'] = map_display['visit_count'] * 20
                                    st.map(map_display, latitude='lat', longitude='lon', size='size')
                                else:
                                    st.info("ìœ íš¨í•œ ì¢Œí‘œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                st.info("ì§€ë„ì— í‘œì‹œí•  ìœ„ì¹˜ ì •ë³´ ë°ì´í„°ê°€ ì•„ì§ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                        else:
                            st.info("ìœ„ì¹˜ ì •ë³´ ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    else:
                        total_visits = 0
                        daily_df_counts = pd.DataFrame()
                except gspread.exceptions.WorksheetNotFound:
                    total_visits = 0
                    daily_df_counts = pd.DataFrame()

                st.write(f"**ì´ ëˆ„ì  ë°©ë¬¸ì ìˆ˜ (ì‹œê°„ ê¸°ë°˜):** {total_visits:,}íšŒ")
                st.write("#### ğŸ“… ì¼ë³„ ë°©ë¬¸ì í˜„í™© (ë‚ ì§œë³„ í•©ì‚°)")
                if not daily_df_counts.empty:
                    fig_visit = px.bar(daily_df_counts, x='Date_Only', y='count', text='count',
                                        labels={'Date_Only': 'ë‚ ì§œ', 'count': 'ë°©ë¬¸ì ìˆ˜'})
                    fig_visit.update_traces(textposition='outside')
                    fig_visit.update_layout(xaxis_title="ë‚ ì§œ", yaxis_title="ë°©ë¬¸ì ìˆ˜", showlegend=False, xaxis={'type': 'category'})
                    st.plotly_chart(fig_visit, use_container_width=True)
                else:
                    st.info("ë°©ë¬¸ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"í†µê³„ ì˜¤ë¥˜: {e}")
        st.divider()
        
        users_df = get_all_users()
        st.dataframe(users_df)

        with st.expander("íšŒì› ì •ë³´ ìˆ˜ì • (ë¹„ë°€ë²ˆí˜¸ ì´ˆê¸°í™” í¬í•¨)"):
            edit_id = st.selectbox("ìˆ˜ì •í•  íšŒì› ID", users_df['id'].unique())
            selected_user = users_df[users_df['id'] == edit_id].iloc[0]
            new_role = st.selectbox("ê¶Œí•œ ë³€ê²½", ['temp', 'official', 'admin'], 
                                    index=['temp', 'official', 'admin'].index(selected_user['role']))
            
            if new_role == 'official' and selected_user['role'] != 'official':
                suggested_date = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).date() + relativedelta(months=2)
                new_expiry = st.text_input("ë§Œë£Œì¼ ì„¤ì • (YYYY-MM-DD) - 2ê°œì›” ê¸°í•œ ìë™ ì œì•ˆë¨", value=str(suggested_date))
            else:
                new_expiry = st.text_input("ë§Œë£Œì¼ ë³€ê²½ (YYYY-MM-DD)", value=selected_user['expiry_date'])
                
            new_pw = st.text_input("ìƒˆ ë¹„ë°€ë²ˆí˜¸ (ì…ë ¥ ì‹œ ë³€ê²½ë¨)", type="password", placeholder="ë³€ê²½í•˜ì§€ ì•Šìœ¼ë ¤ë©´ ë¹„ì›Œë‘ì„¸ìš”")
            
            if st.button("ì •ë³´ ìˆ˜ì • ì ìš©"):
                update_user_full_info(edit_id, new_pw, new_role, new_expiry)
                if new_role == 'official' and selected_user['role'] != 'official':
                    send_approval_email(edit_id)
                st.success(f"{edit_id} íšŒì›ì˜ ì •ë³´ê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()
        
        with st.expander("íšŒì› ì‚­ì œ"):
            del_id = st.selectbox("ì‚­ì œí•  íšŒì› ID ì„ íƒ", users_df['id'].unique(), key='del_user_select')
            if st.button("ì„ íƒí•œ íšŒì› ì‚­ì œ"):
                if del_id == st.session_state.user_id:
                    st.error("ë³¸ì¸ì€ ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    delete_user(del_id)
                    st.success("ì‚­ì œ ì™„ë£Œ")
                    st.rerun()
        st.divider()

    st.subheader("1. AHP ë¶„ì„ ëª¨ë¸ ì„¤ì • ë° ì…ë ¥ í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ")

    if st.session_state.user_id is None:
        st.info("ğŸ”’ **ë¡œê·¸ì¸ í›„** 'ë‚˜ë§Œì˜ ë¶„ì„ ëª¨ë¸'ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ë¹„ë¡œê·¸ì¸ ìƒíƒœì—ì„œë„ ìƒ˜í”Œ ë°ì´í„°ë¡œ ìµœì¢… ë¶„ì„ ê²°ê³¼ë¥¼ ë¯¸ë¦¬ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    else:
        saved_model = load_user_model(st.session_state.user_id)
        default_main = "ê±°ë²„ë„ŒìŠ¤, ê³„íšíƒ€ë‹¹ì„±, ì‹¤í˜„ê°€ëŠ¥ì„±, ì‚¬ì—…íš¨ê³¼"
        default_subs = {
            "ê±°ë²„ë„ŒìŠ¤": "í–‰ì •ì§€ì›, ì§€ì—­ê³µë™ì²´, ì´ê´„ì‚¬ì—…ê´€ë¦¬ì",
            "ê³„íšíƒ€ë‹¹ì„±": "í˜„ì•ˆì ì •ì„±, ëŒ€ì•ˆì ì •ì„±, ëª©í‘œêµ¬ì²´ì„±",
            "ì‹¤í˜„ê°€ëŠ¥ì„±": "ë¶€ì§€í™•ë³´, ì‚¬ì—…êµ¬ì²´í™”, ì‚¬ì—…ë¹„ì ì •ì„±",
            "ì‚¬ì—…íš¨ê³¼": "ê²½ì œì íš¨ê³¼, ì‚¬íšŒì íš¨ê³¼, ì„±ê³¼ê´€ë¦¬"
        }
        
        if saved_model:
            default_main = saved_model.get('main', default_main)
            default_subs = saved_model.get('subs', default_subs)

        with st.expander("ğŸ“Œ ë‚˜ì˜ ë¶„ì„ ëª¨ë¸ ë§Œë“¤ê¸°", expanded=False):
            st.info("ëŒ€í•­ëª©ê³¼ ì„¸ë¶€í•­ëª©ì„ ì…ë ¥í•˜ì—¬ ë‚˜ë§Œì˜ ì…ë ¥ ì—‘ì…€ í…œí”Œë¦¿ì„ ìƒì„±í•˜ì„¸ìš”.\n\ní˜„ì¬ ì…ë ¥ë˜ì–´ ìˆëŠ” ë‚´ìš©ì€ ìƒ˜í”Œ ëª¨ë¸ì…ë‹ˆë‹¤. ì‚­ì œí•˜ì‹œê³  ì´ìš©ìë‹˜ì˜ AHP ëª¨ë¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
            main_criteria_input = st.text_input("ëŒ€í•­ëª© (Main Criteria, ì½¤ë§ˆ êµ¬ë¶„)", value=default_main)
            main_criteria_list = [x.strip() for x in main_criteria_input.split(',') if x.strip()]
            
            model_structure = {}
            if main_criteria_list:
                for mc in main_criteria_list:
                    d_val = default_subs.get(mc, "")
                    if isinstance(d_val, list): d_val = ", ".join(d_val)
                    sub_input = st.text_input(f"'{mc}'ì˜ ì„¸ë¶€í•­ëª©", value=d_val, key=f"sub_{mc}")
                    sub_list = [x.strip() for x in sub_input.split(',') if x.strip()]
                    model_structure[mc] = sub_list
            
            if st.button("ì„¤ì •í•œ ëª¨ë¸ë¡œ ì…ë ¥ ì—‘ì…€ í…œí”Œë¦¿ ìƒì„±"):
                if not main_criteria_list:
                    st.error("ëŒ€í•­ëª© ì…ë ¥ í•„ìš”")
                else:
                    current_model = {'main': main_criteria_input, 'subs': model_structure}
                    save_user_model(st.session_state.user_id, current_model)
                    st.toast("ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
                    
                    output_template = io.BytesIO()
                    with pd.ExcelWriter(output_template, engine='xlsxwriter') as writer:
                        main_pairs = list(itertools.combinations(main_criteria_list, 2))
                        main_cols = ["ID", "Type"] + [f"{a}_{b}" for a, b in main_pairs]
                        df_template_main = pd.DataFrame(columns=main_cols)
                        df_template_main.loc[0] = [1, ""] + [0]*len(main_pairs)
                        df_template_main.to_excel(writer, sheet_name="Main_Criteria", index=False)
                        
                        for mc, subs in model_structure.items():
                            if len(subs) < 2:
                                df_sub = pd.DataFrame(columns=["ID", "Type"])
                            else:
                                sub_pairs = list(itertools.combinations(subs, 2))
                                sub_cols = ["ID", "Type"] + [f"{a}_{b}" for a, b in sub_pairs]
                                df_sub = pd.DataFrame(columns=sub_cols)
                                df_sub.loc[0] = [1, ""] + [0]*len(sub_pairs)
                            safe_sheet_name = mc[:31]
                            df_sub.to_excel(writer, sheet_name=safe_sheet_name, index=False)
                    output_template.seek(0)
                    st.download_button(
                        label="ğŸ“¥ ì—‘ì…€ í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ",
                        data=output_template,
                        file_name="AHP_Master_Template.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )

                    st.markdown("""
                    ---
                    ### ğŸ“ ë°ì´í„° ì…ë ¥ ê°€ì´ë“œ
                    1. **ì—‘ì…€ íŒŒì¼ ì—´ê¸°**: ìœ„ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‹¤ìš´ë¡œë“œí•œ ì—‘ì…€ íŒŒì¼ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
                    2. **ìŒëŒ€ë¹„êµ ë°ì´í„° ì…ë ¥**:
                        - **ì™¼ìª½** í•­ëª©ì´ ë” ì¤‘ìš”í•˜ë©´: **ìŒìˆ˜** ì…ë ¥ (ì˜ˆ: -3)
                        - **ì˜¤ë¥¸ìª½** í•­ëª©ì´ ë” ì¤‘ìš”í•˜ë©´: **ì–‘ìˆ˜** ì…ë ¥ (ì˜ˆ: 3)
                        - **ë™ë“±**í•˜ë©´: `1` ì…ë ¥
                    3. **í•„ìˆ˜ ì •ë³´ ì…ë ¥**: Aì—´(ID), **Bì—´(Type)ì— ê·¸ë£¹ëª… ì…ë ¥ (ì˜ˆ: ì „ë¬¸ê°€, ì£¼ë¯¼ ë“±)**
                    """)
                    if os.path.exists("ahp_input_guide.png"):
                        st.image("ahp_input_guide.png", caption="[ì°¸ê³ ] ì„¤ë¬¸ ì‘ë‹µì„ ì—‘ì…€ì— ì…ë ¥í•˜ëŠ” ë°©ë²•")

    st.markdown("---")

    if st.session_state.user_role == 'official':
        with st.expander("ğŸ“‚ ë‚˜ì˜ ë¶„ì„ ë³´ê´€í•¨ (!ì¤‘ìš”) ë°˜ë“œì‹œ ì»´í“¨í„°ì— ë°±ì—…í•´ ì£¼ì„¸ìš”"):
            my_analyses = get_user_analyses(st.session_state.user_id)
            if not my_analyses: st.info("ì €ì¥ëœ ë¶„ì„ ì—†ìŒ")
            else:
                for item in my_analyses:
                    a_id, filename, save_date = item
                    col_List1, col_List2, col_List3, col_List4 = st.columns([3, 2, 1, 1])
                    with col_List1: st.text(f"{filename}")
                    with col_List2: st.caption(f"{save_date}")
                    with col_List3:
                        file_info = get_analysis_file(analysis_id=a_id)
                        if file_info:
                            fname, fdata = file_info
                            st.download_button("â¬‡ï¸", fdata, fname, "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", key=f"dl_{a_id}")
                    with col_List4:
                        if st.button("ğŸ—‘ï¸", key=f"del_{a_id}"):
                            delete_analysis(a_id)
                            st.rerun()

    with st.container(border=True):
        st.markdown("#### âš¡ ë¹ ë¥¸ ì‹œì‘ (ë„ì‹œì¬ìƒ ì‚¬ì—… ëª¨ë¸)")
        st.info("ì•„ë˜ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì—‘ì…€ íŒŒì¼ì´ ë‹¤ìš´ë¡œë“œ ë©ë‹ˆë‹¤.\n\n"
                "ë‹¤ìš´ë°›ì€ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ì—‘ì…€ íŒŒì¼ì„ ì•„ë˜ 'ë°ì´í„° ì—…ë¡œë“œ ë° ë¶„ì„'ì— ì—…ë¡œë“œ í•˜ì„¸ìš”.")
        
        sample_excel = create_sample_excel()
        st.download_button(
            label="ğŸ“‚ í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ",
            data=sample_excel,
            file_name="AHP_UrbanRegeneration_Sample.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

    st.markdown("---")

    def write_custom_ahp_table(writer, sheet_name, df, title_text, start_row, formats, excluded_df=None):
        workbook = writer.book
        if sheet_name in writer.sheets: worksheet = writer.sheets[sheet_name]
        else:
            worksheet = workbook.add_worksheet(sheet_name)
            writer.sheets[sheet_name] = worksheet
        
        header_fmt = formats['header']
        merge_fmt = formats['merge']
        body_fmt = formats['body']
        num_fmt = formats['num']
        sum_row_fmt = formats['sum_row']
        
        if excluded_df is not None:
            worksheet.write(start_row, 0, f"â€» ë¶„ì„ ì œì™¸ ì‚¬ë¡€ìˆ˜: {len(excluded_df)}ê±´", workbook.add_format({'bold': True, 'font_color': 'red'}))
            start_row += 1
            if not excluded_df.empty:
                worksheet.write(start_row, 0, "â–¶ ì œì™¸ëœ ì‘ë‹µ ë°ì´í„° (ë³´ì • ì‹¤íŒ¨)", workbook.add_format({'bold': True}))
                start_row += 1
                excluded_df.to_excel(writer, sheet_name=sheet_name, startrow=start_row, index=False)
                start_row += len(excluded_df) + 2

        worksheet.merge_range(start_row, 0, start_row, 6, title_text, workbook.add_format({'bold': True, 'font_size': 12}))
        start_row += 1
        
        headers = ["ëŒ€ë¶„ë¥˜", "ê°€ì¤‘ì¹˜(a)", "ì¤‘ë¶„ë¥˜", "ê°€ì¤‘ì¹˜(b)", "ì¢…í•© ê°€ì¤‘ì¹˜(a x b)", "ì¢…í•© ìˆœìœ„", "ë¹„ê³ "]
        for col, h in enumerate(headers):
            worksheet.write(start_row, col, h, header_fmt)
        start_row += 1
        
        main_criteria = df['ëŒ€ë¶„ë¥˜'].unique()
        current_row = start_row
        
        for main_c in main_criteria:
            sub_df = df[df['ëŒ€ë¶„ë¥˜'] == main_c]
            n_subs = len(sub_df)
            main_w = sub_df.iloc[0]['ëŒ€ë¶„ë¥˜ ê°€ì¤‘ì¹˜']
            sub_cr = sub_df.iloc[0]['CR(ì¤‘ë¶„ë¥˜)']
            sum_sub_w = sub_df['ì¤‘ë¶„ë¥˜ ê°€ì¤‘ì¹˜'].sum()
            
            merge_span = n_subs + 2 
            if merge_span > 1:
                worksheet.merge_range(current_row, 0, current_row + merge_span - 1, 0, main_c, merge_fmt)
                worksheet.merge_range(current_row, 1, current_row + merge_span - 1, 1, main_w, num_fmt)
            else:
                worksheet.write(current_row, 0, main_c, merge_fmt)
                worksheet.write(current_row, 1, main_w, num_fmt)
                
            for idx, row in sub_df.iterrows():
                worksheet.write(current_row, 2, row['ì¤‘ë¶„ë¥˜'], body_fmt)
                worksheet.write(current_row, 3, row['ì¤‘ë¶„ë¥˜ ê°€ì¤‘ì¹˜'], num_fmt)
                worksheet.write(current_row, 4, row['Global Weight'], num_fmt)
                worksheet.write(current_row, 5, row['Global Rank'], body_fmt)
                worksheet.write(current_row, 6, "", body_fmt)
                current_row += 1
            
            worksheet.write(current_row, 2, "í•©ê³„", sum_row_fmt)
            worksheet.write(current_row, 3, sum_sub_w, formats['sum_val'])
            worksheet.write_blank(current_row, 4, "", sum_row_fmt)
            worksheet.write_blank(current_row, 5, "", sum_row_fmt)
            worksheet.write_blank(current_row, 6, "", sum_row_fmt)
            current_row += 1
            
            worksheet.write(current_row, 2, "ì¼ê´€ì„± ë¹„ìœ¨(CR)", sum_row_fmt)
            worksheet.write(current_row, 3, sub_cr, formats['num_sum'])
            worksheet.write_blank(current_row, 4, "", sum_row_fmt)
            worksheet.write_blank(current_row, 5, "", sum_row_fmt)
            worksheet.write_blank(current_row, 6, "", sum_row_fmt)
            current_row += 1

        worksheet.write(current_row, 0, "í•©ê³„", sum_row_fmt)
        worksheet.write(current_row, 1, 1, formats['sum_val'])
        worksheet.write(current_row, 2, "í•©ê³„", sum_row_fmt)
        worksheet.write_blank(current_row, 3, "", sum_row_fmt)
        worksheet.write(current_row, 4, 1, formats['sum_val'])
        worksheet.write_blank(current_row, 5, "", sum_row_fmt)
        worksheet.write_blank(current_row, 6, "", sum_row_fmt)
        
        worksheet.set_column('A:A', 15)
        worksheet.set_column('B:B', 12)
        worksheet.set_column('C:C', 25)
        worksheet.set_column('D:F', 12)
        return current_row + 2

    def add_borders_to_data(worksheet, start_row, start_col, df, border_fmt, has_header=True, has_index=False):
        rows = len(df) + (1 if has_header else 0)
        cols = len(df.columns) + (1 if has_index else 0)
        worksheet.conditional_format(start_row, start_col, start_row+rows-1, start_col+cols-1,
                                      {'type': 'formula', 'criteria': '=TRUE', 'format': border_fmt})

    st.subheader("2. ë°ì´í„° ì—…ë¡œë“œ ë° ë¶„ì„")
    uploaded_file = st.file_uploader("ì‘ì„±ëœ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ (.xlsx)", type=['xlsx', 'xls'])

    if uploaded_file:
        try:
            excel_obj = pd.ExcelFile(uploaded_file)
            sheet_names = excel_obj.sheet_names
            df_main = pd.read_excel(uploaded_file, sheet_name=sheet_names[0])
            main_cols_names = df_main.columns[2:]
            main_factors, n_main = infer_factors_from_columns(main_cols_names)

            permission_granted = False
            message = ""
            role = st.session_state.user_role
            user_id = st.session_state.user_id

            if role == 'admin' or role == 'official':
                permission_granted = True
                if role == 'official':
                    today = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).date()
                    expiry = datetime.datetime.strptime(st.session_state.expiry_date, "%Y-%m-%d").date()
                    if today > expiry:
                        permission_granted = False
                        message = "â›” ì´ìš© ê¸°ê°„ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
            else: 
                rows_ok = True
                for sn in sheet_names:
                    if len(pd.read_excel(uploaded_file, sheet_name=sn)) > 5:
                        rows_ok = False
                        break
                if rows_ok: permission_granted = True
                else: message = f"â›” **ë¬´ë£Œì‚¬ìš©ì**ëŠ” ì‹œíŠ¸ë‹¹ ìµœëŒ€ 5ê°œ í‘œë³¸ê¹Œì§€ë§Œ ë¶„ì„ ê°€ëŠ¥í•©ë‹ˆë‹¤."

            if permission_granted:
                with st.spinner("ê³„ì¸µ ë¶„ì„ ìˆ˜í–‰ ì¤‘..."):
                    main_results_df, main_factors, main_excluded, main_excluded_df = process_single_sheet(df_main, cr_threshold, max_iter, mean_method)
                    
                    total_excluded = main_excluded
                    st.markdown(f"**ë¶„ì„ ì œì™¸: {total_excluded}ê±´**")

                    main_sig_df = calculate_pairwise_ttest(main_results_df, main_factors)
                    main_weight_cols = [f"Weight_{f}" for f in main_factors]
                    
                    if mean_method == 'arithmetic':
                        group_main_weights = main_results_df[main_weight_cols].mean(axis=0)
                    else:
                        group_main_weights = gmean(main_results_df[main_weight_cols].values, axis=0)
                    group_main_weights = group_main_weights / group_main_weights.sum()
                    main_cr_final_avg = main_results_df['Final_CR'].mean()
                    
                    main_matrices = np.stack(main_results_df['Matrix_Object'].values)
                    main_group_matrix = np.mean(main_matrices, axis=0) if mean_method == 'arithmetic' else gmean(main_matrices, axis=0)
                    main_grp_cr, main_grp_ci, _ = calculate_consistency(main_group_matrix, mean_method)
                    
                    indiv_global_data = []
                    all_ids = main_results_df['ID'].unique()
                    
                    sub_results_storage = {} 
                    total_excl_df_list = [main_excluded_df]
                    for i, sub_sheet_name in enumerate(sheet_names[1:]):
                        parent_factor = main_factors[i]
                        df_sub = pd.read_excel(uploaded_file, sheet_name=sub_sheet_name)
                        sub_res_df, sub_facts, sub_excl, sub_excl_df = process_single_sheet(df_sub, cr_threshold, max_iter, mean_method)
                        sub_sig_df = calculate_pairwise_ttest(sub_res_df, sub_facts)
                        sub_w_cols = [f"Weight_{f}" for f in sub_facts]
                        group_sub_w = sub_res_df[sub_w_cols].mean(axis=0) if mean_method == 'arithmetic' else gmean(sub_res_df[sub_w_cols].values, axis=0)
                        group_sub_w = group_sub_w / group_sub_w.sum()
                        sub_cr_final_avg = sub_res_df['Final_CR'].mean()
                        sub_matrices = np.stack(sub_res_df['Matrix_Object'].values)
                        sub_group_matrix = np.mean(sub_matrices, axis=0) if mean_method == 'arithmetic' else gmean(sub_matrices, axis=0)
                        sub_grp_cr, _, _ = calculate_consistency(sub_group_matrix, method=mean_method)
                        sub_results_storage[parent_factor] = {
                            'weights': group_sub_w, 'factors': sub_facts, 'cr': sub_cr_final_avg,
                            'df': sub_res_df, 'group_matrix': sub_group_matrix, 'group_cr': sub_grp_cr, 'sig_df': sub_sig_df
                        }
                        if not sub_excl_df.empty:
                            sub_excl_df['Sheet'] = sub_sheet_name
                            total_excl_df_list.append(sub_excl_df)

                    for uid in all_ids:
                        u_main = main_results_df[main_results_df['ID'] == uid]
                        if u_main.empty: continue
                        u_type = u_main['Type'].values[0]
                        for mf in main_factors:
                            m_w = u_main[f"Weight_{mf}"].values[0]
                            s_row_df = sub_results_storage[mf]['df']
                            u_sub = s_row_df[s_row_df['ID'] == uid]
                            if u_sub.empty: continue
                            for sf in sub_results_storage[mf]['factors']:
                                s_w = u_sub[f"Weight_{sf}"].values[0]
                                indiv_global_data.append({
                                    "ID": uid, "Type": str(u_type), "Factor": sf, "Global_Weight": m_w * s_w
                                })
                    indiv_df = pd.DataFrame(indiv_global_data)
                    
                    anova_df = pd.DataFrame()
                    if not indiv_df.empty and len(indiv_df['Type'].unique()) >= 2:
                        anova_df = calculate_anova_and_posthoc(indiv_df)

                    summary_rows = []
                    for idx, main_f in enumerate(main_factors):
                        m_weight = group_main_weights[idx]
                        sub_info = sub_results_storage[main_f]
                        for s_idx, sub_f in enumerate(sub_info['factors']):
                            s_weight = sub_info['weights'][s_idx]
                            global_w = m_weight * s_weight
                            summary_rows.append({
                                "ëŒ€ë¶„ë¥˜": main_f, "ëŒ€ë¶„ë¥˜ ê°€ì¤‘ì¹˜": m_weight, "ì¤‘ë¶„ë¥˜": sub_f, "ì¤‘ë¶„ë¥˜ ê°€ì¤‘ì¹˜": s_weight,
                                "Global Weight": global_w, "CR(ëŒ€ë¶„ë¥˜)": main_cr_final_avg, "CR(ì¤‘ë¶„ë¥˜)": sub_info['cr']
                            })
                    
                    final_df = pd.DataFrame(summary_rows)
                    final_df['Global Rank'] = final_df['Global Weight'].rank(ascending=False, method='min').astype(int)
                    cols_order = ["ëŒ€ë¶„ë¥˜", "ëŒ€ë¶„ë¥˜ ê°€ì¤‘ì¹˜", "ì¤‘ë¶„ë¥˜", "ì¤‘ë¶„ë¥˜ ê°€ì¤‘ì¹˜", "Global Weight", "Global Rank", "CR(ëŒ€ë¶„ë¥˜)", "CR(ì¤‘ë¶„ë¥˜)"]
                    final_df = final_df[cols_order]

                    unique_groups = sorted(main_results_df['Type'].astype(str).unique())
                    group_analysis_results = {}
                    group_full_dfs = {} 
                    
                    for grp in unique_groups:
                        grp_main_df = main_results_df[main_results_df['Type'].astype(str) == grp]
                        if grp_main_df.empty: continue
                        g_main_w = grp_main_df[main_weight_cols].mean(axis=0) if mean_method == 'arithmetic' else gmean(grp_main_df[main_weight_cols].values, axis=0)
                        g_main_w = g_main_w / g_main_w.sum()
                        g_main_mats = np.stack(grp_main_df['Matrix_Object'].values)
                        g_main_mat_obj = np.mean(g_main_mats, axis=0) if mean_method == 'arithmetic' else gmean(g_main_mats, axis=0)
                        g_main_cr, _, _ = calculate_consistency(g_main_mat_obj, method=mean_method)
                        
                        grp_rows = []
                        for idx, main_f in enumerate(main_factors):
                            m_w = g_main_w[idx]
                            full_sub_df = sub_results_storage[main_f]['df']
                            grp_sub_df = full_sub_df[full_sub_df['Type'].astype(str) == grp]
                            sub_facts_list = sub_results_storage[main_f]['factors']
                            if grp_sub_df.empty: continue
                            s_w_cols = [f"Weight_{f}" for f in sub_facts_list]
                            g_sub_w = grp_sub_df[s_w_cols].mean(axis=0) if mean_method == 'arithmetic' else gmean(grp_sub_df[s_w_cols].values, axis=0)
                            g_sub_w = g_sub_w / g_sub_w.sum()
                            g_sub_mats = np.stack(grp_sub_df['Matrix_Object'].values)
                            g_sub_mat_obj = np.mean(g_sub_mats, axis=0) if mean_method == 'arithmetic' else gmean(g_sub_mats, axis=0)
                            g_sub_cr, _, _ = calculate_consistency(g_sub_mat_obj, method=mean_method)
                            for s_idx, sf in enumerate(sub_facts_list):
                                grp_rows.append({
                                    "ëŒ€ë¶„ë¥˜": main_f, "ëŒ€ë¶„ë¥˜ ê°€ì¤‘ì¹˜": m_w, "ì¤‘ë¶„ë¥˜": sf, "ì¤‘ë¶„ë¥˜ ê°€ì¤‘ì¹˜": g_sub_w[s_idx],
                                    "Global Weight": m_w * g_sub_w[s_idx], "CR(ëŒ€ë¶„ë¥˜)": g_main_cr, "CR(ì¤‘ë¶„ë¥˜)": g_sub_cr
                                })
                        g_df = pd.DataFrame(grp_rows)
                        if not g_df.empty:
                            g_df['Global Rank'] = g_df['Global Weight'].rank(ascending=False, method='min').astype(int)
                            group_full_dfs[grp] = g_df[cols_order]
                            group_analysis_results[grp] = group_full_dfs[grp][['ì¤‘ë¶„ë¥˜', 'Global Weight']]

                    comparison_df = final_df[['ì¤‘ë¶„ë¥˜', 'Global Weight']].copy()
                    comparison_df.rename(columns={'Global Weight': 'Overall'}, inplace=True)
                    for grp, df_res in group_analysis_results.items():
                        temp_df = df_res.rename(columns={'Global Weight': grp})
                        comparison_df = comparison_df.merge(temp_df, on='ì¤‘ë¶„ë¥˜', how='left')

                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                        workbook = writer.book
                        formats = {
                            'header': workbook.add_format({'bold': True, 'align': 'center', 'valign': 'vcenter', 'bg_color': '#000000', 'font_color': '#FFFFFF', 'border': 1}),
                            'merge': workbook.add_format({'align': 'center', 'valign': 'vcenter', 'border': 1}),
                            'body': workbook.add_format({'align': 'center', 'valign': 'vcenter', 'border': 1}),
                            'num': workbook.add_format({'align': 'center', 'valign': 'vcenter', 'border': 1, 'num_format': '0.000'}),
                            'sum_row': workbook.add_format({'bold': True, 'bg_color': '#D3D3D3', 'align': 'center', 'valign': 'vcenter', 'border': 1}),
                            'sum_val': workbook.add_format({'num_format': '0', 'bg_color': '#D3D3D3', 'border': 1, 'align':'center'}),
                            'num_sum': workbook.add_format({'num_format': '0.000', 'bg_color': '#D3D3D3', 'border': 1, 'align':'center'}),
                            'yellow': workbook.add_format({'bg_color': 'yellow', 'border': 1, 'align': 'center', 'num_format': '0.000'})
                        }
                        border_fmt = workbook.add_format({'border': 1})
                        fmt_float_no_border = workbook.add_format({'num_format': '0.000', 'align': 'center', 'valign': 'vcenter', 'border': 1})
                        fmt_diagonal = workbook.add_format({'num_format': '0', 'align': 'center', 'valign': 'vcenter', 'bg_color': '#E7E6E6', 'border': 1})

                        total_excluded_df = pd.concat(total_excl_df_list, ignore_index=True)
                        current_row = write_custom_ahp_table(writer, 'ì¢…í•©ë¶„ì„', final_df, "1) ì „ì²´_ì¢…í•©ê²°ê³¼", 1, formats, excluded_df=total_excluded_df)
                        for grp in unique_groups:
                            if grp in group_full_dfs:
                                current_row = write_custom_ahp_table(writer, 'ì¢…í•©ë¶„ì„', group_full_dfs[grp], f"â–¶ [ê·¸ë£¹: {grp}] ë¶„ì„ ê²°ê³¼", current_row, formats)

                        if len(unique_groups) >= 1:
                            ws_comp = workbook.add_worksheet('Group_Comparison')
                            writer.sheets['Group_Comparison'] = ws_comp
                            s_row = 1
                            ws_comp.write_string(s_row, 0, "ê·¸ë£¹ ê°„ ë¹„êµ(ì¼ì›ë°°ì¹˜ ë¶„ì‚°ë¶„ì„: ANOVA)", workbook.add_format({'bold': True, 'font_size': 12}))
                            s_row += 1
                            
                            if not anova_df.empty:
                                anova_for_merge = anova_df.rename(columns={'ìš”ì¸': 'ì¤‘ë¶„ë¥˜'})
                                integrated_df = comparison_df.merge(anova_for_merge, on='ì¤‘ë¶„ë¥˜', how='left')
                            else:
                                integrated_df = comparison_df
                            
                            integrated_df.to_excel(writer, sheet_name='Group_Comparison', startrow=s_row, index=False)
                            add_borders_to_data(ws_comp, s_row, 0, integrated_df, border_fmt)
                            
                            num_format_3 = workbook.add_format({'num_format': '0.000', 'border': 1, 'align': 'center'})
                            for r in range(len(integrated_df)):
                                for c in range(1, len(integrated_df.columns)):
                                    val = integrated_df.iloc[r, c]
                                    if pd.notnull(val) and isinstance(val, (int, float)):
                                        ws_comp.write_number(s_row + 1 + r, c, val, num_format_3)
                                    elif pd.notnull(val):
                                        ws_comp.write(s_row + 1 + r, c, val, border_fmt)

                            guide_start_row = s_row + len(integrated_df) + 3
                            bold_fmt = workbook.add_format({'bold': True, 'font_size': 11, 'valign': 'vcenter', 'align': 'left', 'bg_color': '#F2F2F2', 'border': 1})
                            text_fmt = workbook.add_format({'font_size': 10, 'text_wrap': True, 'valign': 'top', 'align': 'left', 'border': 1})
                            ws_comp.set_column('A:G', 20) 
                            ws_comp.merge_range(guide_start_row, 0, guide_start_row, 6, "â€» ê·¸ë£¹ ê°„ ì¤‘ìš”ë„ì˜ ì°¨ì´ê°€ ìˆì§€ë§Œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•Šê²Œ ë‚˜íƒ€ë‚˜ëŠ” ì´ìœ ", bold_fmt)

                            guide_content = [
                                ("1. ê·¸ë£¹ ë‚´ í¸ì°¨(ë¶„ì‚°)ê°€ ë„ˆë¬´ í° ê²½ìš°", "ANOVAëŠ” 'ê·¸ë£¹ ê°„ì˜ ì°¨ì´'ì™€ 'ê·¸ë£¹ ë‚´ì˜ ì°¨ì´'ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.\n\nâ–  ì›ë¦¬: ê·¸ë£¹ ê°„ í‰ê·  ì°¨ì´ê°€ í¬ë”ë¼ë„, ê° ê·¸ë£¹ ë‚´ë¶€ ë°ì´í„°ë“¤ì´ ì„œë¡œ ë“¤ì­‰ë‚ ì­‰(ë¶„ì‚°ì´ í¼)í•˜ë‹¤ë©´ í†µê³„ì ìœ¼ë¡œëŠ” 'ì´ ì°¨ì´ê°€ ìš°ì—°íˆ ë°œìƒí–ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤'ê³  íŒë‹¨í•©ë‹ˆë‹¤.\nâ–  ë¶„ì„: í˜„ì¬ ë°ì´í„°ì—ì„œ í‰ê· ê°’ì˜ ì ˆëŒ€ì ì¸ ì°¨ì´ëŠ” ì»¤ ë³´ì¼ ìˆ˜ ìˆì§€ë§Œ, ê° ê·¸ë£¹(A~D)ì— ì†í•œ ê°œë³„ ì‘ë‹µìë“¤ì˜ ê°’ë“¤ì´ í‰ê· ì—ì„œ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆë‹¤ë©´ F-ê°’ì´ ë‚®ì•„ì§€ê³  P-ValueëŠ” ì˜¬ë¼ê°€ê²Œ ë©ë‹ˆë‹¤."),
                                ("2. í‘œë³¸ í¬ê¸°(Sample Size)ì˜ ë¶€ì¡±", "í†µê³„ì  ìœ ì˜ì„±ì€ í‘œë³¸ì˜ ìˆ˜ì— ë§¤ìš° ë¯¼ê°í•©ë‹ˆë‹¤.\n\nâ–  í˜„ìƒ: ê° ê·¸ë£¹ì˜ ë°ì´í„° ê°œìˆ˜(í‘œë³¸ìˆ˜)ê°€ ë„ˆë¬´ ì ë‹¤ë©´(ì˜ˆ: ê·¸ë£¹ë‹¹ 3~5ê°œ ë¯¸ë§Œ) ì•„ë¬´ë¦¬ í‰ê·  ì°¨ì´ê°€ ì»¤ë„ í†µê³„ì  í˜(Power)ì´ ë¶€ì¡±í•˜ì—¬ ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ ì°¾ì•„ë‚´ì§€ ëª»í•©ë‹ˆë‹¤.\nâ–  í™•ì¸ ì‚¬í•­: í˜„ì¬ ë¶„ì„ì— ì‚¬ìš©ëœ ê° ê·¸ë£¹ì˜ nìˆ˜(í‘œë³¸ìˆ˜)ê°€ ì¶©ë¶„í•œì§€ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤."),
                                ("3. ë°ì´í„°ì˜ ë‹¨ìœ„(Scale)ì™€ ë³€ë™ì„±", "í‘œì— ë‚˜íƒ€ë‚œ ìˆ˜ì¹˜ë“¤ì´ ëŒ€ë¶€ë¶„ 0.1 ë¯¸ë§Œ í˜¹ì€ 0.2 ìˆ˜ì¤€ì˜ ë§¤ìš° ì‘ì€ ì†Œìˆ˜ì  ë‹¨ìœ„ì…ë‹ˆë‹¤.\n\nâ–  ë¶„ì„: ìˆ˜ì¹˜ ìì²´ê°€ ì‘ê¸° ë•Œë¬¸ì— ì‹œê°ì ìœ¼ë¡œëŠ” 0.05ì™€ 0.15ê°€ 3ë°° ì°¨ì´ë¡œ ì»¤ ë³´ì¼ ìˆ˜ ìˆì§€ë§Œ, ì‹¤ì œ ê³„ì‚° ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” í‘œì¤€ì˜¤ì°¨(Standard Error) ë²”ìœ„ ì•ˆì— í•´ë‹¹ ìˆ˜ì¹˜ë“¤ì´ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ í†µê³„ì ìœ¼ë¡œëŠ” 'ì¸¡ì • ì˜¤ì°¨ ë²”ìœ„ ë‚´ì˜ í”ë“¤ë¦¼'ìœ¼ë¡œ ê°„ì£¼ë©ë‹ˆë‹¤.")
                            ]

                            current_row_comp = guide_start_row + 1
                            for title, body in guide_content:
                                ws_comp.set_row(current_row_comp, 25)
                                ws_comp.merge_range(current_row_comp, 0, current_row_comp, 6, title, bold_fmt)
                                ws_comp.set_row(current_row_comp + 1, 120)
                                ws_comp.merge_range(current_row_comp + 1, 0, current_row_comp + 1, 6, body, text_fmt)
                                current_row_comp += 2

                        def write_detailed_sheet(sheet_name, matrix_data, detail_data_df, matrix_title, row_labels, group_matrices=None, sheet_excl_count=0):
                            ws = workbook.add_worksheet(sheet_name)
                            writer.sheets[sheet_name] = ws
                            s_row_det = 0
                            
                            ws.write(s_row_det, 0, f"ë¶„ì„ ì œì™¸ ì‚¬ë¡€ìˆ˜: {sheet_excl_count}ê±´", workbook.add_format({'bold': True, 'font_color': 'red'}))
                            s_row_det += 1
                            
                            ws.write_string(s_row_det, 0, matrix_title)
                            s_row_det += 1
                            m_df_obj = pd.DataFrame(matrix_data, index=row_labels, columns=row_labels)
                            m_df_obj.to_excel(writer, sheet_name=sheet_name, startrow=s_row_det)
                            add_borders_to_data(ws, s_row_det, 0, m_df_obj, border_fmt, has_header=True, has_index=True)
                            for r in range(len(matrix_data)):
                                for c in range(len(matrix_data)):
                                    val = 1 if r==c else matrix_data[r][c]
                                    ws.write(s_row_det+r+1, c+1, val, border_fmt if r!=c else fmt_diagonal)
                                    if r!=c: ws.write(s_row_det+r+1, c+1, val, fmt_float_no_border)
                            
                            s_row_det += len(matrix_data) + 3
                            
                            if group_matrices:
                                for g_name, g_mat in group_matrices.items():
                                    ws.write_string(s_row_det, 0, f"] ê·¸ë£¹ ì¢…í•© í–‰ë ¬: {g_name}")
                                    s_row_det += 1
                                    gm_df_obj = pd.DataFrame(g_mat, index=row_labels, columns=row_labels)
                                    gm_df_obj.to_excel(writer, sheet_name=sheet_name, startrow=s_row_det)
                                    add_borders_to_data(ws, s_row_det, 0, gm_df_obj, border_fmt, has_header=True, has_index=True)
                                    for r in range(len(g_mat)):
                                        for c in range(len(g_mat)):
                                            val = 1 if r==c else g_mat[r][c]
                                            ws.write(s_row_det+r+1, c+1, val, border_fmt if r!=c else fmt_diagonal)
                                            if r!=c: ws.write(s_row_det+r+1, c+1, val, fmt_float_no_border)
                                    s_row_det += len(g_mat) + 3
                            
                            detail_data_df.to_excel(writer, sheet_name=sheet_name, startrow=s_row_det, index=False)
                            
                            for c_idx, col_val in enumerate(detail_data_df.columns):
                                ws.write(s_row_det, c_idx, col_val, formats['header'])
                            
                            for r_idx in range(len(detail_data_df)):
                                orig_cr_val = detail_data_df.iloc[r_idx]['Original_CR']
                                final_cr_val = detail_data_df.iloc[r_idx]['Final_CR']
                                row_pos = s_row_det + 1 + r_idx
                                
                                for c_idx, col_name in enumerate(detail_data_df.columns):
                                    val = detail_data_df.iloc[r_idx, c_idx]
                                    current_fmt = border_fmt
                                    
                                    if col_name == 'Original_CR' and orig_cr_val > 0.1:
                                        current_fmt = formats['yellow']
                                    elif col_name == 'Final_CR' and final_cr_val > 0.1:
                                        current_fmt = formats['yellow']
                                    elif isinstance(val, (float, np.float64)):
                                        current_fmt = formats['num']
                                    else:
                                        current_fmt = formats['body']
                                        
                                    if pd.isnull(val):
                                        ws.write_blank(row_pos, c_idx, "", current_fmt)
                                    else:
                                        ws.write(row_pos, c_idx, val, current_fmt)

                        main_group_mats = {}
                        for grp in unique_groups:
                            g_df_m = main_results_df[main_results_df['Type'].astype(str) == grp]
                            if not g_df_m.empty:
                                mats_stack = np.stack(g_df_m['Matrix_Object'].values)
                                main_group_mats[grp] = np.mean(mats_stack, axis=0) if mean_method == 'arithmetic' else gmean(mats_stack, axis=0)

                        out_main = main_results_df.drop(columns=['Matrix_Object'], errors='ignore')
                        write_detailed_sheet('Result_Main', main_group_matrix, out_main, f"[1] ì „ì²´ ì¢…í•© í–‰ë ¬", main_factors, group_matrices=main_group_mats, sheet_excl_count=main_excluded)
                        for mf, info in sub_results_storage.items():
                            safe_name = f"Result_{mf}"[:31]
                            sub_grp_mats = {}
                            for grp in unique_groups:
                                g_sub_df = info['df'][info['df']['Type'].astype(str) == grp]
                                if not g_sub_df.empty:
                                    mats_stack = np.stack(g_sub_df['Matrix_Object'].values)
                                    sub_grp_mats[grp] = np.mean(mats_stack, axis=0) if mean_method == 'arithmetic' else gmean(mats_stack, axis=0)
                            out_sub = info['df'].drop(columns=['Matrix_Object'], errors='ignore')
                            
                            sub_excl_val = 0
                            for df_ex in total_excl_df_list:
                                if 'Sheet' in df_ex.columns and not df_ex.empty:
                                     if df_ex['Sheet'].iloc[0] == mf or (mf in df_ex['Sheet'].unique()):
                                          sub_excl_val = len(df_ex[df_ex['Sheet'] == mf])
                                          
                            write_detailed_sheet(safe_name, info['group_matrix'], out_sub, f"[1] ì „ì²´ ì¢…í•© í–‰ë ¬", info['factors'], group_matrices=sub_grp_mats, sheet_excl_count=sub_excl_val)

                        theory_ws = workbook.add_worksheet("Consistency_Theory")
                        theory_title_fmt = workbook.add_format({'bold': True, 'font_size': 14, 'font_name': 'NanumGothic'})
                        theory_body_fmt = workbook.add_format({'text_wrap': True, 'valign': 'top', 'font_name': 'NanumGothic'})
                        theory_text = [
                            ["ì˜ì‚¬ê²°ì •ë¡ ì  ê´€ì ì—ì„œì˜ AHP ì¼ê´€ì„± ë³´ì • ì›ë¦¬ ë° í•™ìˆ ì  ê·¼ê±°"],
                            [""],
                            ["1. ì„œë¡ : ê³„ì¸µë¶„ì„ê³¼ì •(AHP)ì˜ ì¼ê´€ì„± ë¬¸ì œ"],
                            ["Saaty(1980)ì— ì˜í•´ ì œì•ˆëœ ê³„ì¸µë¶„ì„ê³¼ì •(Analytic Hierarchy Process, AHP)ì€ ì¸ê°„ì˜ ì£¼ê´€ì  íŒë‹¨ì„ ì •ëŸ‰í™”í•˜ëŠ” ê°•ë ¥í•œ ë‹¤ê¸°ì¤€ ì˜ì‚¬ê²°ì • ë„êµ¬ì´ë‹¤. ê·¸ëŸ¬ë‚˜ ì˜ì‚¬ê²°ì •ìì˜ ì¸ì§€ì  í•œê³„ë¡œ ì¸í•´ ìŒëŒ€ë¹„êµ í–‰ë ¬ì—ì„œ ì´í–‰ì„±(Transitivity)ì´ ê²°ì—¬ëœ ë¹„ì¼ê´€ì  íŒë‹¨ì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ë³¸ ì‹œìŠ¤í…œì€ ì´ëŸ¬í•œ ë¹„ì¼ê´€ì„±ì„ ìˆ˜í•™ì ìœ¼ë¡œ êµì •í•˜ì—¬ ë¶„ì„ì˜ ì‹ ë¢°ì„±ì„ í™•ë³´í•œë‹¤."],
                            [""],
                            ["2. ë³´ì • ì•Œê³ ë¦¬ì¦˜: ë°˜ë³µ ìˆ˜ë ´ ì¡°ì •ë²•(Iterative Adjustment Method)"],
                            ["ë³¸ ì‹œìŠ¤í…œì— ì ìš©ëœ ë³´ì • ë¡œì§ì€ 'ë°˜ë³µì  ì„ í˜• ê²°í•© ìˆ˜ë ´ë²•'ì— ê·¼ê±°í•œë‹¤. ë¹„ì¼ê´€ì  í–‰ë ¬ Aê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ì¼ê´€ì„± ë¹„ìœ¨(Consistency Ratio, CR)ì´ ì„ê³„ê°’(0.1 ë˜ëŠ” 0.2)ì„ ì´ˆê³¼í•  ê²½ìš° ë‹¤ìŒê³¼ ê°™ì€ í”„ë¡œì„¸ìŠ¤ë¥¼ ìˆ˜í–‰í•œë‹¤."],
                            ["    ê°€. ê³ ìœ ë²¡í„°ë²•(Eigenvector Method) ë˜ëŠ” ê¸°í•˜í‰ê· ë²•ì„ í†µí•´ í˜„ì¬ í–‰ë ¬ì˜ ê°€ì¤‘ì¹˜ ë²¡í„° wë¥¼ ë„ì¶œí•œë‹¤."],
                            ["    ë‚˜. ê°€ì¤‘ì¹˜ ë²¡í„° wë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì™„ë²½í•œ ì¼ê´€ì„±ì„ ê°€ì§„ í–‰ë ¬ W = [wi/wj]ë¥¼ ìƒì„±í•œë‹¤. ì´ë¥¼ 'ì´ìƒì  ì¼ê´€ í–‰ë ¬'ì´ë¼ ì •ì˜í•œë‹¤."],
                            ["    ë‹¤. ì›ë³¸ í–‰ë ¬ Aì™€ ì´ìƒì  í–‰ë ¬ Wë¥¼ íŠ¹ì • í•™ìŠµë¥ (Learning Rate, Î±=0.4)ì— ë”°ë¼ ì„ í˜• ê²°í•©(Linear Combination)í•œë‹¤: A_new = (1-Î±)A + Î±W."],
                            ["    ë¼. êµì •ëœ í–‰ë ¬ A_newì˜ ì—­ìˆ˜ì„±(Reciprocity)ì„ ì¬ì„¤ì •í•˜ê³ , CRì´ ì„ê³„ê°’ ì´í•˜ë¡œ ìˆ˜ë ´í•  ë•Œê¹Œì§€ ìœ„ ê³¼ì •ì„ ìµœëŒ€ 500íšŒ ë°˜ë³µí•œë‹¤."],
                            [""],
                            ["3. í•™ìˆ ì  ê·¼ê±° ë° íš¨ê³¼"],
                            ["ì²«ì§¸, ìµœì†Œ íŒë‹¨ ì™œê³¡ì˜ ì›ë¦¬(Principle of Minimal Distortion): Cao et al.(2008)ì— ë”°ë¥´ë©´, ì›ë³¸ í–‰ë ¬ê³¼ ì¼ê´€ í–‰ë ¬ì˜ ê°€ì¤‘ í‰ê· ì„ ì´ìš©í•œ ì¡°ì •ì€ ì˜ì‚¬ê²°ì •ìì˜ ì›ë˜ ì„ í˜¸ ê²½í–¥ì„±ì„ ìµœëŒ€í•œ ë³´ì¡´í•˜ë©´ì„œ ìˆ˜í•™ì  ì¼ê´€ì„±ë§Œì„ ì„ íƒì ìœ¼ë¡œ í–¥ìƒì‹œí‚¤ëŠ” íš¨ê³¼ê°€ ì…ì¦ë˜ì—ˆë‹¤."],
                            ["ë‘˜ì§¸, ìˆ˜ë ´ ì•ˆì •ì„±: ë°˜ë³µì  ì¡°ì • í”„ë¡œì„¸ìŠ¤ëŠ” í–‰ë ¬ì˜ ìµœëŒ€ ê³ ìœ ê°’(Î»max)ì„ ì°¨ì› ìˆ˜ nì— ìˆ˜ë ´í•˜ê²Œ í•¨ìœ¼ë¡œì¨ ì¼ê´€ì„± ì§€ìˆ˜(CI)ë¥¼ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ìˆ˜ì¤€ìœ¼ë¡œ ê°ì†Œì‹œí‚¨ë‹¤."],
                            ["ì…‹ì§¸, ì‹¤ë¬´ì  ìœ ìš©ì„±: ì„¤ë¬¸ ì‘ë‹µìì—ê²Œ ì¬ì„¤ë¬¸ì„ ìš”êµ¬í•˜ê¸° ì–´ë ¤ìš´ ì—°êµ¬ í™˜ê²½ì—ì„œ, ë³¸ ë³´ì •ë²•ì€ ë°ì´í„°ì˜ ëŒ€í‘¯ê°’ì„ í›¼ì†í•˜ì§€ ì•ŠëŠ” ë²”ìœ„ ë‚´ì—ì„œ ë¶„ì„ì˜ ë…¼ë¦¬ì  íƒ€ë‹¹ì„±ì„ ë¶€ì—¬í•˜ëŠ” í•™ìˆ ì  ëŒ€ì•ˆìœ¼ë¡œ í™œìš©ëœë‹¤."],
                            [""],
                            ["ë³¸ ì‹œìŠ¤í…œì˜ ë¶„ì„ ê²°ê³¼ëŠ” ìœ„ì™€ ê°™ì€ ì—„ë°€í•œ ìˆ˜ì¹˜ì  ë³´ì •ì„ ê±°ì³ ì‚°ì¶œë˜ì—ˆìœ¼ë¯€ë¡œ, í•™ìˆ  ì—°êµ¬ ë° ì •ì±… ì˜ì‚¬ê²°ì •ì˜ ê¸°ì´ˆ ìë£Œë¡œ í™œìš©í•˜ê¸°ì— ì í•©í•œ ì‹ ë¢°ë„ë¥¼ ë³´ìœ í•¨ì„ í™•ì¸í•œë‹¤."]
                        ]
                        theory_ws.set_column('A:A', 100)
                        for r_idx, row_content in enumerate(theory_text):
                            fmt = theory_title_fmt if r_idx == 0 else theory_body_fmt
                            theory_ws.write(r_idx, 0, row_content[0], fmt)

                    st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    if st.session_state.user_role == 'official':
                        save_analysis_to_db(st.session_state.user_id, f"{uploaded_file.name.split('.')[0]}_Result.xlsx", output.getvalue())

                    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸŒ ì¢…í•© ë¶„ì„ (Global)", "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ ê·¸ë£¹ë³„ ë¶„ì„", "ğŸ§ª í†µê³„ ê²€ì • (ANOVA)", "ğŸ“Š ì‹œê°í™” ì„¼í„°", "ğŸ“‘ ìƒì„¸ ë°ì´í„°"])
                    with tab1:
                        st.subheader("ğŸŒ ì¢…í•© ì¤‘ìš”ë„ ë° ìˆœìœ„")
                        st.dataframe(final_df.style.format(precision=3), use_container_width=True)
                    with tab2:
                        st.markdown("#### ê·¸ë£¹ë³„ ê°€ì¤‘ì¹˜ ìƒì„¸ ë¹„êµ")
                        st.dataframe(comparison_df.style.format(precision=4), use_container_width=True)
                    with tab3:
                        st.markdown("#### ì§‘ë‹¨ ê°„ ìœ ì˜ì„± ë¶„ì„")
                        if not anova_df.empty: st.dataframe(anova_df.style.format(precision=5), use_container_width=True)
                        else: st.info("í†µê³„ ê²€ì •ì„ ìœ„í•´ 2ê°œ ì´ìƒì˜ ê·¸ë£¹ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                    with tab4:
                        st.markdown("#### ğŸ“Š ì‹œê°í™” ì„¼í„°")
                        col_chart1, col_chart2 = st.columns(2)
                        with col_chart1:
                            st.write("**ì¢…í•© ì¤‘ìš”ë„ (Bar)**")
                            fig_bar = px.bar(final_df.sort_values('Global Weight'), y='ì¤‘ë¶„ë¥˜', x='Global Weight', orientation='h', text_auto='.3f')
                            st.plotly_chart(fig_bar, use_container_width=True)
                        with col_chart2:
                            st.write("**ê·¸ë£¹ë³„ ì¤‘ìš”ë„ íŒ¨í„´ (Radar)**")
                            indiv_global_radar = []
                            all_ids_r = main_results_df['ID'].unique()
                            for rid in all_ids_r:
                                m_row_r = main_results_df[main_results_df['ID'] == rid].iloc[0]
                                rtype_r = m_row_r['Type']
                                for m_f in main_factors:
                                    mw_indiv = m_row_r[f"Weight_{m_f}"]
                                    s_row_df_r = sub_results_storage[m_f]['df']
                                    s_row_r = s_row_df_r[s_row_df_r['ID'] == rid].iloc[0]
                                    for s_f in sub_results_storage[m_f]['factors']:
                                        indiv_global_radar.append({"Type": rtype_r, "Factor": s_f, "Global_Weight": mw_indiv * s_row_r[f"Weight_{s_f}"]})
                            radar_indiv_df = pd.DataFrame(indiv_global_radar)
                            radar_plot_df = radar_indiv_df.groupby(['Type', 'Factor'])['Global_Weight'].mean().reset_index()
                            fig_radar = go.Figure()
                            for t in radar_plot_df['Type'].unique():
                                t_data = radar_plot_df[radar_plot_df['Type'] == t]
                                fig_radar.add_trace(go.Scatterpolar(r=t_data['Global_Weight'], theta=t_data['Factor'], fill='toself', name=t))
                            st.plotly_chart(fig_radar, use_container_width=True)
                        st.markdown("---")
                        st.write("**3. ì¼ê´€ì„± ë¹„ìœ¨(CR) ë¶„í¬ë„ (Violin/Box Plot)**")
                        cr_dist_data = main_results_df[['ID', 'Type', 'Final_CR']].copy()
                        cr_dist_data['Level'] = 'ëŒ€ë¶„ë¥˜'
                        for m_f in main_factors:
                            temp_cr = sub_results_storage[m_f]['df'][['ID', 'Type', 'Final_CR']].copy()
                            temp_cr['Level'] = f'ì¤‘ë¶„ë¥˜({m_f})'
                            cr_dist_data = pd.concat([cr_dist_data, temp_cr])
                        fig_cr_dist = px.violin(cr_dist_data, y="Final_CR", x="Level", color="Level", box=True, points="all", title="ì‘ë‹µìë³„ ì¼ê´€ì„± ì§€ìˆ˜ ë¶„í¬")
                        st.plotly_chart(fig_cr_dist, use_container_width=True)
                        st.markdown("---")
                        st.write("**4. í•­ëª©ë³„ ìš°ì„ ìˆœìœ„ ì‚°ì ë„ (ì¤‘ìš”ë„ vs. í•©ì˜ë„)**")
                        scatter_df = radar_indiv_df.groupby('Factor')['Global_Weight'].agg(['mean', 'std']).reset_index()
                        scatter_df.columns = ['Factor', 'Weight_Mean', 'Weight_SD']
                        fig_scatter = px.scatter(scatter_df, x="Weight_Mean", y="Weight_SD", text="Factor", size="Weight_Mean", color="Weight_Mean",
                                                 labels={'Weight_Mean': 'ì¤‘ìš”ë„(í‰ê· )', 'Weight_SD': 'ì˜ê²¬ì°¨ì´(í‘œì¤€í¸ì°¨)'},
                                                 title="ì¤‘ìš”ë„-í•©ì˜ë„ ë¶„ì„ (ìš°ì¸¡ í•˜ë‹¨ì¼ìˆ˜ë¡ ì¤‘ìš”í•˜ê³  í•©ì˜ëœ í•­ëª©)")
                        fig_scatter.update_traces(textposition='top center')
                        st.plotly_chart(fig_scatter, use_container_width=True)

                    with tab5:
                        st.download_button("ğŸ“¥ ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (Excel)", data=output.getvalue(), file_name="AHP_Result.xlsx")
                        st.dataframe(radar_indiv_df, use_container_width=True)
            else:
                st.warning(message)
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

st.markdown("---")
st.caption("Â© 2026 AHP Master. All rights reserved.")
