import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import io
import sqlite3
import datetime
import re
import smtplib
import json
import platform
import os
import matplotlib.font_manager as fm
from matplotlib import rc
from email.mime.text import MIMEText
from scipy.stats import gmean, ttest_rel, f_oneway
from PIL import Image
import itertools
from math import pi
from dateutil.relativedelta import relativedelta

# [í•„ìˆ˜] plotly ë¼ì´ë¸ŒëŸ¬ë¦¬ (requirements.txtì— plotly ì¶”ê°€ í•„ìš”)
import plotly.express as px
import plotly.graph_objects as go
from scipy import stats
import gspread
from google.oauth2.service_account import Credentials

# ANOVA ë° ì‚¬í›„ê²€ì •ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì—†ì„ ê²½ìš° ì˜ˆì™¸ì²˜ë¦¬)
try:
    from statsmodels.stats.multicomp import pairwise_tukeyhsd
    STATSMODELS_AVAILABLE = True
except ImportError:
    STATSMODELS_AVAILABLE = False

# =============================================================================
# 0. ì‹œìŠ¤í…œ ì„¤ì • ë° ìœ í‹¸ë¦¬í‹°
# =============================================================================

# [í°íŠ¸ ì„¤ì •]
def set_font_config():
    system_name = platform.system()
    try:
        if system_name == 'Windows':
            font_path = "c:/Windows/Fonts/malgun.ttf"
            if os.path.exists(font_path):
                font_name = fm.FontProperties(fname=font_path).get_name()
                rc('font', family=font_name)
        elif system_name == 'Darwin': # Mac
            rc('font', family='AppleGothic')
        else: # Linux
            font_path = "NanumGothic.ttf"
            if not os.path.exists(font_path):
                import urllib.request
                url = "https://github.com/google/fonts/raw/main/ofl/nanumgothic/NanumGothic-Regular.ttf"
                urllib.request.urlretrieve(url, font_path)
            fm.fontManager.addfont(font_path)
            font_prop = fm.FontProperties(fname=font_path)
            rc('font', family=font_prop.get_name())
    except Exception as e:
        pass
    plt.rcParams['axes.unicode_minus'] = False 

set_font_config()

# DB ì´ˆê¸°í™”
def init_db():
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS users
                  (id TEXT PRIMARY KEY, pw TEXT, role TEXT, signup_date TEXT, expiry_date TEXT)''')
    c.execute('''CREATE TABLE IF NOT EXISTS saved_analyses
                  (id INTEGER PRIMARY KEY AUTOINCREMENT, user_id TEXT, filename TEXT, save_date TEXT, file_data BLOB)''')
    c.execute('''CREATE TABLE IF NOT EXISTS user_models
                  (user_id TEXT PRIMARY KEY, model_data TEXT)''')
    c.execute('''CREATE TABLE IF NOT EXISTS visit_logs
                  (ip_address TEXT, visit_date TEXT, PRIMARY KEY (ip_address, visit_date))''')
    try:
        c.execute("INSERT OR IGNORE INTO users VALUES (?, ?, ?, ?, ?)", 
                  ('shjeon', '@jsh2143033', 'admin', str(datetime.date.today()), '9999-12-31'))
        conn.commit()
    except sqlite3.IntegrityError:
        pass 
    conn.close()

# ë°©ë¬¸ì ì¶”ì 
def track_visitor():
    try:
        if hasattr(st, "context") and hasattr(st.context, "headers"):
            ip = st.context.headers.get("X-Forwarded-For", "unknown_ip")
        else:
            ip = "localhost"
        today = str(datetime.date.today())
        conn = sqlite3.connect('users.db')
        c = conn.cursor()
        c.execute("INSERT OR IGNORE INTO visit_logs (ip_address, visit_date) VALUES (?, ?)", (ip, today))
        conn.commit()
        conn.close()
    except Exception as e:
        pass

track_visitor()

# ìœ íš¨ì„± ê²€ì‚¬
def validate_email(email):
    return re.match(r"[^@]+@[^@]+\.[^@]+", email)

def validate_password(password):
    if len(password) < 4: return False
    has_char = re.search(r'[a-zA-Z]', password)
    has_special = re.search(r'[!@#$%^&*(),.?":{}|<>]', password)
    return has_char and has_special

# ë©”ì¼ ë°œì†¡ í•¨ìˆ˜ë“¤
def send_application_email(user_email):
    sender_email = "jeon080423@gmail.com"
    password = "csuh xxru wqdy mttt" 
    recipient_email = "jeon080423@gmail.com"
    subject = f"[AHP ì•±] ì •ì‹ ì‚¬ìš©ì ìŠ¹ì¸ ìš”ì²­: {user_email}"
    body = f"ì‚¬ìš©ìê°€ ì •ì‹ ê¶Œí•œ ì‹ ì²­.\nID: {user_email}\nì‹ ì²­ì¼: {datetime.date.today()}"
    msg = MIMEText(body)
    msg['Subject'] = subject
    msg['From'] = sender_email
    msg['To'] = recipient_email
    try:
        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:
            server.login(sender_email, password)
            server.sendmail(sender_email, recipient_email, msg.as_string())
    except: pass

def send_approval_email(user_email):
    sender_email = "jeon080423@gmail.com"
    password = "csuh xxru wqdy mttt" 
    recipient_email = user_email
    subject = "[AHP ë¶„ì„ ì‹œìŠ¤í…œ] ì •ì‹ ì‚¬ìš©ì ìŠ¹ì¸ ì™„ë£Œ"
    body = f"{user_email}ë‹˜, ì •ì‹ ì‚¬ìš©ìë¡œ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ë¶€í„° 2ê°œì›”ê°„ ëª¨ë“  ê¸°ëŠ¥ì„ ë¬´ì œí•œìœ¼ë¡œ ì‚¬ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    msg = MIMEText(body)
    msg['Subject'] = subject
    msg['From'] = sender_email
    msg['To'] = recipient_email
    try:
        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:
            server.login(sender_email, password)
            server.sendmail(sender_email, recipient_email, msg.as_string())
        return True
    except: return False

def send_password_recovery_email(user_email, user_pw):
    sender_email = "jeon080423@gmail.com"
    password = "csuh xxru wqdy mttt"
    recipient_email = user_email
    subject = "[AHP ë¶„ì„ ì‹œìŠ¤í…œ] ë¹„ë°€ë²ˆí˜¸ ì•ˆë‚´"
    body = f"""ì•ˆë…•í•˜ì„¸ìš”. ìš”ì²­í•˜ì‹  ê³„ì • ì •ë³´ë¥¼ ì•ˆë‚´í•´ ë“œë¦½ë‹ˆë‹¤.

ID: {user_email}
PW: {user_pw}

ë¡œê·¸ì¸ í›„ ë¹„ë°€ë²ˆí˜¸ë¥¼ ë³€ê²½í•˜ì‹œê¸°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.
ê°ì‚¬í•©ë‹ˆë‹¤.
"""
    msg = MIMEText(body)
    msg['Subject'] = subject
    msg['From'] = sender_email
    msg['To'] = recipient_email
    try:
        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:
            server.login(sender_email, password)
            server.sendmail(sender_email, recipient_email, msg.as_string())
        return True
    except Exception as e:
        return False

# --- DB CRUD ---

def log_to_sheets(user_id, role, signup_date):
    try:
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"], scopes=scope)
        client = gspread.authorize(creds)
        sheet = client.open('AHPkr_Users').sheet1
        sheet.append_row([user_id, role, str(signup_date)])
    except:
        pass
def add_user(user_id, pw, role):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    signup_date = datetime.date.today()
    expiry_date = datetime.date(9999, 12, 31)
    try:
        c.execute("INSERT INTO users VALUES (?, ?, ?, ?, ?)", 
                  (user_id, pw, role, str(signup_date), str(expiry_date)))
        conn.commit()
        log_to_sheets(user_id, role, signup_date)
        success = True
    except sqlite3.IntegrityError:
        success = False
    finally:
        conn.close()
    return success

def check_login(user_id, pw):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("SELECT role, expiry_date FROM users WHERE id=? AND pw=?", (user_id, pw))
    result = c.fetchone()
    conn.close()
    return result

def get_user_password(user_id):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("SELECT pw FROM users WHERE id=?", (user_id,))
    result = c.fetchone()
    conn.close()
    return result[0] if result else None

def change_user_password(user_id, new_pw):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("UPDATE users SET pw=? WHERE id=?", (new_pw, user_id))
    conn.commit()
    conn.close()
    return True

def get_all_users():
    conn = sqlite3.connect('users.db')
    df = pd.read_sql_query("SELECT * FROM users", conn)
    conn.close()
    return df

def update_user_full_info(user_id, new_pw, new_role, new_expiry):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    if new_pw and new_pw.strip() != "":
        c.execute("UPDATE users SET pw=?, role=?, expiry_date=? WHERE id=?", (new_pw, new_role, new_expiry, user_id))
    else:
        c.execute("UPDATE users SET role=?, expiry_date=? WHERE id=?", (new_role, new_expiry, user_id))
    conn.commit()
    conn.close()

def delete_user(user_id):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("DELETE FROM users WHERE id=?", (user_id,))
    c.execute("DELETE FROM saved_analyses WHERE user_id=?", (user_id,))
    c.execute("DELETE FROM user_models WHERE user_id=?", (user_id,))
    conn.commit()
    conn.close()

def save_analysis_to_db(user_id, filename, file_data):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    save_date = str(datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    c.execute("INSERT INTO saved_analyses (user_id, filename, save_date, file_data) VALUES (?, ?, ?, ?)",
              (user_id, filename, save_date, file_data))
    conn.commit()
    conn.close()

def get_user_analyses(user_id):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("SELECT id, filename, save_date FROM saved_analyses WHERE user_id=? ORDER BY save_date DESC", (user_id,))
    rows = c.fetchall()
    conn.close()
    return rows

def get_analysis_file(analysis_id):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("SELECT filename, file_data FROM saved_analyses WHERE id=?", (analysis_id,))
    result = c.fetchone()
    conn.close()
    return result

def delete_analysis(analysis_id):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("DELETE FROM saved_analyses WHERE id=?", (analysis_id,))
    conn.commit()
    conn.close()

def save_user_model(user_id, model_dict):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    model_json = json.dumps(model_dict, ensure_ascii=False)
    c.execute("INSERT OR REPLACE INTO user_models (user_id, model_data) VALUES (?, ?)", (user_id, model_json))
    conn.commit()
    conn.close()

def load_user_model(user_id):
    conn = sqlite3.connect('users.db')
    c = conn.cursor()
    c.execute("SELECT model_data FROM user_models WHERE user_id=?", (user_id,))
    result = c.fetchone()
    conn.close()
    if result:
        return json.loads(result[0])
    return None

# -----------------------------------------------------------------------------
# 1. AHP Functions
# -----------------------------------------------------------------------------
def get_ri(n):
    ri_dict = {1: 0.00, 2: 0.00, 3: 0.58, 4: 0.90, 5: 1.12, 6: 1.24, 7: 1.32, 8: 1.41, 9: 1.45, 10: 1.49}
    return ri_dict.get(n, 1.49)

def calculate_weights(matrix, method='geometric'):
    if method == 'arithmetic':
        col_sum = matrix.sum(axis=0)
        col_sum[col_sum == 0] = 1
        normalized_matrix = matrix / col_sum
        weights = normalized_matrix.mean(axis=1)
    else:
        geom_means = gmean(matrix, axis=1)
        weights = geom_means / geom_means.sum()
    return weights

def calculate_consistency(matrix, method='geometric'):
    n = matrix.shape[0]
    if n <= 2: return 0.0, 0.0, n
    weights = calculate_weights(matrix, method)
    weighted_sum = matrix.dot(weights)
    weights_safe = weights.copy()
    weights_safe[weights_safe == 0] = 1e-10
    lambda_values = weighted_sum / weights_safe
    lambda_max = lambda_values.mean()
    ci = (lambda_max - n) / (n - 1)
    ri = get_ri(n)
    cr = ci / ri if ri > 0 else 0.0
    return cr, ci, lambda_max

def improve_consistency(matrix, threshold, max_iter=500, learning_rate=0.2, method='geometric'):
    current_matrix = matrix.copy()
    n = current_matrix.shape[0]
    cr, ci, _ = calculate_consistency(current_matrix, method)
    iterations = 0
    if cr <= threshold: return current_matrix, cr, iterations, False
    for it in range(max_iter):
        if cr <= threshold: break
        w = calculate_weights(current_matrix, method)
        consistent_matrix = np.outer(w, 1/w)
        new_matrix = (current_matrix * (1 - learning_rate)) + (consistent_matrix * learning_rate)
        for i in range(n):
            new_matrix[i, i] = 1.0
            for j in range(i + 1, n):
                val = new_matrix[i, j]
                new_matrix[j, i] = 1.0 / val
        current_matrix = new_matrix
        cr, ci, _ = calculate_consistency(current_matrix, method)
        iterations += 1
    was_corrected = iterations > 0
    return current_matrix, cr, iterations, was_corrected

def parse_input_value(val):
    if val == 0: return 1.0
    elif val < 0: return abs(val)
    elif val == 1: return 1.0
    else: return 1.0 / val

def infer_factors_from_columns(cols):
    m = len(cols)
    delta = 1 + 8 * m
    n = int((1 + np.sqrt(delta)) / 2)
    extracted_factors = []
    seen = set()
    for c in cols:
        parts = str(c).split('_')
        for p in parts:
            p_str = p.strip()
            if p_str not in seen:
                seen.add(p_str)
                extracted_factors.append(p_str)
    if len(extracted_factors) == n:
        factors = extracted_factors 
    else:
        factors = [f"F{i+1}" for i in range(n)]
    return factors, n

def calculate_pairwise_ttest(df, factors):
    n = len(factors)
    p_values = pd.DataFrame(index=factors, columns=factors)
    weight_cols = [f"Weight_{f}" for f in factors]
    for i in range(n):
        for j in range(n):
            if i == j:
                p_values.iloc[i, j] = 1.0
            else:
                col1 = weight_cols[i]
                col2 = weight_cols[j]
                if col1 in df.columns and col2 in df.columns and len(df) > 1:
                    try:
                        _, p = ttest_rel(df[col1], df[col2], nan_policy='omit')
                        p_values.iloc[i, j] = p
                    except:
                        p_values.iloc[i, j] = np.nan
                else:
                    p_values.iloc[i, j] = np.nan
    return p_values

def process_single_sheet(df, cr_threshold, max_iter, method='geometric'):
    meta_cols = df.columns[:2]
    comp_cols = df.columns[2:]
    factors, n = infer_factors_from_columns(comp_cols)
    results_list = []
    for idx, row in df.iterrows():
        respondent_id = row.iloc[0]
        respondent_type = row.iloc[1]
        matrix = np.eye(n)
        col_idx = 0
        for i in range(n):
            for j in range(i + 1, n):
                if col_idx < len(comp_cols):
                    raw_val = row[comp_cols[col_idx]]
                    ahp_val = parse_input_value(raw_val)
                    matrix[i, j] = ahp_val
                    matrix[j, i] = 1.0 / ahp_val
                    col_idx += 1
        orig_cr, orig_ci, _ = calculate_consistency(matrix, method)
        final_matrix = matrix.copy()
        final_cr = orig_cr
        iterations = 0
        corrected_flag = False
        if orig_cr > cr_threshold:
            final_matrix, final_cr, iterations, corrected_flag = improve_consistency(
                matrix, cr_threshold, max_iter=max_iter, method=method
            )
        _, final_ci, _ = calculate_consistency(final_matrix, method)
        final_weights = calculate_weights(final_matrix, method)
        res = {
            "ID": respondent_id,
            "Type": respondent_type,
            "Original_CR": orig_cr,
            "Final_CR": final_cr,
            "Original_CI": orig_ci,
            "Final_CI": final_ci,
            "Iterations": iterations,
            "Corrected": corrected_flag,
            "Matrix_Object": final_matrix 
        }
        for f_idx, f_name in enumerate(factors):
            res[f"Weight_{f_name}"] = final_weights[f_idx]
        results_list.append(res)
    results_df = pd.DataFrame(results_list)
    return results_df, factors

def create_sample_excel():
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        main_cols = ["ID", "Type", "ê±°ë²„ë„ŒìŠ¤_ê³„íšíƒ€ë‹¹ì„±", "ê±°ë²„ë„ŒìŠ¤_ì‹¤í˜„ê°€ëŠ¥ì„±", "ê±°ë²„ë„ŒìŠ¤_ì‚¬ì—…íš¨ê³¼", 
                      "ê³„íšíƒ€ë‹¹ì„±_ì‹¤í˜„ê°€ëŠ¥ì„±", "ê³„íšíƒ€ë‹¹ì„±_ì‚¬ì—…íš¨ê³¼", "ì‹¤í˜„ê°€ëŠ¥ì„±_ì‚¬ì—…íš¨ê³¼"]
        main_data = [
            [1, "ì „ë¬¸ê°€", 5, -5, 5, 5, -5, 5],      
            [2, "ì „ë¬¸ê°€", 7, 7, -7, -7, 2, -2],   
            [3, "ì¼ë°˜", -5, 5, 5, -5, 5, 5],
            [4, "ì¼ë°˜", 3, -3, 3, -3, 3, -3],
            [5, "ê³µë¬´ì›", 9, -9, 9, -9, 9, -9]
        ]
        df_main = pd.DataFrame(main_data, columns=main_cols)
        df_main.to_excel(writer, sheet_name="Main_Criteria", index=False)
        
        inconsistent_pattern = [
            [1, "ì „ë¬¸ê°€", 5, -5, 5],
            [2, "ì „ë¬¸ê°€", 7, -7, 7],
            [3, "ì¼ë°˜", 3, -3, 3],
            [4, "ì¼ë°˜", 9, -9, 9],
            [5, "ê³µë¬´ì›", 4, -4, 4]
        ]
        sub1_cols = ["ID", "Type", "í–‰ì •ì§€ì›_ì§€ì—­ê³µë™ì²´", "í–‰ì •ì§€ì›_ì´ê´„ì‚¬ì—…ê´€ë¦¬ì", "ì§€ì—­ê³µë™ì²´_ì´ê´„ì‚¬ì—…ê´€ë¦¬ì"]
        pd.DataFrame(inconsistent_pattern, columns=sub1_cols).to_excel(writer, sheet_name="ê±°ë²„ë„ŒìŠ¤", index=False)
        sub2_cols = ["ID", "Type", "í˜„ì•ˆì ì •ì„±_ëŒ€ì•ˆì ì •ì„±", "í˜„ì•ˆì ì •ì„±_ëª©í‘œêµ¬ì²´ì„±", "ëŒ€ì•ˆì ì •ì„±_ëª©í‘œêµ¬ì²´ì„±"]
        pd.DataFrame(inconsistent_pattern, columns=sub2_cols).to_excel(writer, sheet_name="ê³„íšíƒ€ë‹¹ì„±", index=False)
        sub3_cols = ["ID", "Type", "ë¶€ì§€í™•ë³´_ì‚¬ì—…êµ¬ì²´í™”", "ë¶€ì§€í™•ë³´_ì‚¬ì—…ë¹„ì ì •ì„±", "ì‚¬ì—…êµ¬ì²´í™”_ì‚¬ì—…ë¹„ì ì •ì„±"]
        pd.DataFrame(inconsistent_pattern, columns=sub3_cols).to_excel(writer, sheet_name="ì‹¤í˜„ê°€ëŠ¥ì„±", index=False)
        sub4_cols = ["ID", "Type", "ê²½ì œì íš¨ê³¼_ì‚¬íšŒì íš¨ê³¼", "ê²½ì œì íš¨ê³¼_ì„±ê³¼ê´€ë¦¬", "ì‚¬íšŒì íš¨ê³¼_ì„±ê³¼ê´€ë¦¬"]
        pd.DataFrame(inconsistent_pattern, columns=sub4_cols).to_excel(writer, sheet_name="ì‚¬ì—…íš¨ê³¼", index=False)
    output.seek(0)
    return output

def calculate_anova_and_posthoc(full_data):
    results = []
    unique_factors = full_data['Factor'].unique()
    
    for factor in unique_factors:
        subset = full_data[full_data['Factor'] == factor]
        groups = [group['Global_Weight'].values for name, group in subset.groupby('Type')]
        
        if len(groups) < 2:
            continue
            
        f_stat, p_val = f_oneway(*groups)
        
        row = {
            "ìš”ì¸": factor,
            "F-Statistic": f_stat,
            "P-Value": p_val,
            "ìœ ì˜ì„±": "ìœ ì˜í•¨" if p_val < 0.05 else "ìœ ì˜í•˜ì§€ ì•ŠìŒ",
            "ì‚¬í›„ê²€ì •(Tukey HSD)": ""
        }
        
        if p_val < 0.05 and STATSMODELS_AVAILABLE:
            try:
                tukey = pairwise_tukeyhsd(endog=subset['Global_Weight'], groups=subset['Type'], alpha=0.05)
                tukey_df = pd.DataFrame(data=tukey.summary().data[1:], columns=tukey.summary().data[0])
                sig_pairs = tukey_df[tukey_df['reject'] == True]
                if not sig_pairs.empty:
                    pairs_str = []
                    for _, r in sig_pairs.iterrows():
                        pairs_str.append(f"{r['group1']} vs {r['group2']}")
                    row["ì‚¬í›„ê²€ì •(Tukey HSD)"] = ", ".join(pairs_str) + " ì°¨ì´ ìˆìŒ"
                else:
                    row["ì‚¬í›„ê²€ì •(Tukey HSD)"] = "ì§‘ë‹¨ ê°„ êµ¬ì²´ì  ì°¨ì´ ë°œê²¬ ëª»í•¨"
            except Exception as e:
                row["ì‚¬í›„ê²€ì •(Tukey HSD)"] = "ê³„ì‚° ì˜¤ë¥˜"
        
        results.append(row)
        
    return pd.DataFrame(results)

# -----------------------------------------------------------------------------
# 2. Setup & Layout
# -----------------------------------------------------------------------------

init_db()

try:
    icon_img = Image.open("image_4.png")
    st.set_page_config(page_title="AHP Analysis Tool", layout="wide", page_icon=icon_img)
except FileNotFoundError:
    st.set_page_config(page_title="AHP Analysis Tool", layout="wide", page_icon="ğŸ“Š")

# CSS ìµœì í™”
st.markdown("""
<style>
    .stDataFrame {font-size: 0.9rem;} 
    div[data-testid="stMetricValue"] {font-size: 1.2rem;}
</style>
""", unsafe_allow_html=True)

if 'user_id' not in st.session_state: st.session_state.user_id = None
if 'user_role' not in st.session_state: st.session_state.user_role = None
if 'expiry_date' not in st.session_state: st.session_state.expiry_date = None
if 'admin_mode' not in st.session_state: st.session_state.admin_mode = False
if 'model_structure' not in st.session_state: st.session_state.model_structure = {}

col_h1, col_h2 = st.columns([1, 15])
with col_h1:
    try: 
        st.image("image_4.png", width=80) 
    except: 
        st.header("ğŸ“Š")
with col_h2:
    st.title("AHP ë¶„ì„ ìë™í™” ì‹œìŠ¤í…œ")

st.markdown("Analytic Hierarchy Process (AHP) ë¶„ì„ ë° ì¼ê´€ì„± ìë™ ë³´ì • ë„êµ¬ì…ë‹ˆë‹¤. ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ê°œì¸ë³„ ê°€ì¤‘ì¹˜ ì‚°ì¶œ, ì¼ê´€ì„± ë³´ì •(CR), ê·¸ë£¹ë³„ ì§‘ê³„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")

# =============================================================================
# 3. Sidebar (Auth & Settings)
# =============================================================================

# ì´ìš© ìš”ê¸ˆ ê³µí†µ ì•ˆë‚´ í…ìŠ¤íŠ¸ ì •ì˜
fee_info_text = """
---
### ğŸ’° ì„œë¹„ìŠ¤ ì´ìš© ê¸ˆì•¡ ì•ˆë‚´
- **í•™ìœ„ë…¼ë¬¸ ë¶„ì„**: 40ë§Œì›
- **ì¼ë°˜ ì—°êµ¬ ë¶„ì„**: 50ë§Œì›

**ê²°ì œ ì •ë³´**
- **ê³„ì¢Œë²ˆí˜¸**: ì¹´ì¹´ì˜¤ë±…í¬ 333-26-7331429
- **ì˜ˆê¸ˆì£¼**: ì „ìƒí˜„(í”„ë ˆì‰¬í‘¸ë“œ)
- **ì£¼ì˜**: ì†¡ê¸ˆìëª…ì— **ê°€ì…í•œ ì´ë©”ì¼ ì£¼ì†Œ**ë¥¼ ê¸°ì…í•´ì£¼ì„¸ìš”.
"""

with st.sidebar:
    with st.expander("ğŸ’¡ ì‚¬ìš©ì ê¶Œí•œ ì•ˆë‚´", expanded=False):
        st.info("**ë¹„ë¡œê·¸ì¸(Guest)**: ìƒ˜í”Œ íŒŒì¼ ë¶„ì„ë§Œ ê°€ëŠ¥ (5í–‰ ì œí•œ)")
        st.info("**ì„ì‹œ ì‚¬ìš©ì**: ë‚˜ë§Œì˜ ëª¨ë¸ ìƒì„± ê°€ëŠ¥, ë¶„ì„ 5í–‰ ì œí•œ")
        st.info("**ì •ì‹ ì‚¬ìš©ì**: ëª¨ë“  ê¸°ëŠ¥ ë¬´ì œí•œ (2ê°œì›”)")
        st.info("**ê´€ë¦¬ì**: ëª¨ë“  ê¸°ëŠ¥ ë¬´ì œí•œ + ê´€ë¦¬ì ë„êµ¬")

    if st.session_state.user_id is None:
        tab_login, tab_signup, tab_find_pw = st.tabs(["ë¡œê·¸ì¸", "íšŒì›ê°€ì…", "ë¹„ë°€ë²ˆí˜¸ ì°¾ê¸°"])
        
        with tab_login:
            st.header("ğŸ” ë¡œê·¸ì¸")
            l_id = st.text_input("ì•„ì´ë”” (ì´ë©”ì¼ ì£¼ì†Œ)", key="l_id")
            l_pw = st.text_input("ë¹„ë°€ë²ˆí˜¸ (PW)", type="password", key="l_pw")
            if st.button("ë¡œê·¸ì¸ ì‹¤í–‰"):
                result = check_login(l_id.strip(), l_pw.strip())
                if result:
                    # ë§Œë£Œ ì²´í¬ ë¡œì§
                    today = datetime.date.today()
                    expiry_date = datetime.datetime.strptime(result[1], "%Y-%m-%d").date()
                    if today > expiry_date:
                        st.error(f"âŒ ì´ìš© ê¸°ê°„ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (ë§Œë£Œì¼: {result[1]})")
                    else:
                        st.session_state.user_id = l_id.strip()
                        st.session_state.user_role = result[0]
                        st.session_state.expiry_date = result[1]
                        st.success(f"í™˜ì˜í•©ë‹ˆë‹¤, {l_id}ë‹˜!")
                        st.rerun()
                else:
                    st.error("ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
            # [ì¶”ê°€] ë¡œê·¸ì¸ íƒ­ ë‚´ ì„œë¹„ìŠ¤ ì´ìš© ìš”ê¸ˆ ì•ˆë‚´
            st.markdown(fee_info_text)

        with tab_signup:
            st.header("ğŸ“ íšŒì›ê°€ì…")
            s_id = st.text_input("ì•„ì´ë”” (ì´ë©”ì¼ ì£¼ì†Œ)", key="s_id")
            s_pw = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="s_pw")
            s_role_selection = st.radio("ì´ìš© ê¶Œí•œ ì„ íƒ", ("ì„ì‹œ ì‚¬ìš©ì (5 Sample)", "ì •ì‹ ì‚¬ìš©ì (2ê°œì›” ë¬´ì œí•œ)"), index=0)
            
            if "ì •ì‹" in s_role_selection:
                st.warning("âš ï¸ ì •ì‹ ì‚¬ìš©ì ê°€ì… ì•ˆë‚´")
                st.info("ì •ì‹ ì‚¬ìš©ì ì‹ ì²­ ì‹œ ì¦‰ì‹œ **ì„ì‹œ ì‚¬ìš©ì** ê¶Œí•œì´ ë¶€ì—¬ë©ë‹ˆë‹¤.")
                st.info("ê´€ë¦¬ìê°€ ì…ê¸ˆ í™•ì¸ í›„ **ì •ì‹ ì‚¬ìš©ì**ë¡œ ê¶Œí•œì„ ìŠ¹ì¸í•˜ë©°(ìŠ¹ì¸ ì‹œì ë¶€í„° 2ê°œì›”ë¡œ ì œí•œ), ìŠ¹ì¸ ì™„ë£Œ ì‹œ ì´ë©”ì¼ë¡œ ì•Œë¦¼ì„ ë³´ë‚´ ë“œë¦½ë‹ˆë‹¤.")
            
            if st.button("ê°€ì…ì‹ ì²­"):
                if not validate_email(s_id): st.error("ì˜¬ë°”ë¥¸ ì´ë©”ì¼ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                elif not validate_password(s_pw): st.error("ë¹„ë°€ë²ˆí˜¸ëŠ” ë¬¸ì+íŠ¹ìˆ˜ë¬¸ìì—¬ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    initial_role = 'temp' 
                    if add_user(s_id.strip(), s_pw.strip(), initial_role):
                        if "ì •ì‹" in s_role_selection:
                            send_application_email(s_id)
                            st.success("ê°€ì… ì‹ ì²­ ì ‘ìˆ˜ë¨ (ì…ê¸ˆ í™•ì¸ ì „ê¹Œì§€ ì„ì‹œ ê¶Œí•œ ë¶€ì—¬)")
                        else:
                            st.success("ê°€ì… ì™„ë£Œ!")
                    else:
                        st.error("ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì•„ì´ë””ì…ë‹ˆë‹¤.")
            
            # íšŒì›ê°€ì… íƒ­ ë‚´ ì„œë¹„ìŠ¤ ì´ìš© ìš”ê¸ˆ ì•ˆë‚´
            st.markdown(fee_info_text)

        with tab_find_pw:
            st.header("ğŸ”‘ ë¹„ë°€ë²ˆí˜¸ ì°¾ê¸°")
            st.write("ê°€ì… ì‹œ ì‚¬ìš©í•œ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            f_id = st.text_input("ê°€ì…í•œ ì•„ì´ë”” (ì´ë©”ì¼)", key="f_id")
            if st.button("ë¹„ë°€ë²ˆí˜¸ ì´ë©”ì¼ ì „ì†¡"):
                if not f_id:
                    st.warning("ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    found_pw = get_user_password(f_id.strip())
                    if found_pw:
                        if send_password_recovery_email(f_id.strip(), found_pw):
                            st.success(f"'{f_id}'ë¡œ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì „ì†¡í–ˆìŠµë‹ˆë‹¤.\nì´ë©”ì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                        else:
                            st.error("ì´ë©”ì¼ ì „ì†¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.error("ë“±ë¡ë˜ì§€ ì•Šì€ ì•„ì´ë””ì…ë‹ˆë‹¤.")

    else:
        st.success(f"**{st.session_state.user_id}** ë‹˜")
        role_disp = "ê´€ë¦¬ì" if st.session_state.user_role == 'admin' else ("ì •ì‹ ì‚¬ìš©ì" if st.session_state.user_role == 'official' else "ì„ì‹œ ì‚¬ìš©ì")
        st.info(f"ê¶Œí•œ: {role_disp}")
        
        if st.session_state.expiry_date:
            st.warning(f"ğŸ“… ì‚¬ìš© ë§Œë£Œì¼: {st.session_state.expiry_date}")
        
        if st.session_state.user_role == 'admin':
            if st.button("ğŸ”§ ê´€ë¦¬ì í™”ë©´ ì ‘ì†"):
                st.session_state.admin_mode = not st.session_state.admin_mode
                st.rerun()

        with st.expander("ğŸ” ë¹„ë°€ë²ˆí˜¸ ë³€ê²½"):
            cur_pw = st.text_input("í˜„ì¬ ë¹„ë°€ë²ˆí˜¸", type="password", key="chg_cur")
            new_pw = st.text_input("ìƒˆ ë¹„ë°€ë²ˆí˜¸", type="password", key="chg_new")
            confirm_pw = st.text_input("ìƒˆ ë¹„ë°€ë²ˆí˜¸ í™•ì¸", type="password", key="chg_conf")
            
            if st.button("ë¹„ë°€ë²ˆí˜¸ ë³€ê²½"):
                if new_pw != confirm_pw:
                    st.error("ìƒˆ ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                elif not validate_password(new_pw):
                    st.error("ë¹„ë°€ë²ˆí˜¸ëŠ” 4ì ì´ìƒ, ì˜ë¬¸+íŠ¹ìˆ˜ë¬¸ìë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    chk_res = check_login(st.session_state.user_id, cur_pw)
                    if chk_res:
                        change_user_password(st.session_state.user_id, new_pw)
                        st.success("ë¹„ë°€ë²ˆí˜¸ê°€ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.error("í˜„ì¬ ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        if st.button("ë¡œê·¸ì•„ì›ƒ"):
            st.session_state.user_id = None
            st.session_state.user_role = None
            st.session_state.expiry_date = None
            st.session_state.admin_mode = False
            st.rerun()

    st.markdown("---")
    st.header("ë¶„ì„ ì„¤ì •")
    mean_method_label = st.radio("í‰ê·  ì‚°ì¶œ ë°©ì‹", ('ê¸°í•˜í‰ê·  (Geometric)', 'ì‚°ìˆ í‰ê·  (Arithmetic)'), index=0)
    mean_method = 'geometric' if 'ê¸°í•˜' in mean_method_label else 'arithmetic'
    cr_threshold = st.selectbox("ì¼ê´€ì„± ë¹„ìœ¨(CR) ì„ê³„ê°’", [0.1, 0.2], index=0)
    max_iter = st.number_input("ìµœëŒ€ ë³´ì • ë°˜ë³µ íšŸìˆ˜", min_value=10, max_value=2000, value=500, step=50)

    st.markdown("---")
    with st.expander("â„¹ï¸ ì¼ê´€ì„± ë³´ì • ì•ˆë‚´", expanded=False):
        st.markdown("""
        **ë³´ì • ë°©ë²•: ë°˜ë³µ ìˆ˜ë ´ ì¡°ì •ë²•(Iterative Adjustment)**
        íŒë‹¨ í–‰ë ¬ì´ ë¹„ì¼ê´€ì (CR > ì„ê³„ê°’)ì¸ ê²½ìš°, ìˆ˜í•™ì ìœ¼ë¡œ ì¼ê´€ëœ í–‰ë ¬ê³¼ ì›ë³¸ í–‰ë ¬ì„ ì¼ì • ë¹„ìœ¨ë¡œ í˜¼í•©í•˜ì—¬ ë°˜ë³µì ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ë¯¸ì„¸ ì¡°ì •í•œ ê²°ê³¼ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
        
        **í˜„ì¬ ë°©ë²•ì˜ íŠ¹ì§•:**
        1. **ìµœì†Œ íŒë‹¨ ì™œê³¡**: ì›ë³¸ ì„¤ë¬¸ ì‘ë‹µì˜ ê²½í–¥ì„±ì„ ìµœëŒ€í•œ ë³´ì¡´í•˜ë©´ì„œ ìˆ˜í•™ì  ì¼ê´€ì„±ë§Œì„ í™•ë³´í•©ë‹ˆë‹¤.
        2. **ìë™ ìˆ˜ë ´**: ì„¤ì •ëœ ë°˜ë³µ íšŸìˆ˜ ë‚´ì—ì„œ CR ê°’ì„ ì„ê³„ê°’ ì´í•˜ë¡œ ìë™ ê°œì„ í•©ë‹ˆë‹¤.
        """)

# =============================================================================
# 4. Main Content Logic
# =============================================================================

# CASE: Admin Mode
if st.session_state.get('admin_mode', False) and st.session_state.user_role == 'admin':
    st.subheader("ğŸ‘¥ ê°€ì…ì í˜„í™© ë° ê´€ë¦¬")
    try:
        conn = sqlite3.connect('users.db')
        c = conn.cursor()
        c.execute("SELECT COUNT(*) FROM visit_logs")
        total_visits = c.fetchone()[0]
        daily_df = pd.read_sql_query("SELECT visit_date, COUNT(*) as count FROM visit_logs GROUP BY visit_date ORDER BY visit_date ASC", conn)
        conn.close()
        st.write(f"**ì´ ëˆ„ì  ë°©ë¬¸ì ìˆ˜:** {total_visits:,}ëª…")
        st.write("#### ğŸ“… ì¼ë³„ ë°©ë¬¸ì í˜„í™©")
        if not daily_df.empty:
            st.bar_chart(daily_df.set_index("visit_date"))
        else:
            st.info("ë°©ë¬¸ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"í†µê³„ ì˜¤ë¥˜: {e}")
    st.divider()
    
    users_df = get_all_users()
    st.dataframe(users_df)

    with st.expander("íšŒì› ì •ë³´ ìˆ˜ì • (ë¹„ë°€ë²ˆí˜¸ ì´ˆê¸°í™” í¬í•¨)"):
        edit_id = st.selectbox("ìˆ˜ì •í•  íšŒì› ID", users_df['id'].unique())
        selected_user = users_df[users_df['id'] == edit_id].iloc[0]
        new_role = st.selectbox("ê¶Œí•œ ë³€ê²½", ['temp', 'official', 'admin'], 
                                index=['temp', 'official', 'admin'].index(selected_user['role']))
        
        # ê´€ë¦¬ìê°€ 'official'ë¡œ ë³€ê²½í•  ë•Œ 2ê°œì›” ê¸°í•œ ì œì•ˆ
        if new_role == 'official' and selected_user['role'] != 'official':
            suggested_date = datetime.date.today() + relativedelta(months=2)
            new_expiry = st.text_input("ë§Œë£Œì¼ ì„¤ì • (YYYY-MM-DD) - 2ê°œì›” ê¸°í•œ ìë™ ì œì•ˆë¨", value=str(suggested_date))
        else:
            new_expiry = st.text_input("ë§Œë£Œì¼ ë³€ê²½ (YYYY-MM-DD)", value=selected_user['expiry_date'])
            
        new_pw = st.text_input("ìƒˆ ë¹„ë°€ë²ˆí˜¸ (ì…ë ¥ ì‹œ ë³€ê²½ë¨)", type="password", placeholder="ë³€ê²½í•˜ì§€ ì•Šìœ¼ë ¤ë©´ ë¹„ì›Œë‘ì„¸ìš”")
        
        if st.button("ì •ë³´ ìˆ˜ì • ì ìš©"):
            update_user_full_info(edit_id, new_pw, new_role, new_expiry)
            if new_role == 'official' and selected_user['role'] != 'official':
                send_approval_email(edit_id)
            st.success(f"{edit_id} íšŒì›ì˜ ì •ë³´ê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()
    
    with st.expander("íšŒì› ì‚­ì œ"):
        del_id = st.selectbox("ì‚­ì œí•  íšŒì› ID ì„ íƒ", users_df['id'].unique(), key='del_user_select')
        if st.button("ì„ íƒí•œ íšŒì› ì‚­ì œ"):
            if del_id == st.session_state.user_id:
                st.error("ë³¸ì¸ì€ ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                delete_user(del_id)
                st.success("ì‚­ì œ ì™„ë£Œ")
                st.rerun()
    st.divider()

# CASE: Analysis View (Everyone)
st.subheader("1. AHP ë¶„ì„ ëª¨ë¸ ì„¤ì • ë° ì…ë ¥ í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ")

if st.session_state.user_id is None:
    st.info("ğŸ”’ **ë¡œê·¸ì¸ í›„** 'ë‚˜ë§Œì˜ ë¶„ì„ ëª¨ë¸'ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ë¹„ë¡œê·¸ì¸ ìƒíƒœì—ì„œëŠ” ê¸°ë³¸ ëª¨ë¸ ë° ìƒ˜í”Œ ë°ì´í„°ë§Œ ì œê³µ)")
else:
    saved_model = load_user_model(st.session_state.user_id)
    default_main = "ê±°ë²„ë„ŒìŠ¤, ê³„íšíƒ€ë‹¹ì„±, ì‹¤í˜„ê°€ëŠ¥ì„±, ì‚¬ì—…íš¨ê³¼"
    default_subs = {
        "ê±°ë²„ë„ŒìŠ¤": "í–‰ì •ì§€ì›, ì§€ì—­ê³µë™ì²´, ì´ê´„ì‚¬ì—…ê´€ë¦¬ì",
        "ê³„íšíƒ€ë‹¹ì„±": "í˜„ì•ˆì ì •ì„±, ëŒ€ì•ˆì ì •ì„±, ëª©í‘œêµ¬ì²´ì„±",
        "ì‹¤í˜„ê°€ëŠ¥ì„±": "ë¶€ì§€í™•ë³´, ì‚¬ì—…êµ¬ì²´í™”, ì‚¬ì—…ë¹„ì ì •ì„±",
        "ì‚¬ì—…íš¨ê³¼": "ê²½ì œì íš¨ê³¼, ì‚¬íšŒì íš¨ê³¼, ì„±ê³¼ê´€ë¦¬"
    }
    
    if saved_model:
        default_main = saved_model.get('main', default_main)
        default_subs = saved_model.get('subs', default_subs)

    with st.expander("ğŸ“Œ ë‚˜ì˜ ë¶„ì„ ëª¨ë¸ ë§Œë“¤ê¸°", expanded=False):
        st.info("ëŒ€í•­ëª©ê³¼ ì„¸ë¶€í•­ëª©ì„ ì…ë ¥í•˜ì—¬ ë‚˜ë§Œì˜ ì…ë ¥ ì—‘ì…€ í…œí”Œë¦¿ì„ ìƒì„±í•˜ì„¸ìš”.\n\ní˜„ì¬ ì…ë ¥ë˜ì–´ ìˆëŠ” ë‚´ìš©ì€ ìƒ˜í”Œ ëª¨ë¸ì…ë‹ˆë‹¤. ì‚­ì œí•˜ì‹œê³  ì´ìš©ìë‹˜ì˜ AHP ëª¨ë¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
        main_criteria_input = st.text_input("ëŒ€í•­ëª© (Main Criteria, ì½¤ë§ˆ êµ¬ë¶„)", value=default_main)
        main_criteria_list = [x.strip() for x in main_criteria_input.split(',') if x.strip()]
        
        model_structure = {}
        if main_criteria_list:
            for mc in main_criteria_list:
                d_val = default_subs.get(mc, "")
                if isinstance(d_val, list): d_val = ", ".join(d_val)
                sub_input = st.text_input(f"'{mc}'ì˜ ì„¸ë¶€í•­ëª©", value=d_val, key=f"sub_{mc}")
                sub_list = [x.strip() for x in sub_input.split(',') if x.strip()]
                model_structure[mc] = sub_list
        
        if st.button("ì„¤ì •í•œ ëª¨ë¸ë¡œ ì…ë ¥ ì—‘ì…€ í…œí”Œë¦¿ ìƒì„±"):
            if not main_criteria_list:
                st.error("ëŒ€í•­ëª© ì…ë ¥ í•„ìš”")
            else:
                current_model = {'main': main_criteria_input, 'subs': model_structure}
                save_user_model(st.session_state.user_id, current_model)
                st.toast("ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
                
                output_template = io.BytesIO()
                with pd.ExcelWriter(output_template, engine='xlsxwriter') as writer:
                    main_pairs = list(itertools.combinations(main_criteria_list, 2))
                    main_cols = ["ID", "Type"] + [f"{a}_{b}" for a, b in main_pairs]
                    df_template_main = pd.DataFrame(columns=main_cols)
                    df_template_main.loc[0] = [1, ""] + [0]*len(main_pairs)
                    df_template_main.to_excel(writer, sheet_name="Main_Criteria", index=False)
                    
                    for mc, subs in model_structure.items():
                        if len(subs) < 2:
                            df_sub = pd.DataFrame(columns=["ID", "Type"])
                        else:
                            sub_pairs = list(itertools.combinations(subs, 2))
                            sub_cols = ["ID", "Type"] + [f"{a}_{b}" for a, b in sub_pairs]
                            df_sub = pd.DataFrame(columns=sub_cols)
                            df_sub.loc[0] = [1, ""] + [0]*len(sub_pairs)
                        safe_sheet_name = mc[:31]
                        df_sub.to_excel(writer, sheet_name=safe_sheet_name, index=False)
                output_template.seek(0)
                st.download_button(
                    label="ğŸ“¥ ì—‘ì…€ í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ",
                    data=output_template,
                    file_name="AHP_Custom_Template.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

                st.markdown("""
                ---
                ### ğŸ“ ë°ì´í„° ì…ë ¥ ê°€ì´ë“œ
                1. **ì—‘ì…€ íŒŒì¼ ì—´ê¸°**: ìœ„ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‹¤ìš´ë¡œë“œí•œ ì—‘ì…€ íŒŒì¼ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
                2. **ìŒëŒ€ë¹„êµ ë°ì´í„° ì…ë ¥**:
                    - **ì™¼ìª½** í•­ëª©ì´ ë” ì¤‘ìš”í•˜ë©´: **ìŒìˆ˜** ì…ë ¥ (ì˜ˆ: -3)
                    - **ì˜¤ë¥¸ìª½** í•­ëª©ì´ ë” ì¤‘ìš”í•˜ë©´: **ì–‘ìˆ˜** ì…ë ¥ (ì˜ˆ: 3)
                    - **ë™ë“±**í•˜ë©´: `1` ì…ë ¥
                3. **í•„ìˆ˜ ì •ë³´ ì…ë ¥**: Aì—´(ID), **Bì—´(Type)ì— ê·¸ë£¹ëª… ì…ë ¥ (ì˜ˆ: ì „ë¬¸ê°€, ì£¼ë¯¼ ë“±)**
                """)
                if os.path.exists("ahp_input_guide.png"):
                    st.image("ahp_input_guide.png", caption="[ì°¸ê³ ] ì„¤ë¬¸ ì‘ë‹µì„ ì—‘ì…€ì— ì…ë ¥í•˜ëŠ” ë°©ë²•")

st.markdown("---")

if st.session_state.user_role == 'official':
    with st.expander("ğŸ“‚ ë‚˜ì˜ ë¶„ì„ ë³´ê´€í•¨"):
        my_analyses = get_user_analyses(st.session_state.user_id)
        if not my_analyses: st.info("ì €ì¥ëœ ë¶„ì„ ì—†ìŒ")
        else:
            for item in my_analyses:
                a_id, filename, save_date = item
                col_List1, col_List2, col_List3, col_List4 = st.columns([3, 2, 1, 1])
                with col_List1: st.text(f"{filename}")
                with col_List2: st.caption(f"{save_date}")
                with col_List3:
                    file_info = get_analysis_file(a_id)
                    if file_info:
                        fname, fdata = file_info
                        st.download_button("â¬‡ï¸", fdata, fname, "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", key=f"dl_{a_id}")
                with col_List4:
                    if st.button("ğŸ—‘ï¸", key=f"del_{a_id}"):
                        delete_analysis(a_id)
                        st.rerun()

with st.container(border=True):
    st.markdown("#### âš¡ ë¹ ë¥¸ ì‹œì‘ (ë„ì‹œì¬ìƒ ë‰´ë”œì‚¬ì—… ëª¨ë¸)")
    st.info("ì•„ë˜ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì—‘ì…€ íŒŒì¼ì´ ë‹¤ìš´ë¡œë“œ ë©ë‹ˆë‹¤.\n\n"
            "ë‹¤ìš´ë°›ì€ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ì—‘ì…€ íŒŒì¼ì„ ì•„ë˜ 2. ë°ì´í„° ì—…ë¡œë“œ ë° ë¶„ì„ì— ë“œë¡­ë‹¤ìš´ í•˜ê±°ë‚˜ íŒŒì¼ì„ ì°¾ì•„ ì—…ë¡œë“œ í•˜ì„¸ìš”.")
    
    sample_excel = create_sample_excel()
    st.download_button(
        label="ğŸ“‚ í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ (CR > 0.3, 5 Rows)",
        data=sample_excel,
        file_name="AHP_UrbanRegeneration_Sample.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

st.markdown("---")

# ì—‘ì…€ ë³‘í•© ì¶œë ¥ ë° ë³‘í•© ì„œì‹ í•¨ìˆ˜
def write_custom_ahp_table(writer, sheet_name, df, title_text, start_row, formats):
    workbook = writer.book
    if sheet_name in writer.sheets: worksheet = writer.sheets[sheet_name]
    else:
        worksheet = workbook.add_worksheet(sheet_name)
        writer.sheets[sheet_name] = worksheet
    
    header_fmt = formats['header']
    merge_fmt = formats['merge']
    body_fmt = formats['body']
    num_fmt = formats['num']
    sum_row_fmt = formats['sum_row']
    
    worksheet.merge_range(start_row, 0, start_row, 6, title_text, workbook.add_format({'bold': True, 'font_size': 12}))
    start_row += 1
    
    headers = ["ëŒ€ë¶„ë¥˜", "ê°€ì¤‘ì¹˜(a)", "ì¤‘ë¶„ë¥˜", "ê°€ì¤‘ì¹˜(b)", "ì¢…í•© ê°€ì¤‘ì¹˜(a x b)", "ì¢…í•© ìˆœìœ„", "ë¹„ê³ "]
    for col, h in enumerate(headers):
        worksheet.write(start_row, col, h, header_fmt)
    start_row += 1
    
    main_criteria = df['ëŒ€ë¶„ë¥˜'].unique()
    current_row = start_row
    
    for main_c in main_criteria:
        sub_df = df[df['ëŒ€ë¶„ë¥˜'] == main_c]
        n_subs = len(sub_df)
        main_w = sub_df.iloc[0]['ëŒ€ë¶„ë¥˜ ê°€ì¤‘ì¹˜']
        sub_cr = sub_df.iloc[0]['CR(ì¤‘ë¶„ë¥˜)']
        sum_sub_w = sub_df['ì¤‘ë¶„ë¥˜ ê°€ì¤‘ì¹˜'].sum()
        
        merge_span = n_subs + 2 
        if merge_span > 1:
            worksheet.merge_range(current_row, 0, current_row + merge_span - 1, 0, main_c, merge_fmt)
            worksheet.merge_range(current_row, 1, current_row + merge_span - 1, 1, main_w, num_fmt)
        else:
            worksheet.write(current_row, 0, main_c, merge_fmt)
            worksheet.write(current_row, 1, main_w, num_fmt)
            
        for idx, row in sub_df.iterrows():
            worksheet.write(current_row, 2, row['ì¤‘ë¶„ë¥˜'], body_fmt)
            worksheet.write(current_row, 3, row['ì¤‘ë¶„ë¥˜ ê°€ì¤‘ì¹˜'], num_fmt)
            worksheet.write(current_row, 4, row['Global Weight'], num_fmt)
            worksheet.write(current_row, 5, row['Global Rank'], body_fmt)
            worksheet.write(current_row, 6, "", body_fmt)
            current_row += 1
        
        worksheet.write(current_row, 2, "í•©ê³„", sum_row_fmt)
        worksheet.write(current_row, 3, sum_sub_w, formats['sum_val'])
        worksheet.write_blank(current_row, 4, "", sum_row_fmt)
        worksheet.write_blank(current_row, 5, "", sum_row_fmt)
        worksheet.write_blank(current_row, 6, "", sum_row_fmt)
        current_row += 1
        
        worksheet.write(current_row, 2, "ì¼ê´€ì„± ë¹„ìœ¨(CR)", sum_row_fmt)
        worksheet.write(current_row, 3, sub_cr, formats['num_sum'])
        worksheet.write_blank(current_row, 4, "", sum_row_fmt)
        worksheet.write_blank(current_row, 5, "", sum_row_fmt)
        worksheet.write_blank(current_row, 6, "", sum_row_fmt)
        current_row += 1

    worksheet.write(current_row, 0, "í•©ê³„", sum_row_fmt)
    worksheet.write(current_row, 1, 1, formats['sum_val'])
    worksheet.write(current_row, 2, "í•©ê³„", sum_row_fmt)
    worksheet.write_blank(current_row, 3, "", sum_row_fmt)
    worksheet.write(current_row, 4, 1, formats['sum_val'])
    worksheet.write_blank(current_row, 5, "", sum_row_fmt)
    worksheet.write_blank(current_row, 6, "", sum_row_fmt)
    
    worksheet.set_column('A:A', 15)
    worksheet.set_column('B:B', 12)
    worksheet.set_column('C:C', 25)
    worksheet.set_column('D:F', 12)
    return current_row + 2

def add_borders_to_data(worksheet, start_row, start_col, df, border_fmt, has_header=True, has_index=False):
    rows = len(df) + (1 if has_header else 0)
    cols = len(df.columns) + (1 if has_index else 0)
    worksheet.conditional_format(start_row, start_col, start_row+rows-1, start_col+cols-1,
                                   {'type': 'formula', 'criteria': '=TRUE', 'format': border_fmt})

st.subheader("2. ë°ì´í„° ì—…ë¡œë“œ ë° ë¶„ì„")
uploaded_file = st.file_uploader("ì‘ì„±ëœ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ (.xlsx)", type=['xlsx', 'xls'])

if uploaded_file:
    try:
        excel_obj = pd.ExcelFile(uploaded_file)
        sheet_names = excel_obj.sheet_names
        df_main = pd.read_excel(uploaded_file, sheet_name=sheet_names[0])
        main_cols = df_main.columns[2:]
        main_factors, n_main = infer_factors_from_columns(main_cols)

        permission_granted = False
        message = ""
        role = st.session_state.user_role
        user_id = st.session_state.user_id

        if role == 'admin' or role == 'official':
            permission_granted = True
            if role == 'official':
                today = datetime.date.today()
                expiry = datetime.datetime.strptime(st.session_state.expiry_date, "%Y-%m-%d").date()
                if today > expiry:
                    permission_granted = False
                    message = "â›” ì´ìš© ê¸°ê°„ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        else: 
            rows_ok = True
            for sn in sheet_names:
                if len(pd.read_excel(uploaded_file, sheet_name=sn)) > 5:
                    rows_ok = False
                    break
            if rows_ok: permission_granted = True
            else: message = f"â›” **ì„ì‹œ ì‚¬ìš©ì**ëŠ” ì‹œíŠ¸ë‹¹ ìµœëŒ€ 5ê°œ í‘œë³¸ê¹Œì§€ë§Œ ë¶„ì„ ê°€ëŠ¥í•©ë‹ˆë‹¤."

        if permission_granted:
            with st.spinner("ê³„ì¸µ ë¶„ì„ ìˆ˜í–‰ ì¤‘..."):
                main_results_df, main_factors = process_single_sheet(df_main, cr_threshold, max_iter, mean_method)
                main_sig_df = calculate_pairwise_ttest(main_results_df, main_factors)
                main_weight_cols = [f"Weight_{f}" for f in main_factors]
                
                if mean_method == 'arithmetic':
                    group_main_weights = main_results_df[main_weight_cols].mean(axis=0)
                else:
                    group_main_weights = gmean(main_results_df[main_weight_cols], axis=0)
                group_main_weights = group_main_weights / group_main_weights.sum()
                main_cr_final_avg = main_results_df['Final_CR'].mean()
                
                main_matrices = np.stack(main_results_df['Matrix_Object'].values)
                main_group_matrix = np.mean(main_matrices, axis=0) if mean_method == 'arithmetic' else gmean(main_matrices, axis=0)
                main_grp_cr, main_grp_ci, _ = calculate_consistency(main_group_matrix, mean_method)
                
                indiv_global_data = []
                all_ids = main_results_df['ID'].unique()
                
                sub_results_storage = {} 
                for i, sub_sheet_name in enumerate(sheet_names[1:]):
                    parent_factor = main_factors[i]
                    df_sub = pd.read_excel(uploaded_file, sheet_name=sub_sheet_name)
                    sub_res_df, sub_facts = process_single_sheet(df_sub, cr_threshold, max_iter, mean_method)
                    sub_sig_df = calculate_pairwise_ttest(sub_res_df, sub_facts)
                    sub_w_cols = [f"Weight_{f}" for f in sub_facts]
                    group_sub_w = sub_res_df[sub_w_cols].mean(axis=0) if mean_method == 'arithmetic' else gmean(sub_res_df[sub_w_cols], axis=0)
                    group_sub_w = group_sub_w / group_sub_w.sum()
                    sub_cr_final_avg = sub_res_df['Final_CR'].mean()
                    sub_matrices = np.stack(sub_res_df['Matrix_Object'].values)
                    sub_group_matrix = np.mean(sub_matrices, axis=0) if mean_method == 'arithmetic' else gmean(sub_matrices, axis=0)
                    sub_grp_cr, _, _ = calculate_consistency(sub_group_matrix, mean_method)
                    sub_results_storage[parent_factor] = {
                        'weights': group_sub_w, 'factors': sub_facts, 'cr': sub_cr_final_avg,
                        'df': sub_res_df, 'group_matrix': sub_group_matrix, 'group_cr': sub_grp_cr, 'sig_df': sub_sig_df
                    }

                for uid in all_ids:
                    u_main = main_results_df[main_results_df['ID'] == uid]
                    if u_main.empty: continue
                    u_type = u_main['Type'].values[0]
                    for mf in main_factors:
                        m_w = u_main[f"Weight_{mf}"].values[0]
                        s_df = sub_results_storage[mf]['df']
                        u_sub = s_df[s_df['ID'] == uid]
                        if u_sub.empty: continue
                        for sf in sub_results_storage[mf]['factors']:
                            s_w = u_sub[f"Weight_{sf}"].values[0]
                            indiv_global_data.append({
                                "ID": uid, "Type": str(u_type), "Factor": sf, "Global_Weight": m_w * s_w
                            })
                indiv_df = pd.DataFrame(indiv_global_data)
                
                anova_df = pd.DataFrame()
                if not indiv_df.empty and len(indiv_df['Type'].unique()) >= 2:
                    anova_df = calculate_anova_and_posthoc(indiv_df)

                summary_rows = []
                for idx, main_f in enumerate(main_factors):
                    m_weight = group_main_weights[idx]
                    sub_info = sub_results_storage[main_f]
                    for s_idx, sub_f in enumerate(sub_info['factors']):
                        s_weight = sub_info['weights'][s_idx]
                        global_w = m_weight * s_weight
                        summary_rows.append({
                            "ëŒ€ë¶„ë¥˜": main_f, "ëŒ€ë¶„ë¥˜ ê°€ì¤‘ì¹˜": m_weight, "ì¤‘ë¶„ë¥˜": sub_f, "ì¤‘ë¶„ë¥˜ ê°€ì¤‘ì¹˜": s_weight,
                            "Global Weight": global_w, "CR(ëŒ€ë¶„ë¥˜)": main_cr_final_avg, "CR(ì¤‘ë¶„ë¥˜)": sub_info['cr']
                        })
                
                final_df = pd.DataFrame(summary_rows)
                final_df['Global Rank'] = final_df['Global Weight'].rank(ascending=False, method='min').astype(int)
                cols_order = ["ëŒ€ë¶„ë¥˜", "ëŒ€ë¶„ë¥˜ ê°€ì¤‘ì¹˜", "ì¤‘ë¶„ë¥˜", "ì¤‘ë¶„ë¥˜ ê°€ì¤‘ì¹˜", "Global Weight", "Global Rank", "CR(ëŒ€ë¶„ë¥˜)", "CR(ì¤‘ë¶„ë¥˜)"]
                final_df = final_df[cols_order]

                unique_groups = sorted(main_results_df['Type'].astype(str).unique())
                group_analysis_results = {}
                group_full_dfs = {} 
                
                for grp in unique_groups:
                    grp_main_df = main_results_df[main_results_df['Type'].astype(str) == grp]
                    if grp_main_df.empty: continue
                    g_main_w = grp_main_df[main_weight_cols].mean(axis=0) if mean_method == 'arithmetic' else gmean(grp_main_df[main_weight_cols], axis=0)
                    g_main_w = g_main_w / g_main_w.sum()
                    g_main_mats = np.stack(grp_main_df['Matrix_Object'].values)
                    g_main_mat_obj = np.mean(g_main_mats, axis=0) if mean_method == 'arithmetic' else gmean(g_main_mats, axis=0)
                    g_main_cr, _, _ = calculate_consistency(g_main_mat_obj, mean_method)
                    
                    grp_rows = []
                    for idx, main_f in enumerate(main_factors):
                        m_w = g_main_w[idx]
                        full_sub_df = sub_results_storage[main_f]['df']
                        grp_sub_df = full_sub_df[full_sub_df['Type'].astype(str) == grp]
                        sub_facts = sub_results_storage[main_f]['factors']
                        if grp_sub_df.empty: continue
                        s_w_cols = [f"Weight_{f}" for f in sub_facts]
                        g_sub_w = grp_sub_df[s_w_cols].mean(axis=0) if mean_method == 'arithmetic' else gmean(grp_sub_df[s_w_cols], axis=0)
                        g_sub_w = g_sub_w / g_sub_w.sum()
                        g_sub_mats = np.stack(grp_sub_df['Matrix_Object'].values)
                        g_sub_mat_obj = np.mean(g_sub_mats, axis=0) if mean_method == 'arithmetic' else gmean(g_sub_mats, axis=0)
                        g_sub_cr, _, _ = calculate_consistency(g_sub_mat_obj, mean_method)
                        for s_idx, sf in enumerate(sub_facts):
                            grp_rows.append({
                                "ëŒ€ë¶„ë¥˜": main_f, "ëŒ€ë¶„ë¥˜ ê°€ì¤‘ì¹˜": m_w, "ì¤‘ë¶„ë¥˜": sf, "ì¤‘ë¶„ë¥˜ ê°€ì¤‘ì¹˜": g_sub_w[s_idx],
                                "Global Weight": m_w * g_sub_w[s_idx], "CR(ëŒ€ë¶„ë¥˜)": g_main_cr, "CR(ì¤‘ë¶„ë¥˜)": g_sub_cr
                            })
                    g_df = pd.DataFrame(grp_rows)
                    if not g_df.empty:
                        g_df['Global Rank'] = g_df['Global Weight'].rank(ascending=False, method='min').astype(int)
                        group_full_dfs[grp] = g_df[cols_order]
                        group_analysis_results[grp] = group_full_dfs[grp][['ì¤‘ë¶„ë¥˜', 'Global Weight']]

                comparison_df = final_df[['ì¤‘ë¶„ë¥˜', 'Global Weight']].copy()
                comparison_df.rename(columns={'Global Weight': 'Overall'}, inplace=True)
                for grp, df_res in group_analysis_results.items():
                    temp_df = df_res.rename(columns={'Global Weight': grp})
                    comparison_df = comparison_df.merge(temp_df, on='ì¤‘ë¶„ë¥˜', how='left')

                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    workbook = writer.book
                    formats = {
                        'header': workbook.add_format({'bold': True, 'align': 'center', 'valign': 'vcenter', 'bg_color': '#000000', 'font_color': '#FFFFFF', 'border': 1}),
                        'merge': workbook.add_format({'align': 'center', 'valign': 'vcenter', 'border': 1}),
                        'body': workbook.add_format({'align': 'center', 'valign': 'vcenter', 'border': 1}),
                        'num': workbook.add_format({'align': 'center', 'valign': 'vcenter', 'border': 1, 'num_format': '0.000'}),
                        'sum_row': workbook.add_format({'bold': True, 'bg_color': '#D3D3D3', 'align': 'center', 'valign': 'vcenter', 'border': 1}),
                        'sum_val': workbook.add_format({'num_format': '0', 'bg_color': '#D3D3D3', 'border': 1, 'align':'center'}),
                        'num_sum': workbook.add_format({'num_format': '0.000', 'bg_color': '#D3D3D3', 'border': 1, 'align':'center'})
                    }
                    border_fmt = workbook.add_format({'border': 1})
                    fmt_float_no_border = workbook.add_format({'num_format': '0.000', 'align': 'center', 'valign': 'vcenter'})
                    fmt_plain_no_border = workbook.add_format({'align': 'center', 'valign': 'vcenter'})
                    fmt_diagonal = workbook.add_format({'num_format': '0', 'align': 'center', 'valign': 'vcenter', 'bg_color': '#E7E6E6'})

                    current_row = write_custom_ahp_table(writer, 'ì¢…í•©ë¶„ì„', final_df, "1) ì „ì²´_ì¢…í•©ê²°ê³¼", 1, formats)
                    for grp in unique_groups:
                        if grp in group_full_dfs:
                            current_row = write_custom_ahp_table(writer, 'ì¢…í•©ë¶„ì„', group_full_dfs[grp], f"â–¶ [ê·¸ë£¹: {grp}] ë¶„ì„ ê²°ê³¼", current_row, formats)

                    comparison_df.to_excel(writer, sheet_name='Group_Comparison', index=False)
                    ws_comp = writer.sheets['Group_Comparison']
                    add_borders_to_data(ws_comp, 0, 0, comparison_df, border_fmt)

                    if not anova_df.empty:
                        anova_df.to_excel(writer, sheet_name='Statistical_Test', index=False)
                        ws_anova = writer.sheets['Statistical_Test']
                        add_borders_to_data(ws_anova, 0, 0, anova_df, border_fmt)

                    # ê·¸ë£¹ë³„ ì¢…í•© í–‰ë ¬í‘œ ì—‘ì…€ ì¶œë ¥ ê¸°ëŠ¥
                    def write_detailed_sheet(sheet_name, matrix_df, detail_df, matrix_title, row_labels, group_matrices=None):
                        ws = workbook.add_worksheet(sheet_name)
                        writer.sheets[sheet_name] = ws
                        s_row = 0
                        ws.write_string(s_row, 0, matrix_title)
                        s_row += 1
                        
                        pd.DataFrame(matrix_df, index=row_labels, columns=row_labels).to_excel(writer, sheet_name=sheet_name, startrow=s_row)
                        for r in range(len(matrix_df)):
                            for c in range(len(matrix_df)):
                                val = 1 if r==c else matrix_df[r][c]
                                ws.write(s_row+r+1, c+1, val, border_fmt if r!=c else fmt_diagonal)
                                if r!=c: ws.write(s_row+r+1, c+1, val, fmt_float_no_border)
                        s_row += len(matrix_df) + 3

                        if group_matrices:
                            for g_name, g_mat in group_matrices.items():
                                ws.write_string(s_row, 0, f"] ê·¸ë£¹ ì¢…í•© í–‰ë ¬: {g_name}")
                                s_row += 1
                                pd.DataFrame(g_mat, index=row_labels, columns=row_labels).to_excel(writer, sheet_name=sheet_name, startrow=s_row)
                                for r in range(len(g_mat)):
                                    for c in range(len(g_mat)):
                                        val = 1 if r==c else g_mat[r][c]
                                        ws.write(s_row+r+1, c+1, val, border_fmt if r!=c else fmt_diagonal)
                                        if r!=c: ws.write(s_row+r+1, c+1, val, fmt_float_no_border)
                                s_row += len(g_mat) + 3

                        detail_df.to_excel(writer, sheet_name=sheet_name, startrow=s_row, index=False)
                        add_borders_to_data(ws, s_row, 0, detail_df, border_fmt)

                    main_group_mats = {}
                    for grp in unique_groups:
                        g_df = main_results_df[main_results_df['Type'].astype(str) == grp]
                        if not g_df.empty:
                            mats = np.stack(g_df['Matrix_Object'].values)
                            main_group_mats[grp] = np.mean(mats, axis=0) if mean_method == 'arithmetic' else gmean(mats, axis=0)

                    out_main = main_results_df.drop(columns=['Matrix_Object'], errors='ignore')
                    write_detailed_sheet('Result_Main', main_group_matrix, out_main, f"[1] ì „ì²´ ì¢…í•© í–‰ë ¬", main_factors, group_matrices=main_group_mats)
                    
                    for mf, info in sub_results_storage.items():
                        safe_name = f"Result_{mf}"[:31]
                        sub_grp_mats = {}
                        for grp in unique_groups:
                            g_sub_df = info['df'][info['df']['Type'].astype(str) == grp]
                            if not g_sub_df.empty:
                                mats = np.stack(g_sub_df['Matrix_Object'].values)
                                sub_grp_mats[grp] = np.mean(mats, axis=0) if mean_method == 'arithmetic' else gmean(mats, axis=0)
                        out_sub = info['df'].drop(columns=['Matrix_Object'], errors='ignore')
                        write_detailed_sheet(safe_name, info['group_matrix'], out_sub, f"[1] ì „ì²´ ì¢…í•© í–‰ë ¬", info['factors'], group_matrices=sub_grp_mats)

                st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                if st.session_state.user_role == 'official':
                    save_analysis_to_db(st.session_state.user_id, f"{uploaded_file.name.split('.')[0]}_Result.xlsx", output.getvalue())

                tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸŒ ì¢…í•© ë¶„ì„ (Global)", "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ ê·¸ë£¹ë³„ ë¶„ì„", "ğŸ§ª í†µê³„ ê²€ì • (ANOVA)", "ğŸ“Š ì‹œê°í™” ì„¼í„°", "ğŸ“‘ ìƒì„¸ ë°ì´í„°"])
                with tab1:
                    st.subheader("ğŸŒ ì¢…í•© ì¤‘ìš”ë„ ë° ìˆœìœ„")
                    st.dataframe(final_df.style.format(precision=3), use_container_width=True)
                with tab2:
                    st.markdown("#### ê·¸ë£¹ë³„ ê°€ì¤‘ì¹˜ ìƒì„¸ ë¹„êµ")
                    st.dataframe(comparison_df.style.format(precision=4), use_container_width=True)
                with tab3:
                    st.markdown("#### ì§‘ë‹¨ ê°„ ìœ ì˜ì„± ë¶„ì„")
                    if not anova_df.empty: st.dataframe(anova_df.style.format(precision=5), use_container_width=True)
                    else: st.info("í†µê³„ ê²€ì •ì„ ìœ„í•´ 2ê°œ ì´ìƒì˜ ê·¸ë£¹ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                with tab4:
                    st.markdown("#### ğŸ“Š ì‹œê°í™” ì„¼í„°")
                    col_chart1, col_chart2 = st.columns(2)
                    with col_chart1:
                        st.write("**ì¢…í•© ì¤‘ìš”ë„ (Bar)**")
                        fig_bar = px.bar(final_df.sort_values('Global Weight'), y='ì¤‘ë¶„ë¥˜', x='Global Weight', orientation='h', text_auto='.3f')
                        st.plotly_chart(fig_bar, use_container_width=True)
                    with col_chart2:
                        st.write("**ê·¸ë£¹ë³„ ì¤‘ìš”ë„ íŒ¨í„´ (Radar)**")
                        radar_plot_df = indiv_global_data = []
                        all_ids = main_results_df['ID'].unique()
                        for rid in all_ids:
                            m_row = main_results_df[main_results_df['ID'] == rid].iloc[0]
                            rtype = m_row['Type']
                            for m_f in main_factors:
                                mw_indiv = m_row[f"Weight_{m_f}"]
                                s_row = sub_results_storage[m_f]['df'][sub_results_storage[m_f]['df']['ID'] == rid].iloc[0]
                                for s_f in sub_results_storage[m_f]['factors']:
                                    indiv_global_data.append({"Type": rtype, "Factor": s_f, "Global_Weight": mw_indiv * s_row[f"Weight_{s_f}"]})
                        radar_indiv_df = pd.DataFrame(indiv_global_data)
                        radar_plot_df = radar_indiv_df.groupby(['Type', 'Factor'])['Global_Weight'].mean().reset_index()
                        fig_radar = go.Figure()
                        for t in radar_plot_df['Type'].unique():
                            t_data = radar_plot_df[radar_plot_df['Type'] == t]
                            fig_radar.add_trace(go.Scatterpolar(r=t_data['Global_Weight'], theta=t_data['Factor'], fill='toself', name=t))
                        st.plotly_chart(fig_radar, use_container_width=True)

                    st.markdown("---")
                    st.write("**3. ì¼ê´€ì„± ë¹„ìœ¨(CR) ë¶„í¬ë„ (Violin/Box Plot)**")
                    cr_dist_data = main_results_df[['ID', 'Type', 'Final_CR']].copy()
                    cr_dist_data['Level'] = 'ëŒ€ë¶„ë¥˜'
                    for m_f in main_factors:
                        temp_cr = sub_results_storage[m_f]['df'][['ID', 'Type', 'Final_CR']].copy()
                        temp_cr['Level'] = f'ì¤‘ë¶„ë¥˜({m_f})'
                        cr_dist_data = pd.concat([cr_dist_data, temp_cr])
                    fig_cr_dist = px.violin(cr_dist_data, y="Final_CR", x="Level", color="Level", box=True, points="all", title="ì‘ë‹µìë³„ ì¼ê´€ì„± ì§€ìˆ˜ ë¶„í¬")
                    st.plotly_chart(fig_cr_dist, use_container_width=True)

                    st.markdown("---")
                    st.write("**4. í•­ëª©ë³„ ìš°ì„ ìˆœìœ„ ì‚°ì ë„ (ì¤‘ìš”ë„ vs. í•©ì˜ë„)**")
                    scatter_df = radar_indiv_df.groupby('Factor')['Global_Weight'].agg(['mean', 'std']).reset_index()
                    scatter_df.columns = ['Factor', 'Weight_Mean', 'Weight_SD']
                    fig_scatter = px.scatter(scatter_df, x="Weight_Mean", y="Weight_SD", text="Factor", size="Weight_Mean", color="Weight_Mean",
                                            labels={'Weight_Mean': 'ì¤‘ìš”ë„(í‰ê· )', 'Weight_SD': 'ì˜ê²¬ì°¨ì´(í‘œì¤€í¸ì°¨)'},
                                            title="ì¤‘ìš”ë„-í•©ì˜ë„ ë¶„ì„ (ìš°ì¸¡ í•˜ë‹¨ì¼ìˆ˜ë¡ ì¤‘ìš”í•˜ê³  í•©ì˜ëœ í•­ëª©)")
                    fig_scatter.update_traces(textposition='top center')
                    st.plotly_chart(fig_scatter, use_container_width=True)

                with tab5:
                    st.download_button("ğŸ“¥ ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (Excel)", data=output.getvalue(), file_name="AHP_Result.xlsx")
                    st.dataframe(radar_indiv_df, use_container_width=True)
        else:
            st.warning(message)
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

st.markdown("---")
st.caption("Â© 2026 AHP Analysis System. All rights reserved.")


